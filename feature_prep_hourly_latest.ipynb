{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $VIRTUAL_ENV_DIR/python3/bin/activate\n",
    "\n",
    "install_package_python3.sh add dsw_qr==0.1.13\n",
    "\n",
    "$VIRTUAL_ENV_DIR/python3/bin/python -m pip install galileo\n",
    "$VIRTUAL_ENV_DIR/python3/bin/python -m pip install galileo-py\n",
    "$VIRTUAL_ENV_DIR/python3/bin/python -m pip install tchannel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dsw_qr import dsw_qr\n",
    "from queryrunner_client import Client\n",
    "qr = Client(user_email='thai@uber.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_query(city_list, sample_percentage, start_date, end_date):\n",
    "    QUERY = \"\"\"\n",
    "    SET session hash_partition_count=64;\n",
    "    \n",
    "    -- calculate features based on average plan value for first 60s of the hour\n",
    "    select\n",
    "        plans.datestr,\n",
    "        plans.city_id,\n",
    "        hour(from_unixtime(cast(plans.ts as bigint))) as hour_of_day,\n",
    "        count(*) as num_plans,\n",
    "        avg(LOG2(completed.client_upfront_fare_usd)) as market_log2_fare_usd,\n",
    "        avg(LOG2(completed.client_upfront_fare_local)) as market_log2_fare_local,\n",
    "        avg(LOG2(completed.client_upfront_fare_local / 15.0)) as market_log2_scaled_fare_local,\n",
    "        avg(LOG2(plans.network_contention + (1 - plans.network_contention)*completed.client_upfront_fare_local/15.0)) as market_log2_network_scaled_fare_local,\n",
    "        avg(plans.log2_eta) as market_log2_eta,\n",
    "        avg(LOG2(plans.cr_ratio)) as market_log2_cr_ratio\n",
    "    from\n",
    "      (\n",
    "        select\n",
    "            distinct mgv.datestr,\n",
    "            mgv.city_id,\n",
    "            mgv.supply_plan_uuid,\n",
    "            mgv.job_uuid,\n",
    "            mgv.supply_uuid,\n",
    "            mgv.job_creation_time_ms,\n",
    "            LOG2(1 - mgv.eta / 1500.0) as log2_eta,\n",
    "            1.0 / POWER(mgv.surge_mul, 5) as network_contention,\n",
    "            (1.0 - mgv.driver_cancel_prob) * (1.0 - mgv.rider_cancel_prob) * (1.0 - mgv.spinner_cancel_prob) + mgv.eventual_comp_prob * mgv.driver_cancel_prob as cr_ratio,\n",
    "            rank() over (\n",
    "            PARTITION BY mgv.supply_uuid,\n",
    "            mgv.job_uuid\n",
    "            ORDER BY\n",
    "              mgv.ts desc\n",
    "            ) as rank,\n",
    "            mgv.ts\n",
    "        from\n",
    "          (\n",
    "            select\n",
    "              distinct datestr,\n",
    "              msg.job_uuid,\n",
    "              msg.supply_uuid,\n",
    "              msg.supply_plan_uuid,\n",
    "              msg.city_id,\n",
    "              msg.ct_request_uuid,\n",
    "              msg.job_creation_time_ms,\n",
    "              1.0 - msg.solo_cancel_model_driver_accept_prob as driver_cancel_prob,\n",
    "              1.0 - msg.solo_cancel_model_rider_accept_prob as rider_cancel_prob,\n",
    "              1.0 - msg.spinner_survive_prob_before_next_scan as spinner_cancel_prob,\n",
    "              (CASE\n",
    "                WHEN msg.adjustedeta >= 1500 THEN 1499.0\n",
    "                WHEN msg.adjustedeta < 0 THEN 0.0\n",
    "                ELSE msg.adjustedeta\n",
    "              END) as eta,\n",
    "              msg.job_surge as surge_mul,\n",
    "              msg.eventual_completion_probability as eventual_comp_prob,\n",
    "              msg.job_type,\n",
    "              msg.flow_type,\n",
    "              ts\n",
    "            from\n",
    "              rawdata.kafka_hp_multileg_mgv_log_nodedup\n",
    "            where\n",
    "              msg.tenancy = 'uber/production'\n",
    "              and msg.solo_cancel_model_driver_accept_prob is not NULL\n",
    "              and msg.solo_cancel_model_rider_accept_prob is not NULL\n",
    "              and msg.spinner_survive_prob_before_next_scan is not NULL\n",
    "              and msg.eventual_completion_probability is not NULL\n",
    "              and msg.city_id in ({})\n",
    "              and datestr between '{}' and '{}'\n",
    "          ) mgv\n",
    "        where\n",
    "          mgv.job_type = 'PERSONAL_TRANSPORT'\n",
    "          and mgv.flow_type in ('solo_batch', 'solo')\n",
    "          and minute(from_unixtime(cast(mgv.ts as bigint))) = 0 and second(from_unixtime(cast(mgv.ts as bigint))) between 0 and 60\n",
    "          and abs(\n",
    "            mod(\n",
    "              from_big_endian_64(xxhash64(CAST(mgv.job_uuid AS varbinary))),\n",
    "              100\n",
    "            )\n",
    "          ) <= {}\n",
    "      ) as plans\n",
    "      join\n",
    "        dwh.fact_trip as completed \n",
    "      on\n",
    "        plans.job_uuid = completed.uuid\n",
    "        and plans.supply_uuid = completed.driver_uuid\n",
    "        and plans.datestr = completed.datestr\n",
    "        and plans.rank = 1 -- left join fares for last plan\n",
    "        and completed.datestr between '{}' and '{}'\n",
    "        and completed.status = 'completed'\n",
    "        and completed.client_upfront_fare_usd > 0\n",
    "        and completed.client_upfront_fare_local > 0\n",
    "    group by\n",
    "      plans.datestr,\n",
    "      plans.city_id,\n",
    "      hour(from_unixtime(cast(plans.ts as bigint)))\n",
    "    order by\n",
    "      plans.datestr,\n",
    "      plans.city_id,\n",
    "      hour_of_day\n",
    "    \"\"\".format(\",\".join([str(city_id) for city_id in city_list]), start_date, end_date, sample_percentage, start_date, end_date)\n",
    "    return QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_list, sample_percentage, start_date, end_date\n",
    "city_list = [1269, 789, 797, 801, 803, 144, 787, 933]\n",
    "sample_percentage = 100\n",
    "dates_list = [\n",
    "              ('2022-10-13', '2022-10-14'), ('2022-10-15', '2022-10-16'),\n",
    "              ('2022-10-17', '2022-10-18'), ('2022-10-19', '2022-10-20'),\n",
    "              ('2022-10-21', '2022-10-22'), ('2022-10-23', '2022-10-24'),\n",
    "              ('2022-10-25', '2022-10-26'), ('2022-10-27', '2022-10-28'),\n",
    "              ('2022-10-29', '2022-10-30'), ('2022-10-31', '2022-11-01'),\n",
    "              ('2022-11-02', '2022-11-03'), ('2022-11-04', '2022-11-05'),\n",
    "              ('2022-11-06', '2022-11-07'), ('2022-11-08', '2022-11-09')\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dates_list)):\n",
    "    start_date, end_date = dates_list[i]\n",
    "    QUERY = prepare_query(city_list, \n",
    "                          sample_percentage,\n",
    "                          start_date,\n",
    "                          end_date)\n",
    "    cursor = qr.execute(\"presto-secure\", QUERY)\n",
    "    result = cursor.fetchall()\n",
    "    pd.DataFrame(result).to_csv(f\"latam_hourly_features_latest_{i+1}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02. Python 3.6 (General DS)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
