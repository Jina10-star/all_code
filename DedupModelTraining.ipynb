{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Duplicated pairs from the ELK, categorized by years, tasks (snaptask or wisdom), and apps\n",
    "\n",
    "You can download the `elk_result.pickle` data from https://drive.google.com/file/d/1WHASgopxAo1nk279p70LJppdMZyfj4k4/view?usp=sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('elk_result.pickle', 'rb') as f:\n",
    "    elk_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the cassandra client for feature_pool and bug_report querying given `report_id`\n",
    "\n",
    "- Features created by wisdom team right now is stored in `wisdom_classifier.feature_pool` table\n",
    "- Features that are not yet being used by either quality score or dedup model is stored in `wisdom.bug_reports`, this table contains network_logs, analytics_logs, console_logs etc.\n",
    "- When doing the query with `report_id`, do make sure `case_sensitive` is setup to `False` as the cassandra table is currently mixing `report_id` will all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra import ConsistencyLevel\n",
    "from cassandra.query import SimpleStatement\n",
    "from cassandra.cluster import Cluster, ExecutionProfile, EXEC_PROFILE_DEFAULT\n",
    "from cassandra.query import BatchStatement\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import editdistance\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Install cassandra via \n",
    "\n",
    "brew install cassandra\n",
    "\n",
    "Then run this on local machine\n",
    "\n",
    "ssh -MfN -L 9042:schemadock3128-dca1:9042 adhoc20-dca1\n",
    "\"\"\"\n",
    "\n",
    "class CassandraClient:\n",
    "    def __init__(self, contact_points, port, username, password):\n",
    "        auth_provider = PlainTextAuthProvider(username=username, password=password)\n",
    "        profile = ExecutionProfile(request_timeout=10000)\n",
    "        cluster = Cluster(contact_points=[contact_points], port=port, auth_provider=auth_provider, \n",
    "                          idle_heartbeat_interval=150, idle_heartbeat_timeout=150, \\\n",
    "                          execution_profiles={EXEC_PROFILE_DEFAULT: profile})\n",
    "        self.wisdom_session = cluster.connect('wisdom')\n",
    "        self.wisdom_classifier_session = cluster.connect('wisdom_classifier')\n",
    "    \n",
    "    def execute(self, session, cql):\n",
    "        return [row for row in session.execute(cql)]\n",
    "        \n",
    "    def get_bug_report(self, report_id, columns = None):\n",
    "        table_name = 'bug_reports'\n",
    "        if not columns:\n",
    "            columns = ['*']\n",
    "            \n",
    "        cql = \"\"\"\n",
    "            select {columns}\n",
    "            from {tablename}\n",
    "            where report_uuid = '{report_id}' ALLOW FILTERING;\"\"\".format(columns=','.join(columns),\n",
    "            tablename=table_name, report_id=report_id)\n",
    "        \n",
    "        res = self.execute(self.wisdom_session, cql)\n",
    "    \n",
    "        if len(res) > 0:\n",
    "                return res[0]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def _get_case_insensitive_ids(self, report_ids):\n",
    "        new_report_ids = []\n",
    "        for report_id in report_ids:\n",
    "            new_report_ids.extend([report_id.lower(), report_id.upper()])\n",
    "                \n",
    "        return new_report_ids\n",
    "    \n",
    "    def get_bug_reports(self, report_ids, case_sensitive = False, columns = None):\n",
    "        table_name = 'bug_reports'\n",
    "        if not columns:\n",
    "            columns = ['*']\n",
    "        \n",
    "        if not case_sensitive:\n",
    "            report_ids = self._get_case_insensitive_ids(report_ids)\n",
    "\n",
    "        cql = \"\"\"\n",
    "            select {columns}\n",
    "            from {tablename}\n",
    "            where report_uuid in ('{report_ids}') ALLOW FILTERING;\"\"\".format(columns=','.join(columns), \\\n",
    "                                                                             tablename=table_name, \n",
    "                                                                             report_ids='\\',\\''.join(report_ids))\n",
    "        return self.execute(self.wisdom_session, cql)\n",
    "    \n",
    "    def get_report_feature_pool(self, report_id, columns = None):\n",
    "        table_name = 'feature_pool'\n",
    "        if not columns:\n",
    "            columns = ['*']\n",
    "                    \n",
    "        cql = \"\"\"\n",
    "            select {columns} from {tablename}\n",
    "            where report_id = '{report_id}' ALLOW FILTERING;\"\"\".format(columns=','.join(columns), \\\n",
    "                                                                       tablename=table_name, report_id=report_id)\n",
    "        \n",
    "        res = self.execute(self.wisdom_classifier_session, cql)\n",
    "        \n",
    "        if len(res) > 0:\n",
    "            return res[0]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def get_report_feature_pools(self, report_ids, case_sensitive = False, columns = None):\n",
    "        table_name = 'feature_pool'\n",
    "        if not columns:\n",
    "            columns = ['*']\n",
    "        \n",
    "        if not case_sensitive:\n",
    "            report_ids = self._get_case_insensitive_ids(report_ids)\n",
    "        \n",
    "        cql = \"\"\"\n",
    "            select * from {tablename}\n",
    "            where report_id in ('{report_ids}') ALLOW FILTERING;\"\"\".format(tablename=table_name, \\\n",
    "                                                                           report_ids='\\',\\''.join(report_ids))\n",
    "        \n",
    "        res = self.execute(self.wisdom_classifier_session, cql)\n",
    "        \n",
    "        return res\n",
    "        \n",
    "    def get_reports_feature_pool_with_time_duration(self, time_duration):\n",
    "        table_name = 'feature_pool'\n",
    "        \n",
    "        date_input = datetime.datetime.today()\n",
    "        date1 = date_input.strftime('%Y-%m-%d')\n",
    "        date2 = (date_input-datetime.timedelta(time_duration)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        print('date1 is : {}\\n'.format(date1))\n",
    "        print('date2 is : {}\\n'.format(date2))\n",
    "        \n",
    "        cql = \"\"\"\n",
    "            select report_id, created_at, report_created_at, title, description, tag, screenshot_hash_avg, screenshot_hash_perception, screenshot_hash_diff, \n",
    "            text_tf_ngram, title_tf_ngram, feature_descr_tf_ngram, app_name, platform\n",
    "            from {tablename} \n",
    "            where report_created_at > '{date2}' and report_created_at <= '{date1}' \n",
    "            ALLOW FILTERING;\"\"\".format(tablename=table_name, date1=date1, date2=date2)\n",
    "        \n",
    "        return self.execute(self.wisdom_classifier_session, cql)\n",
    "\n",
    "contact_points = \"localhost\"\n",
    "port = 9042\n",
    "username = \"apphealth_cassandra\"\n",
    "password = \"xxx\"\n",
    "\n",
    "wisdom_cassandra_client = CassandraClient(contact_points, port, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying cassandra database by calling this method.\n",
    "\n",
    "\n",
    "- `get_report_id_to_features` will create a mapping between `report_id` and its corrresponding `bug_report` (from wisdom.bug_reports) and `feature_pool` (from `wisdom_classifier.feature_pool`)\n",
    "\n",
    "\n",
    "- `get_random_pairs` will generate the corresponding nondup pairs given the dup pairs and list of `report_ids`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query for bug_reports of snap, 2018, rider has completed\n",
      "query for feature_pools of snap, 2018, rider has completed\n",
      "query for bug_reports of snap, 2018, driver has completed\n",
      "query for feature_pools of snap, 2018, driver has completed\n",
      "query for bug_reports of snap, 2019, rider has completed\n",
      "query for feature_pools of snap, 2019, rider has completed\n",
      "query for bug_reports of snap, 2019, driver has completed\n",
      "query for feature_pools of snap, 2019, driver has completed\n",
      "query for bug_reports of wisdom, 2019, rider has completed\n",
      "query for feature_pools of wisdom, 2019, rider has completed\n",
      "9320D5C3-913C-47FA-96CC-C2261E86C896 does not exist in cassandra table\n",
      "52E597D2-DCDD-4A17-A1EC-CB3E5F6E6919 does not exist in cassandra table\n",
      "5C9A78F3-2AB1-4162-A720-9D8FA00F3A12 does not exist in cassandra table\n",
      "A77E5441-1108-4AB6-9DEA-7C1FF3ED9D97 does not exist in cassandra table\n",
      "0DB73EEB-E905-445E-9F79-96B2CDA85352 does not exist in cassandra table\n",
      "C7918660-0B23-4DC0-B4F1-D617C69F4A88 does not exist in cassandra table\n",
      "7269C37A-53D7-4E28-A07E-87D12D671D6E does not exist in cassandra table\n",
      "85555ED6-F664-413A-85E3-8052B45D1987 does not exist in cassandra table\n",
      "A417FE0B-609D-4D0C-9021-926F1D912052 does not exist in cassandra table\n",
      "6C0157F0-FD2A-4C4D-A9A3-BEB89C4D06A6 does not exist in cassandra table\n",
      "4D5A6D06-08D6-4E08-95E6-1CAD4FD7F76C does not exist in cassandra table\n",
      "CBD6B2FF-2591-448B-88B8-4EC0F8E432A2 does not exist in cassandra table\n",
      "0AB5A504-2930-41B9-A1A0-02E056846014 does not exist in cassandra table\n",
      "07E3EF68-3B63-401C-9D33-BCB01DCB927E does not exist in cassandra table\n",
      "72FF45F1-5D8C-4BE8-B6AF-A8FC214F45AB does not exist in cassandra table\n",
      "118D111F-EB9B-4D14-9789-4CCAA763FCC3 does not exist in cassandra table\n",
      "8EC85157-E822-4AB9-8A51-79FAA1BD470C does not exist in cassandra table\n",
      "51FFECB6-5B82-4426-9CE9-BEC43D9A37F8 does not exist in cassandra table\n",
      "FF572DE5-7891-4DF0-B108-EC2A83A367EA does not exist in cassandra table\n",
      "5B82E012-584E-42F3-956D-BEC5CC939F97 does not exist in cassandra table\n",
      "11FEE900-8C30-4B46-9A0B-E03C9D10A973 does not exist in cassandra table\n",
      "59A29C3B-F233-4E49-8EE0-603F921F9B9A does not exist in cassandra table\n",
      "798F138A-E06A-4F33-B980-00653CFA0623 does not exist in cassandra table\n",
      "DE1DE5C0-FA8F-4A92-B8C4-B888F9BDFAAF does not exist in cassandra table\n",
      "7BD889E2-23E4-478A-9A86-E29086EFC43E does not exist in cassandra table\n",
      "E5BFAF53-90D9-4CB3-87FD-80EC78EA0BB4 does not exist in cassandra table\n",
      "63F62CEF-3C01-4580-98B3-76AE46355EE3 does not exist in cassandra table\n",
      "45AB1AAB-886F-4182-A242-5395617D6ACC does not exist in cassandra table\n",
      "1D4E7C8B-805F-4E0B-8779-5D875B5ED8DA does not exist in cassandra table\n",
      "FDAB8926-3C0E-4E2D-B014-7F5FB167AE05 does not exist in cassandra table\n",
      "F375F6ED-2861-444D-B5D9-6A59AE2304ED does not exist in cassandra table\n",
      "70564AAD-B44D-4879-8FD4-E0E7DB3A7EFF does not exist in cassandra table\n",
      "D345DF17-C09D-423B-AE3D-2DE3DB87F07B does not exist in cassandra table\n",
      "54A43660-CB05-4A0C-9E52-C11115C0A169 does not exist in cassandra table\n",
      "7BDC3CA7-217A-4D42-A91A-9C1A2AC9A3FE does not exist in cassandra table\n",
      "E667DCE1-55B7-4B09-ABC2-1A06FC71D801 does not exist in cassandra table\n",
      "6614A097-9485-4128-87A3-D02650840C6F does not exist in cassandra table\n",
      "2C8A0489-6996-45B7-9DFE-EC7F18C3404A does not exist in cassandra table\n",
      "09FFF183-3F0F-4431-A193-66F1D3E69141 does not exist in cassandra table\n",
      "04787865-D768-4737-BA56-0E9394B66276 does not exist in cassandra table\n",
      "BA660D9F-800D-45F3-A979-D73F091C8815 does not exist in cassandra table\n",
      "78B48BB4-E38A-49A5-9F99-E03696D55A89 does not exist in cassandra table\n",
      "C12A6100-A97D-4817-8E56-439E953C1516 does not exist in cassandra table\n",
      "5D6348B0-A291-4865-B839-11C6F5B985D2 does not exist in cassandra table\n",
      "ECF76FC8-8361-4F11-95CA-964D6AA52A98 does not exist in cassandra table\n",
      "978128A2-F693-437B-9565-596643466513 does not exist in cassandra table\n",
      "606605D5-F5AC-4149-8273-1923C05FE1D2 does not exist in cassandra table\n",
      "D1D05469-E857-4026-AB59-D2E4342DB4F9 does not exist in cassandra table\n",
      "97317752-E8AF-46D3-AA3C-FE868A7EEC68 does not exist in cassandra table\n",
      "8D8AB215-A444-46A6-B99C-C8F1C6559190 does not exist in cassandra table\n",
      "C1B542C8-1AFE-41C7-9B27-1782FD74816A does not exist in cassandra table\n",
      "59FB1E93-5B71-4DAA-B857-B5F4DB8327A5 does not exist in cassandra table\n",
      "2D7F657A-AC90-4E11-9D24-349187A92119 does not exist in cassandra table\n",
      "499CF8CF-8A9B-42B2-8B49-642B8C05E843 does not exist in cassandra table\n",
      "A1C585FB-D51E-4B96-9241-691C660781AD does not exist in cassandra table\n",
      "CAA1E5C9-C789-461B-A9DC-F5078E14BD8D does not exist in cassandra table\n",
      "8CCAA873-7A36-4BE3-87A9-BA7C5A2D7D51 does not exist in cassandra table\n",
      "4ECC70F1-8E71-4D2B-9535-BB9F600D96CC does not exist in cassandra table\n",
      "2E9FABED-A686-4987-A3F6-803AD6C6AB0E does not exist in cassandra table\n",
      "29ABEB05-5CC9-43A9-B2EC-C1E72F958BA7 does not exist in cassandra table\n",
      "047379B9-AF40-4CC7-A363-93448313D072 does not exist in cassandra table\n",
      "9C52EF18-C3D8-400C-A290-0B8AB4744A7A does not exist in cassandra table\n",
      "6D5E50B3-671C-4D1F-B545-45E9D5BCD5D8 does not exist in cassandra table\n",
      "962B76A2-2B9B-4F9B-9296-7E99C32C9D48 does not exist in cassandra table\n",
      "23AA5F85-94F3-4B1C-AE9E-29BD9D111B03 does not exist in cassandra table\n",
      "D26BCDA1-BB57-413E-B1BE-37EDB057EBF3 does not exist in cassandra table\n",
      "68BE3533-1E6A-4F7D-A44B-8BCCFDC5FC70 does not exist in cassandra table\n",
      "CE800513-1294-4E49-8A17-C0B8F097B6E5 does not exist in cassandra table\n",
      "737BD311-9F1C-4D24-9AD2-3A3C84D4B256 does not exist in cassandra table\n",
      "D607EDAC-74E0-4364-9FEB-5E682EC70DED does not exist in cassandra table\n",
      "F5FB8BAD-30B3-429E-AE94-6930C86194DA does not exist in cassandra table\n",
      "C81E493B-D6F0-4C13-A48E-C4564E8A1B6D does not exist in cassandra table\n",
      "39CBE180-96A7-4068-80F5-A838DD99C767 does not exist in cassandra table\n",
      "3D49F5AD-0A3B-421E-8A9E-87A327857720 does not exist in cassandra table\n",
      "A7B7804B-05BE-42A9-B297-E4F814F75EDB does not exist in cassandra table\n",
      "6371C6F5-C1CE-411A-88BF-A2DE74E4297D does not exist in cassandra table\n",
      "9808ECAC-36A8-464E-9A15-17590024EC25 does not exist in cassandra table\n",
      "60DACE34-0C87-4C0B-A999-2559E32327EB does not exist in cassandra table\n",
      "33277A9D-0553-43AE-AC05-E32BE984233B does not exist in cassandra table\n",
      "FB4046C1-5A99-43DC-BBA8-6C53B67CEAE7 does not exist in cassandra table\n",
      "D7714ADF-4247-4566-B905-3CAE8D222D86 does not exist in cassandra table\n",
      "90BA3656-C029-4D2F-8CF2-025490DB362D does not exist in cassandra table\n",
      "837AB6B5-A5DC-4AFB-BB29-DBA1ABC7496B does not exist in cassandra table\n",
      "53935781-EE0D-4DEC-8311-997E13F84499 does not exist in cassandra table\n",
      "B49FB238-5335-4084-827D-05EA6987F632 does not exist in cassandra table\n",
      "D3E9EC83-4477-473E-924E-96B1F82DAC81 does not exist in cassandra table\n",
      "DB90A9B3-DC95-4B5A-8DF0-FD4F5377C31D does not exist in cassandra table\n",
      "4A619CA9-C770-45DB-982C-4A1A100E545F does not exist in cassandra table\n",
      "07E31309-135F-4B42-AE0A-103CD6B88958 does not exist in cassandra table\n",
      "D166131D-F005-46A4-915B-424ED76E73CC does not exist in cassandra table\n",
      "DEBE5193-45CD-4433-A307-4498573130B9 does not exist in cassandra table\n",
      "ACE6B82E-7F1D-46D7-B376-55B1CDE3494B does not exist in cassandra table\n",
      "D4FE983A-EBD7-4447-AC6E-00CF6D1AB8D4 does not exist in cassandra table\n",
      "BA0F3D53-4E10-44C9-82E2-2C0D5CE0E96C does not exist in cassandra table\n",
      "82B58402-CC40-4C52-9E3F-E16914DB6405 does not exist in cassandra table\n",
      "1C2EE7BD-EB0B-45DE-B7B4-3B0996FFA475 does not exist in cassandra table\n",
      "DAA08E04-00F1-43D0-BAB1-14D80AFE62CC does not exist in cassandra table\n",
      "0106CA10-5C53-432F-A912-954AD6A4CEA3 does not exist in cassandra table\n",
      "AF544C2B-5F55-44A2-BD58-2E375E9E6FF3 does not exist in cassandra table\n",
      "1167B376-3DC1-422B-8EBE-906127CD0668 does not exist in cassandra table\n",
      "9FF16EAC-7CA1-47F7-A79F-8092511D1834 does not exist in cassandra table\n",
      "AE568824-4A96-4353-B48E-9ECCAFAF60E1 does not exist in cassandra table\n",
      "query for bug_reports of wisdom, 2019, driver has completed\n",
      "query for feature_pools of wisdom, 2019, driver has completed\n",
      "63968859-21CD-49E2-9605-9BCCCAA8C311 does not exist in cassandra table\n",
      "D2A8F0C3-D994-440E-B0F6-49138151E962 does not exist in cassandra table\n",
      "query for bug_reports of wisdom, 2019, eats has completed\n",
      "query for feature_pools of wisdom, 2019, eats has completed\n",
      "ED44D1C8-59C5-401A-9D03-3954AA8F0B83 does not exist in cassandra table\n",
      "A11E1D52-FE69-4AA5-BF23-6FE5F47596D7 does not exist in cassandra table\n",
      "C5693621-0552-4C0B-B1B4-8DD6D8FBCD6D does not exist in cassandra table\n",
      "12B90E35-C52D-4F0D-99CA-5CE5D863BE37 does not exist in cassandra table\n",
      "45EBA1D1-F7E4-4076-BC80-9A35A3F50780 does not exist in cassandra table\n",
      "597B1A8C-1EFD-4930-A563-23B83675DBBF does not exist in cassandra table\n",
      "28FABFBE-4F19-4C97-B049-DC9836180595 does not exist in cassandra table\n",
      "AB4DD753-4D4D-47CC-A238-D7ED3FF99068 does not exist in cassandra table\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Generate random pairs that are not duplicated as contrast training data\n",
    "def get_random_pairs(report_ids, dup_pairs, n_random_samples, random_seed=7):\n",
    "    random.seed(random_seed)\n",
    "    random_pairs_set = set()\n",
    "    df = pd.DataFrame(dup_pairs)\n",
    "    while len(random_pairs_set) < n_random_samples:\n",
    "        p = random.sample(set(report_ids), 2)\n",
    "        if (df[(df[0] == p[0]) & (df[1] == p[1])].empty) and (df[(df[1] == p[0]) & (df[0] == p[1])].empty):\n",
    "            random_pairs_set.add(frozenset(p))\n",
    "            \n",
    "    random_pairs = [list(random_pair) for random_pair in random_pairs_set]\n",
    "    \n",
    "    return random_pairs\n",
    "\n",
    "def get_report_id_to_features(elk_result):\n",
    "    report_id_to_features = {}\n",
    "    for task in elk_result.keys():\n",
    "        for year in elk_result[task].keys():\n",
    "            for app in elk_result[task][year].keys():\n",
    "                report_ids = elk_result[task][year][app]['report_ids']\n",
    "\n",
    "                bug_reports = wisdom_cassandra_client.get_bug_reports(report_ids, False)\n",
    "                print('query for bug_reports of {0}, {1}, {2} has completed'.format(task, year, app))\n",
    "                feature_pools = wisdom_cassandra_client.get_report_feature_pools(report_ids, False)\n",
    "                print('query for feature_pools of {0}, {1}, {2} has completed'.format(task, year, app))\n",
    "\n",
    "                bug_reports_dict = {bug_report.report_uuid.upper(): bug_report for bug_report in bug_reports}\n",
    "                feature_pool_dict = {feature_pool.report_id.upper(): feature_pool for feature_pool in feature_pools}\n",
    "\n",
    "                features = dict()\n",
    "                for report_id in report_ids:\n",
    "                    report_id = report_id.upper()\n",
    "                    try:\n",
    "                        bug_report = bug_reports_dict[report_id]\n",
    "                        feature_pool = feature_pool_dict[report_id]\n",
    "                        features[report_id.upper()] = {'bug_report': bug_report, 'feature_pool': feature_pool}\n",
    "                    except:\n",
    "                        if task == 'wisdom':\n",
    "                            print(report_id + ' does not exist in cassandra table')\n",
    "                            \n",
    "                valid_report_ids = features.keys()\n",
    "                dup_pairs = []\n",
    "                for pair in elk_result[task][year][app]['pairs']:\n",
    "                    if pair[0] in valid_report_ids and pair[1] in valid_report_ids:\n",
    "                        dup_pairs.append(pair)\n",
    "\n",
    "                elk_result[task][year][app]['dup_pairs'] = dup_pairs\n",
    "                elk_result[task][year][app]['random_pairs'] = get_random_pairs(valid_report_ids, dup_pairs, \\\n",
    "                                                                               len(dup_pairs) * 30)\n",
    "                \n",
    "                elk_result[task][year][app]['features'] = features\n",
    "                report_id_to_features.update(features)\n",
    "\n",
    "    return report_id_to_features\n",
    "\n",
    "report_id_to_features = get_report_id_to_features(elk_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tokenizer to the text feature by doing the several following things\n",
    "\n",
    "- Remove the stop words\n",
    "- Change the word to its original form (lemmatization)\n",
    "- Add a synonyms map, this is useful as in many cases, `hyperlink` means exactly as `url` and since we are not using large models for extracting these features, these rules can be encoded by ourselves by doing failure analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<__main__.LemmaTokenizer object at 0x7fd3a76800b8>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.vocab[\"not\"].is_stop = False\n",
    "\n",
    "with open('synonyms.json', 'rb') as f:\n",
    "    synonyms_dict = json.load(f)\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self, synonyms_dict):\n",
    "        self.synonyms_dict = synonyms_dict\n",
    "    def __call__(self, doc):\n",
    "        words = []\n",
    "        for token in nlp(doc):\n",
    "            if not token.is_stop:\n",
    "                words.append(self.synonyms_dict.get(token.lemma_, token.lemma_))\n",
    "                if token.pos_ == 'NUM':\n",
    "                    words.append('number')\n",
    "        return [self.synonyms_dict.get(token.lemma_, token.lemma_) for token in nlp(doc) if not token.is_stop]\n",
    "    \n",
    "lemma_tokenizer = LemmaTokenizer(synonyms_dict)\n",
    "\n",
    "def xstr(s):\n",
    "    return '' if s is None else str(s)\n",
    "\n",
    "titles = list(filter(lambda x: x is not None, [xstr(v['feature_pool'].title) + ' ' + \n",
    "                                               xstr(v['feature_pool'].description)\n",
    "                                               for v in report_id_to_features.values()]))\n",
    "tfidf = TfidfVectorizer(tokenizer=lemma_tokenizer)\n",
    "tfidf.fit(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reimplementing the Java feature extrator using Python which already has,\n",
    "\n",
    "- text ngram feature\n",
    "- Feature desc feature\n",
    "- Image hash feature\n",
    "- If app version major.minor is matched\n",
    "- If two reports are created in the same minute, or in the same hour\n",
    "- If two reports are from the same city\n",
    "- If two reports has the same locale\n",
    "- If two reports has the same device\n",
    "\n",
    "\n",
    "### At the same time, I was also adding a few more features\n",
    "\n",
    "- Diff score for the analytics logs (levenstein distance after deduping along the sequence)\n",
    "- Diff score for the network logs (levenstein distance after deduping along the sequence)\n",
    "- If two logs has the same `build_id`\n",
    "- If two logs has the same `category_id`\n",
    "- TfIdf feature for title. Before it was vectorized, several preprocessing was done\n",
    "    - Remove the stop words\n",
    "    - Lemmatization for words\n",
    "    - Replacing the synonyms with a user (me!) defined dictionary\n",
    "    - If numbers are detected, add `number` to the sentence for calculating tfidf\n",
    "    \n",
    "    This is used for handling case \n",
    "        e.g: \n",
    "        ```\n",
    "        1. Booking two seats on uberpool but only one booked for driver\n",
    "        2. Wrong Number of Riders on Pool Request\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bert_serving.client import BertClient\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, report_id_to_features):\n",
    "        self.report_id_to_features = report_id_to_features\n",
    "        self.features = ['feature_desc', 'title_desc_tfidf', 'image_hash', 'app_version', 'device', \n",
    "                         'os_version', 'time_diff', 'city', 'locale', 'analytics_logs', 'network_logs', 'build_id', \n",
    "                         'experiments_failure']\n",
    "        \n",
    "    def get_pairwise_feature(self, report_id_1, report_id_2):\n",
    "        feature_pool_1 = self._get_feature_pool(report_id_1)\n",
    "        feature_pool_2 = self._get_feature_pool(report_id_2)\n",
    "        \n",
    "        # bug reports contain features that does not entailed in the feature pool right now, including the logs\n",
    "        bug_report_1 = self._get_bug_report(report_id_1)\n",
    "        bug_report_2 = self._get_bug_report(report_id_2)\n",
    "        \n",
    "        sims = []\n",
    "        self._add_feature_desc_feature(feature_pool_1, feature_pool_2, sims)\n",
    "        self._add_title_desc_tfidf_feature(bug_report_1, bug_report_2, sims)\n",
    "        self._add_image_hash_feature(feature_pool_1, feature_pool_2, sims)\n",
    "        self._add_app_version_feature(feature_pool_1, feature_pool_2, sims)\n",
    "        self._add_device_feature(feature_pool_1, feature_pool_2, sims)\n",
    "        self._add_os_version_feature(feature_pool_1, feature_pool_2, sims)\n",
    "        self._add_time_diff_feature(feature_pool_1, feature_pool_2, sims)\n",
    "        self._add_same_city_feature(feature_pool_1, feature_pool_2, sims)\n",
    "        self._add_same_locale_feature(feature_pool_1, feature_pool_2, sims)\n",
    "        self._add_analytics_logs_feature(bug_report_1, bug_report_2, sims)\n",
    "        self._add_network_logs_feature(bug_report_1, bug_report_2, sims)\n",
    "        self._add_build_id_feature(bug_report_1, bug_report_2, sims)\n",
    "        self._add_experiments_feature(bug_report_1, bug_report_2, sims)\n",
    "        \n",
    "        return np.array(sims)\n",
    "        \n",
    "    def get_text_bert_feature(self, feature_pool):        \n",
    "        title = feature_pool.title\n",
    "        if title.strip() == '':\n",
    "            title = '.'\n",
    "            \n",
    "        description = feature_pool.description\n",
    "        if description.strip() == '':\n",
    "            description = '.' \n",
    "            \n",
    "        vec = np.concatenate(self.bc.encode([title + ' ' + description]))\n",
    "\n",
    "        return vec    \n",
    "    \n",
    "    def get_bert_title_feature(self, report_id):\n",
    "        title = feature_pool.title\n",
    "        if title.strip() == '':\n",
    "            title = '.'\n",
    "        \n",
    "        return np.concatenate(self.bc.encode([title]))\n",
    "    \n",
    "    def _get_feature_pool(self, report_id):\n",
    "        return self.report_id_to_features[report_id.upper()]['feature_pool']\n",
    "    \n",
    "    def _get_bug_report(self, report_id):\n",
    "        return self.report_id_to_features[report_id.upper()]['bug_report']\n",
    "        \n",
    "    def _add_image_hash_feature(self, feature_pool_1, feature_pool_2, sims):\n",
    "        sims = []\n",
    "        sims.append(hamming(feature_pool_1.screenshot_hash_avg, feature_pool_2.screenshot_hash_avg))\n",
    "        sims.append(hamming(feature_pool_1.screenshot_hash_diff, feature_pool_2.screenshot_hash_diff))\n",
    "        sims.append(hamming(feature_pool_1.screenshot_hash_perception, feature_pool_2.screenshot_hash_perception))\n",
    "        \n",
    "        return sims\n",
    "    \n",
    "    def _add_build_id_feature(self, bug_report_1, bug_report_2, sims):\n",
    "        def get_build_uuid(bug_report):\n",
    "            try:\n",
    "                build_uuid = bug_report_1.meta.app.build_uuid\n",
    "            except:\n",
    "                build_uuid = ''\n",
    "                \n",
    "            return build_uuid\n",
    "        \n",
    "        sims.append(1.0 if get_build_uuid(bug_report_1) == get_build_uuid(bug_report_2) else 0.0)\n",
    "    \n",
    "    def _add_app_version_feature(self, feature_pool_1, feature_pool_2, sims):\n",
    "        new_sims = [0.0, 0.0]\n",
    "        app_ver_1, app_ver_2 = feature_pool_1.app_version, feature_pool_2.app_version\n",
    "        if app_ver_1 is not None and app_ver_2 is not None and len(app_ver_1) == len(app_ver_2) == 3:\n",
    "            if app_ver_1[0] == app_ver_2[0] and app_ver_1[1] == app_ver_2[1]:\n",
    "                new_sims[0] = 1.0\n",
    "                if app_ver_1[2] == app_ver_2[2]:\n",
    "                    new_sims[1] = 1.0\n",
    "\n",
    "        sims.extend(new_sims)\n",
    "\n",
    "    def _add_device_feature(self, feature_pool_1, feature_pool_2, sims):\n",
    "        dev_1, dev_2 = feature_pool_1.device_model, feature_pool_2.device_model\n",
    "        if dev_1 is None or dev_2 is None:\n",
    "            if dev_1 is None and dev_2 is None:\n",
    "                sims.append(1.0)\n",
    "            else:\n",
    "                sims.append(0.0)\n",
    "        else:\n",
    "            sims.append(1.0 if dev_1 == dev_2 else 0.0)\n",
    "\n",
    "    def _add_os_version_feature(self, feature_pool_1, feature_pool_2, sims):\n",
    "        os_1, os_2 = feature_pool_1.os_version, feature_pool_2.os_version\n",
    "        if (os_1 is not None and os_2 is not None) and len(os_1) == len(os_2) == 2:\n",
    "            sims.append(1.0 if os_1[0] == os_2[0] and os_1[1] == os_2[1] else 0.0)\n",
    "        else:\n",
    "            sims.append(0.0)\n",
    "                \n",
    "    def _add_time_diff_feature(self, feature_pool_1, feature_pool_2, sims):        \n",
    "        t1, t2 = feature_pool_1.created_at, feature_pool_2.created_at\n",
    "        seconds_diff = abs(t1 - t2).seconds\n",
    "        # if in the same minute\n",
    "        sims.append(1.0 if seconds_diff < 60 else 0.0)\n",
    "        # if in the same hour\n",
    "        sims.append(1.0 if seconds_diff / 3600.0 < 1 else 0.0)\n",
    "        \n",
    "    def _add_text_bert_sim(self, feature_pool_1, feature_pool_2, sims):\n",
    "        vecs = list(map(self.get_text_bert_feature, [feature_pool_1, feature_pool_2]))\n",
    "        \n",
    "        sims.append(self._get_cosine_similarity(vecs[0], vecs[1]))\n",
    "        \n",
    "    def _get_cosine_similarity(self, vec_1, vec_2):\n",
    "        print(vec_1, vec_2)\n",
    "        return cosine_similarity([vec_1], [vec_2])[0][0]\n",
    "        \n",
    "    def _add_text_ngram_feature(self, feature_pool_1, feature_pool_2, sims):\n",
    "        sims.append(self._jaccard_similarity(self._get_ngram_union(feature_pool_1), \\\n",
    "                                             self._get_ngram_union(feature_pool_2)))\n",
    "        \n",
    "    def _add_title_desc_tfidf_feature(self, feature_pool_1, feature_pool_2, sims):\n",
    "        s1, s2 = map(lambda fp: xstr(fp.title) + ' ' + xstr(fp.description), \n",
    "                     [feature_pool_1, feature_pool_2])\n",
    "        \n",
    "        tfidf_vectors = tfidf.transform([s1, s2])\n",
    "        sim = cosine_similarity(tfidf_vectors)[0, 1]\n",
    "        \n",
    "        sims.append(sim)\n",
    "        \n",
    "    def _add_feature_desc_feature(self, feature_pool_1, feature_pool_2, sims):\n",
    "        x = self._preprocess_ngram(feature_pool_1.feature_descr_tf_ngram)\n",
    "        y = self._preprocess_ngram(feature_pool_2.feature_descr_tf_ngram)\n",
    "        \n",
    "        sims.append(self._jaccard_similarity(x, y))\n",
    "        \n",
    "    def _add_same_city_feature(self, feature_pool_1, feature_pool_2, sims):\n",
    "        sims.append(1.0 if feature_pool_1.city_id == feature_pool_2.city_id else 0.0)\n",
    "        \n",
    "    def _add_same_locale_feature(self, feature_pool_1, feature_pool_2, sims):\n",
    "        sims.append(1.0 if feature_pool_1.locale == feature_pool_2.locale else 0)\n",
    "        \n",
    "    def _add_analytics_logs_feature(self, bug_report_1, bug_report_2, sims):\n",
    "        \"\"\"\n",
    "        This feature is to add editdistance score of analytics logs after deduping each individual log along the sequence,\n",
    "        the deduping was made such that the order of the sequence will be kept\n",
    "        \n",
    "        e.g\n",
    "        \n",
    "        aaaabbbccd -> abcd\n",
    "        \"\"\"\n",
    "        # keep the order\n",
    "        to_unique_log = lambda bug_report: pd.unique([log.name.lower() \n",
    "                                                      for log in (bug_report.analytics_logs\n",
    "                                                     if bug_report.analytics_logs is not None else [])]).tolist()\n",
    "        unique_logs_1, unique_logs_2 = to_unique_log(bug_report_1), to_unique_log(bug_report_2)\n",
    "        \n",
    "        score = 0.0\n",
    "        if len(unique_logs_1) == 0 and len(unique_logs_2) == 0:\n",
    "            sims.append(score)\n",
    "            return\n",
    "        score = editdistance.eval(unique_logs_1, unique_logs_2) * 1.0 / max(len(unique_logs_1), len(unique_logs_2))\n",
    "\n",
    "        sims.append(score)\n",
    "\n",
    "    def _add_network_logs_feature(self, bug_report_1, bug_report_2, sims):\n",
    "        \"\"\"\n",
    "        Same as analytics log, `endpoint_path:status_code` was used for each individual log term\n",
    "        \"\"\"\n",
    "        # keep the order\n",
    "        to_unique_log = lambda bug_report: pd.unique([log.endpoint_path.lower() if log.endpoint_path else '' \n",
    "                                                      + str(log.status_code) if log.status_code else ''\n",
    "                                                      for log in (bug_report.network_logs\n",
    "                                                     if bug_report.network_logs is not None else [])]).tolist()\n",
    "        unique_logs_1, unique_logs_2 = to_unique_log(bug_report_1), to_unique_log(bug_report_2)\n",
    "\n",
    "        score = 0.0\n",
    "        if len(unique_logs_1) == 0 and len(unique_logs_2) == 0:\n",
    "            sims.append(score)\n",
    "            return\n",
    "        score = editdistance.eval(unique_logs_1, unique_logs_2) * 1.0 / max(len(unique_logs_1), len(unique_logs_2))\n",
    "\n",
    "        sims.append(score)\n",
    "        \n",
    "    def _add_experiments_feature(self, bug_report_1, bug_report_2, sims):\n",
    "        \"\"\"\n",
    "        This feature was to identify the percentage of similarity in experiments between every two logs\n",
    "        \n",
    "        \"\"\"\n",
    "        def _get_experiments(bug_report):\n",
    "            exp_dict = {}\n",
    "            experiments = [] if bug_report.experiments is None else bug_report.experiments\n",
    "            for exp in experiments:\n",
    "                exp_dict[exp.name] = exp.group\n",
    "            \n",
    "            return exp_dict\n",
    "        \n",
    "        exp_dict_1 = _get_experiments(bug_report_1)\n",
    "        exp_dict_2 = _get_experiments(bug_report_2)\n",
    "        \n",
    "        same_count = 0\n",
    "        common_exps = set(exp_dict_1.keys()).intersection(exp_dict_2.keys())\n",
    "        \n",
    "        if len(common_exps) == 0:\n",
    "            sims.append(1.0)\n",
    "            return\n",
    "        \n",
    "        for exp_name in common_exps:\n",
    "            same_count += (1.0 if exp_dict_1[exp_name] == exp_dict_2[exp_name] else 0.0)\n",
    "                        \n",
    "        sims.append(same_count / len(common_exps))\n",
    "\n",
    "    def _get_ngram_union(self, feature_pool):\n",
    "        \"\"\"\n",
    "        DEPRECATING!\n",
    "        \n",
    "        Get the bag of union words, used by the previous model, maybe replaced with tfidf vector or language model \n",
    "        in the future\n",
    "        \"\"\"\n",
    "        \n",
    "        text_tf_ngram = self._preprocess_ngram(feature_pool.text_tf_ngram)\n",
    "        title_tf_ngram = self._preprocess_ngram(feature_pool.title_tf_ngram)\n",
    "        \n",
    "        bag_of_words = set()\n",
    "        for ngram in [text_tf_ngram, title_tf_ngram]:\n",
    "            bag_of_words = bag_of_words.union(set(ngram))\n",
    "            \n",
    "        bag_of_words = [word.lower() for word in bag_of_words]\n",
    "        \n",
    "        return bag_of_words\n",
    "    \n",
    "    def _preprocess_ngram(self, ngram):\n",
    "        ngram = [gram for gram in (ngram if ngram is not None else [])]\n",
    "        \n",
    "        return ngram\n",
    "    \n",
    "    def _jaccard_similarity(self, x, y):\n",
    "        \"\"\"\n",
    "        Jaccard Similarity J (A,B) = | Intersection (A,B) | /\n",
    "                                        | Union (A,B) |\n",
    "        \"\"\"\n",
    "        if len(x) == 0 and len(y) == 0:\n",
    "            return 1.0\n",
    "        elif len(x) == 0 or len(y) == 0:\n",
    "            return 0.0\n",
    "        intersection_cardinality = len(set(x).intersection(set(y)))\n",
    "        union_cardinality = len(set(x).union(set(y)))\n",
    "        return intersection_cardinality / float(union_cardinality)\n",
    "\n",
    "feature_extractor = FeatureExtractor(report_id_to_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = feature_extractor._get_bug_report('D0A33AD5-6D1D-4BA1-A325-9C71227B152D')\n",
    "b = feature_extractor._get_bug_report('D159F4F9-DD98-4593-832F-2856D167288B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = feature_extractor._get_feature_pool('D159F4F9-DD98-4593-832F-2856D167288B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the training data from the feature extractor\n",
    "\n",
    "- All dup pairs have label 1, while all nondup random pairs have label 0\n",
    "- They are shuffled after these features are generated independenly for each `task:year:app` group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snap 2018 rider (9548, 14)\n",
      "snap 2018 driver (93, 14)\n",
      "snap 2019 rider (930, 14)\n",
      "snap 2019 driver (31, 14)\n",
      "wisdom 2019 rider (13888, 14)\n",
      "wisdom 2019 driver (31, 14)\n",
      "wisdom 2019 eats (744, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_training_data_from_feature_extractor(elk_result):\n",
    "    X_all, y_all = [], []\n",
    "    training_data = dict()\n",
    "    for task in elk_result.keys():\n",
    "        training_data[task] = dict()\n",
    "        for year in elk_result[task].keys():\n",
    "            training_data[task][year] = dict()\n",
    "            for app in elk_result[task][year].keys():\n",
    "\n",
    "                training_data[task][year][app] = dict()\n",
    "\n",
    "                X_positive_curr, X_negative_curr = [], []\n",
    "\n",
    "                dup_pairs = elk_result[task][year][app]['dup_pairs']\n",
    "                random_pairs = elk_result[task][year][app]['random_pairs']\n",
    "\n",
    "                for pair in dup_pairs:\n",
    "                    X_positive_curr.append(feature_extractor.get_pairwise_feature(pair[0], pair[1]))\n",
    "                for pair in random_pairs:\n",
    "                    X_negative_curr.append(feature_extractor.get_pairwise_feature(pair[0], pair[1]))\n",
    "\n",
    "                X_curr = np.array(X_positive_curr + X_negative_curr)\n",
    "                y_curr = np.concatenate([np.ones(len(X_positive_curr)), np.zeros(len(X_negative_curr))])\n",
    "\n",
    "                X_curr, y_curr, shuffled_pairs = shuffle(X_curr, y_curr, dup_pairs + random_pairs)\n",
    "                print(task, year, app, X_curr.shape)\n",
    "\n",
    "                training_data[task][year][app]['X'] = X_curr\n",
    "                training_data[task][year][app]['y'] = y_curr\n",
    "                training_data[task][year][app]['shuffled_pairs'] = shuffled_pairs\n",
    "\n",
    "                X_all.append(X_curr)\n",
    "                y_all.append(y_curr)\n",
    "\n",
    "    X_all = np.concatenate(X_all)\n",
    "    y_all = np.concatenate(y_all)\n",
    "    \n",
    "    return X_all, y_all, training_data\n",
    "\n",
    "X_all, y_all, training_data = get_training_data_from_feature_extractor(elk_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(frozenset(pair) for pair in elk_result['wisdom']['2019']['rider']['dup_pairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = set(frozenset(pair) for pair in elk_result['wisdom']['2019']['rider']['random_pairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozenset({'B6F3B553-2463-45A2-B5A5-1E54B035FC1D','704D3E76-3E83-4F3C-A393-60A6A0EA0FD2'\n",
    "            }) in s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozenset({'438AEE6E-E9FD-4972-B69B-2F92D92C31C3',\n",
    " 'A1AB750C-5255-4A3D-A469-031CE89AEB76'}) in s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the training_data into snap tickets and wisdom tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split wisdom and snaptask data\n",
    "def split_training_data_by_task(training_data):\n",
    "    X_snap, y_snap, snap_shuffled_pairs, X_wisdom_dict, y_wisdom_dict, wisdom_shuffled_pairs_dict = [], [], [], {}, {}, {}\n",
    "    for task in training_data.keys():\n",
    "        for year in training_data[task].keys():\n",
    "            for app in training_data[task][year].keys():\n",
    "                X = training_data[task][year][app]['X']\n",
    "                y = training_data[task][year][app]['y']\n",
    "                shuffled_pairs = training_data[task][year][app]['shuffled_pairs']\n",
    "                if task == 'snap':\n",
    "                    X_snap.append(X)\n",
    "                    y_snap.append(y)\n",
    "                    snap_shuffled_pairs.append(shuffled_pairs)\n",
    "                else:\n",
    "                    X_wisdom_dict[app] = X\n",
    "                    y_wisdom_dict[app] = y\n",
    "                    wisdom_shuffled_pairs_dict[app] = shuffled_pairs\n",
    "    \n",
    "    X_snap, y_snap, snap_shuffled_pairs = list(map(np.concatenate, [X_snap, y_snap, snap_shuffled_pairs]))\n",
    "    \n",
    "    return X_snap, y_snap, snap_shuffled_pairs, X_wisdom_dict, y_wisdom_dict, wisdom_shuffled_pairs_dict\n",
    "\n",
    "X_snap, y_snap, snap_shuffled_pairs, X_wisdom_dict, y_wisdom_dict, shuffled_pairs_dict = split_training_data_by_task(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(X_all[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = feature_extractor._get_feature_pool('D0A33AD5-6D1D-4BA1-A325-9C71227B152D')\n",
    "b = feature_extractor._get_feature_pool('D159F4F9-DD98-4593-832F-2856D167288B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_id = 'a69e70ce-e850-48d1-9e84-ccb85067a612'.upper()\n",
    "\n",
    "print(wisdom_cassandra_client.get_bug_report(report_id))\n",
    "print(wisdom_cassandra_client.get_report_feature_pool(report_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xtong/anaconda3/envs/wisdom-dedup-python/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning:\n",
      "\n",
      "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:   13.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score for rider: 0.81\n",
      "confusion matrix [[2673   14]\n",
      " [  35   56]]\n",
      "tn: 2673, fp: 14, fn: 35, tp: 56, precision: 0.8, recall: 0.6153846153846154\n",
      "Best parameters: {'subsample': 0.1, 'scale_pos_weight': 3.7, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 3, 'colsample_bytree': 0.2}\n",
      "Best cross-validation score: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.975831\n",
       "1    0.975832\n",
       "2    0.975871\n",
       "3    0.977567\n",
       "4    0.977844\n",
       "5    0.977646\n",
       "6    0.975943\n",
       "7    0.978590\n",
       "8    0.978299\n",
       "9    0.977534\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score for driver: 0.97\n",
      "confusion matrix [[28  2]\n",
      " [ 0  1]]\n",
      "tn: 28, fp: 2, fn: 0, tp: 1, precision: 0.3333333333333333, recall: 1.0\n",
      "Best parameters: {'subsample': 0.1, 'scale_pos_weight': 3.7, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 3, 'colsample_bytree': 0.2}\n",
      "Best cross-validation score: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.975831\n",
       "1    0.975832\n",
       "2    0.975871\n",
       "3    0.977567\n",
       "4    0.977844\n",
       "5    0.977646\n",
       "6    0.975943\n",
       "7    0.978590\n",
       "8    0.978299\n",
       "9    0.977534\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score for eats: 0.86\n",
      "confusion matrix [[672  48]\n",
      " [  5  19]]\n",
      "tn: 672, fp: 48, fn: 5, tp: 19, precision: 0.2835820895522388, recall: 0.7916666666666666\n",
      "Best parameters: {'subsample': 0.1, 'scale_pos_weight': 3.7, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 3, 'colsample_bytree': 0.2}\n",
      "Best cross-validation score: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.975831\n",
       "1    0.975832\n",
       "2    0.975871\n",
       "3    0.977567\n",
       "4    0.977844\n",
       "5    0.977646\n",
       "6    0.975943\n",
       "7    0.978590\n",
       "8    0.978299\n",
       "9    0.977534\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.2, gamma=3,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=3.7, seed=None,\n",
       "              silent=None, subsample=0.1, verbosity=1)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import display\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# SETTINGS - CHANGE THESE TO GET SOMETHING MEANINGFUL\n",
    "ITERATIONS = 10 # 1000\n",
    "TRAINING_SIZE = 100000 # 20000000\n",
    "TEST_SIZE = 25000\n",
    "\n",
    "\n",
    "random.seed(7)\n",
    "np.random.seed(7)\n",
    "\n",
    "FOLDS = 5\n",
    "PARAM_COMB = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle = True, random_state = 1001)\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "    'min_child_weight': [5, 10],\n",
    "    'gamma': [3, 5],\n",
    "    'subsample': [0.1],\n",
    "    'colsample_bytree': [0.6, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'scale_pos_weight': [3.7]\n",
    "}\n",
    "\n",
    "model = RandomizedSearchCV(\n",
    "    xgb.XGBClassifier(learning_rate=0.02, \n",
    "                      n_estimators=600, \n",
    "                      objective='binary:logistic',\n",
    "                      silent=True,\n",
    "                      nthread=1), \n",
    "    param_distributions=params,\n",
    "    n_iter=50,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=4,\n",
    "    verbose=3)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "!!!\n",
    "\"\"\"\n",
    "X_train_wisdom_rider, X_test_wisdom_rider, y_train_wisdom_rider, y_test_wisdom_rider, _, shuffled_pairs_test_wisdom_rider = train_test_split(X_wisdom_dict['rider'], y_wisdom_dict['rider'], \n",
    "                                                                            shuffled_pairs_dict['rider'], \n",
    "                                                                            test_size=0.2, random_state=1)\n",
    "\n",
    "X_train = np.concatenate([X_snap, X_train_wisdom_rider])\n",
    "y_train = np.concatenate([y_snap, y_train_wisdom_rider])\n",
    "\n",
    "X_train, y_train = X_train_wisdom_rider, y_train_wisdom_rider\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "failure_analysis = dict()\n",
    "for app in X_wisdom_dict.keys():\n",
    "    if app == 'rider':\n",
    "        X_test = X_test_wisdom_rider\n",
    "        y_test = y_test_wisdom_rider\n",
    "        shuffled_pairs_test = shuffled_pairs_test_wisdom_rider\n",
    "    else:\n",
    "        X_test = X_wisdom_dict[app]\n",
    "        y_test = y_wisdom_dict[app]\n",
    "        shuffled_pairs_test = shuffled_pairs_dict[app]\n",
    "                \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Test set score for {}: {:.2f}\".format(app, roc_auc_score(y_test, y_pred)))\n",
    "    con_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    fp_indices = np.where((y_test == 0) & (y_pred == 1))[0]\n",
    "    fn_indices = np.where((y_test == 1) & (y_pred == 0))[0]\n",
    "\n",
    "    tn, fp, fn, tp = con_matrix.ravel()\n",
    "    print('confusion matrix', con_matrix)\n",
    "    print('tn: {}, fp: {}, fn: {}, tp: {}, precision: {}, recall: {}'.format(tn, fp, fn, tp, tp*1.0/(tp+fp), tp*1.0/(tp+fn)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_titles(shuffled_pairs_test, indices):\n",
    "        titles = []\n",
    "        for index in indices:\n",
    "            bug_reports = [feature_extractor._get_bug_report(report_id) for report_id in shuffled_pairs_test[index]]\n",
    "            titles.append(list(map(lambda b: b.report_uuid.lower(), bug_reports)))\n",
    "            titles.append(list(map(lambda b: b.title, bug_reports)))\n",
    "            titles.append(list(map(lambda b: b.description, bug_reports)))\n",
    "        return pd.DataFrame(titles)\n",
    "\n",
    "    fn_titles = get_titles(shuffled_pairs_test, fn_indices)\n",
    "    fp_titles = get_titles(shuffled_pairs_test, fp_indices)\n",
    "    \n",
    "    failure_analysis[app] = {'fn_titles': fn_titles, 'fp_titles': fp_titles}\n",
    "\n",
    "    print(\"Best parameters: {}\".format(model.best_params_))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(model.best_score_))\n",
    "    results = pd.DataFrame(model.cv_results_)\n",
    "    display(results.mean_test_score)\n",
    "\n",
    "    \n",
    "# rebuild a model on the train\n",
    "best_model = xgb.XGBClassifier(**model.best_params_)\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "bar",
         "x": [
          "feature_desc",
          "title_desc_tfidf",
          "image_hash",
          "app_version",
          "device",
          "os_version",
          "time_diff",
          "city",
          "locale",
          "analytics_logs",
          "network_logs",
          "build_id",
          "experiments_failure"
         ],
         "xaxis": "x",
         "y": [
          0.28227636218070984,
          0.18050873279571533,
          0.08649349212646484,
          0.06758773326873779,
          0.03265049681067467,
          0.047356873750686646,
          0,
          0.01998576521873474,
          0.058707643300294876,
          0.05348137766122818,
          0.053797513246536255,
          0.044008683413267136,
          0,
          0.07314528524875641
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.4305,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.2805
         ]
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"c4698841-8494-4b3a-8eea-ba9a465f9812\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"c4698841-8494-4b3a-8eea-ba9a465f9812\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'c4698841-8494-4b3a-8eea-ba9a465f9812',\n",
       "                        [{\"type\": \"bar\", \"x\": [\"feature_desc\", \"title_desc_tfidf\", \"image_hash\", \"app_version\", \"device\", \"os_version\", \"time_diff\", \"city\", \"locale\", \"analytics_logs\", \"network_logs\", \"build_id\", \"experiments_failure\"], \"xaxis\": \"x\", \"y\": [0.28227636218070984, 0.18050873279571533, 0.08649349212646484, 0.06758773326873779, 0.03265049681067467, 0.047356873750686646, 0.0, 0.01998576521873474, 0.058707643300294876, 0.05348137766122818, 0.053797513246536255, 0.044008683413267136, 0.0, 0.07314528524875641], \"yaxis\": \"y\"}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.4305, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.2805]}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c4698841-8494-4b3a-8eea-ba9a465f9812');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chart_studio.plotly import plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "importances = best_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    row_heights=[0.67, 0.33],\n",
    "    start_cell=\"top-left\")\n",
    "\n",
    "fig.add_bar(x=feature_extractor.features, y=importances, row=1, col=1)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
