{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa18879",
   "metadata": {},
   "source": [
    "# <h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import Requirements\" data-toc-modified-id=\"Import-Requirements-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Requirements</a></span></li><li><span><a href=\"#Prepare Training Data\" data-toc-modified-id=\"Prepare-Training-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prepare Training Data</a></span><ul class=\"toc-item\"></ul></li><li><span><a href=\"#Model Training\" data-toc-modified-id=\"Model Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Training</a></span></li><li><span><a href=\"#Model Saving\" data-toc-modified-id=\"Model Saving-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model Saving</a></span><ul class=\"toc-item\"></ul></li><li><span><a href=\"#Validation and Results\" data-toc-modified-id=\"Validation and Results-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Validation and Results</a></span><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe6d0d",
   "metadata": {},
   "source": [
    "<a id='Import Requirements'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971b37a",
   "metadata": {},
   "source": [
    "# Import Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca994c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb98b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('max_rows',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4342ccbd",
   "metadata": {},
   "source": [
    "<a id='Prepare Training Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4230c",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0d0ec",
   "metadata": {},
   "source": [
    "Input data for training consists of both historical data and CICD data( Production run data for which manual agent validation has been done for the ML prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322e3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(message):\n",
    "\n",
    "    #stopwords\n",
    "    new_stopwords=['default']\n",
    "    stpwrd = nltk.corpus.stopwords.words('english')\n",
    "    stpwrd.extend(new_stopwords)\n",
    "    # 1. Init Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #lowering and removing punctuation\n",
    "    #lowering and removing punctuation\n",
    "    message = re.sub(r'[^\\w\\s]','', message.lower())\n",
    "    #removing the numerical values and working only with text values\n",
    "    message = re.sub('[^a-zA-Z]', \" \", message )\n",
    "    #removing extra spaces\n",
    "    message=re.sub(' +', ' ',message)\n",
    "    #removing the stopwords\n",
    "    message = ' '.join([word for word in message.split() if word not in stpwrd and len(word)>2])\n",
    "    message1 = [lemmatizer.lemmatize(w) for w in nltk.word_tokenize(message) if w not in string.punctuation]\n",
    "    #lemmatizing the text\n",
    "    message2 =  \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(message) if w not in string.punctuation])\n",
    "    #print(\"message is : \",message)\n",
    "\n",
    "    return message1,message2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e4a91f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(553860, 8)\n",
      "(89928, 5)\n",
      "(79442, 5)\n",
      "(79442, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#read input from cicd data into dataframe\n",
    "data_cicd=pd.read_csv('../data/Old Records Prod TaxML Restaurant-CICD - Prod_Data.csv', usecols = ['Item','Description','establishment_type','Confidence Score','Agent Corrected CAT Name', 'Agent Corrected Integer','CAT NAME_ ValidationScore [0-100]','Integer_ValidationScore[0-100]'])\n",
    "print(data_cicd.shape)\n",
    "#low conf and correcr predicted data\n",
    "#data_cicd_low_conf=data_cicd[(data_cicd['Confidence Score']<=1)]\n",
    "#data_cicd_low_conf=data_cicd_low_conf[(data_cicd_low_conf['CAT NAME_ ValidationScore [0-100]']==0) &(data_cicd_low_conf['Integer_ValidationScore[0-100]']==0)]\n",
    "#misclassified data                                        \n",
    "data_cicd_misclassification=data_cicd[(data_cicd['CAT NAME_ ValidationScore [0-100]']!=100) &(data_cicd['Integer_ValidationScore[0-100]']!=100)]\n",
    "data_cicd_latest=data_cicd_misclassification\n",
    "data_cicd_latest=data_cicd_latest[['Item','Description','establishment_type','Agent Corrected CAT Name', 'Agent Corrected Integer']]\n",
    "#remove empty rows from dataframe\n",
    "data_cicd_latest.dropna(how='all',inplace=True)\n",
    "#remove rows having empty 'Agent Corrected CAT Name', ''Agent Corrected Integer'\n",
    "data_cicd_latest.dropna(subset=['Agent Corrected CAT Name', 'Agent Corrected Integer'],inplace=True)\n",
    "#removing all duplicate rows\n",
    "data_cicd_latest=data_cicd_latest.drop_duplicates(subset=['Item','establishment_type','Agent Corrected CAT Name', 'Agent Corrected Integer'],keep='first')\n",
    "print(data_cicd_latest.shape)\n",
    "#fresh data of cicd\n",
    "data_cicd_without_duplicate=data_cicd_latest.drop_duplicates(subset=['Item','establishment_type'],keep=False)\n",
    "print(data_cicd_without_duplicate.shape)\n",
    "#append two dataframe\n",
    "data_cicd_final=data_cicd_without_duplicate\n",
    "#creat target string which will be used for prediction \n",
    "data_cicd_final['target']= data_cicd_final['Agent Corrected CAT Name'] + \":\" + data_cicd_final['Agent Corrected Integer']\n",
    "print(data_cicd_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767be0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "data_cicd['combined_text'] = data_cicd[['Item','Description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "\n",
    "# apply data preprocessing steps on the prepared column\n",
    "data_cicd['processed_text']= data_cicd['combined_text'].map(lambda s:preprocess_text(s)[1]) \n",
    "\n",
    "data_cicd = data_cicd.reset_index(drop=True)\n",
    "# prepare the target column by combining 'Agent Corrected CAT Name' and 'Agent Corrected Integer'\n",
    "data_cicd['target']= data_cicd['Agent Corrected CAT Name'] + \":\" + data_cicd['Agent Corrected Integer']\n",
    "\n",
    "#remove rows having empty target column\n",
    "data_cicd.dropna(subset=['target'],inplace=True)\n",
    "\n",
    "data_cicd = data_cicd[data_cicd['target']!= '#REF!:#REF!']\n",
    "\n",
    "X_cicd= data_cicd[['Item','Description','establishment_type','processed_text']]\n",
    "y_cicd= data_cicd['target']\n",
    "\n",
    "# split the cicd data into train and test \n",
    "X_train_cicd, X_test_cicd, y_train_cicd, y_test_cicd = train_test_split(X_cicd, y_cicd, test_size =.01, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a549eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100820, 4)\n",
      "(100820, 6)\n",
      "(91447, 6)\n"
     ]
    }
   ],
   "source": [
    "#read input from historical data into dataframe\n",
    "data_df = pd.read_csv('../data/final_historical_data.csv', encoding='utf8',engine='python',usecols=['Item','Description','establishment_type','target'])\n",
    "#choose sample data from entire data\n",
    "data_df = data_df.sample(frac=1, random_state=42)\n",
    "print(data_df.shape)\n",
    "#fill blanks with ''\n",
    "data_df = data_df.fillna('')\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "data_df['combined_text'] = data_df[['Item','Description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "data_df['processed_text'] = data_df['combined_text'].map(lambda s:preprocess_text(s)[1])\n",
    "print(data_df.shape)\n",
    "data_df.drop_duplicates(subset=['processed_text','target'],inplace=True)\n",
    "print(data_df.shape)\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "X = data_df[['Item','Description','establishment_type','processed_text']]\n",
    "y = data_df['target']\n",
    "# split the cicd data into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a27ed",
   "metadata": {},
   "source": [
    "We will append the CICD data to the historical data to create the final train and test data.\n",
    "Train set has 80% of all historical data and 90% of all cicd data.\n",
    "Test set consists of 20% of historic data and 10% of all cicd data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dceeea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train.append(X_train_cicd)\n",
    "X_test_final = X_test.append(X_test_cicd)\n",
    "y_train_final = y_train.append(y_train_cicd)\n",
    "y_test_final = y_test.append(y_test_cicd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123f453",
   "metadata": {},
   "source": [
    "<a id='Model Training'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd540e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 73157\n",
      "Test data size: 18290\n"
     ]
    }
   ],
   "source": [
    "print('Training data size: {}'.format(len(X_train)))\n",
    "print('Test data size: {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2e6c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels : 102\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique labels : {}'.format(len(y_train.unique().tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6d97a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75af4ab",
   "metadata": {},
   "source": [
    "The Model Pipeline consists of 1. CountVectorizer, 2. Tfidf-Transformer 3. RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d043639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model pipeline\n",
    "rf = Pipeline([('vect', CountVectorizer(token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',stop_words='english',max_df=0.85)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            #('mnb', MultinomialNB(alpha= 0.05,fit_prior= False))])\n",
    "            ('clf', RandomForestClassifier(n_jobs=-1, random_state=42,class_weight='balanced',max_depth=400))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c304e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/utils/validation.py:179: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(joblib_version) < '0.12':\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/utils/fixes.py:223: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.85,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',\n",
       "                                 tokenizer=None,...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                        criterion='gini', max_depth=400,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform model training\n",
    "rf.fit(X_train_final['processed_text'].values, y_train_final.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75505ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/utils/fixes.py:223: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/utils/fixes.py:223: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# create a result dataframe to store final results\n",
    "result=X_test_final\n",
    "# model prediction\n",
    "y_pred = rf.predict(X_test_final['processed_text'].values)\n",
    "\n",
    "result['original_cat']= y_test_final.values\n",
    "result['predicted_cat'] = y_pred\n",
    "result['prediction_cat_confscore'] = np.round_(np.max(rf.predict_proba(X_test_final['processed_text']), axis=1), decimals=2)\n",
    "\n",
    "#\n",
    "output = {'accuracy': accuracy_score(y_pred,y_test_final),'precision_score':precision_score(y_pred,y_test_final,average='weighted'),'recall_score':recall_score(y_pred,y_test_final,average='weighted')\n",
    ",'f1_score':f1_score(y_pred,y_test_final,average='weighted')}\n",
    "\n",
    "result['confusion_matrix'] = str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bfdd20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47576"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf.named_steps['vect'].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "245c1c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(rf.named_steps['clf'].estimators_[0].tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbebbc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean tree depth in the Random Forest: 400.0\n"
     ]
    }
   ],
   "source": [
    "depths = [tree.tree_.max_depth for tree in rf.named_steps['clf'].estimators_]\n",
    "print(f\"Mean tree depth in the Random Forest: {np.round(np.mean(depths))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94863ce4",
   "metadata": {},
   "source": [
    "<a id='Model Saving'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf544aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"{'accuracy': 0.8072686733556299, 'precision_score': 0.8029800433559108, 'recall_score': 0.8072686733556299, 'f1_score': 0.7904798356764975}\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['confusion_matrix'][5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94462f5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dk/dcz1bsq51ydb6f7j_7n8pxpr0000gn/T/ipykernel_1764/2835444874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m array([\"{'accuracy': 0.8214672148885522, 'precision_score': 0.8704898295343778, 'recall_score': 0.8214672148885522, 'f1_score': 0.8401291751124788}\"],\n\u001b[0m\u001b[1;32m      2\u001b[0m       dtype=object)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "array([\"{'accuracy': 0.8214672148885522, 'precision_score': 0.8704898295343778, 'recall_score': 0.8214672148885522, 'f1_score': 0.8401291751124788}\"],\n",
    "      dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dab90b",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54abd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import datetime\n",
    "# save the model to disk\n",
    "filename_primary= 'finalized_model.sav'\n",
    "joblib.dump(rf, open(filename_primary, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0273b",
   "metadata": {},
   "source": [
    "<a id='Validation and Results'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4c028",
   "metadata": {},
   "source": [
    "# Validation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score of the model\n",
    "accuracy = rf.score(X_test['processed_text'].values, y_test)\n",
    "print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8a0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b64ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report \n",
    "classification_report = metrics.classification_report(y_test_final, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605beb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(classification_report).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the misclassifications\n",
    "misclassifications= result.loc[result['original_cat']!=result['predicted_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications.to_csv('../output/misclassifications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications.groupby(['establishment_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0851c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_end = int(len(data_df)*train_size)\n",
    "df_train = data_df[:train_end]\n",
    "df_test = data_df[train_end:]\n",
    "df_train = df_train[['Item','Description','establishment_type','target']]\n",
    "df_test = df_test[['Item','Description','establishment_type','target']]\n",
    "train_size_cicd=0.02\n",
    "train_end_cicd = int(len(data_cicd_final)*train_size_cicd)\n",
    "df2_train = data_cicd_final[:train_end_cicd]\n",
    "df2_test = data_cicd_final[train_end_cicd:]\n",
    "df2_train = df2_train[['Item','Description','establishment_type','target']]\n",
    "df2_test = df2_test[['Item','Description','establishment_type','target']]\n",
    "X_train_save = df_train.append(df2_train)\n",
    "X_test_save = df_test.append(df2_test)\n",
    "X_train_save['label'] = 'train'\n",
    "X_test_save['label'] = 'test'\n",
    "X_data = X_train_save.append(X_test_save)\n",
    "X_data.to_csv('df_traintestdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827162c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6dc68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387bb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50336a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669cde9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
