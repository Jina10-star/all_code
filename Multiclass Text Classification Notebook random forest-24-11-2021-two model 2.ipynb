{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5c46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "#from tqdm.notebook import tqdm\n",
    "#tqdm.pandas()\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f025c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(message):\n",
    "\n",
    "    new_stopwords=['ml','oz','pk','grocery','lb']\n",
    "    stpwrd = nltk.corpus.stopwords.words('english')\n",
    "    stpwrd.extend(new_stopwords)\n",
    "    # 1. Init Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #lowering and removing punctuation\n",
    "    message = re.sub(r'[^\\w\\s]','', message.lower())\n",
    "    #removing the numerical values and working only with text values\n",
    "    message = re.sub('[^a-zA-Z]', \" \", message )\n",
    "    #removing the stopwords\n",
    "    message = ' '.join([word for word in message.split() if word not in stpwrd and len(word)>1])\n",
    "    #lemmatizing the text\n",
    "    message =  \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(message) if w not in string.punctuation])\n",
    "    #print(\"message is : \",message)\n",
    "    return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa56fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jina_final.csv', encoding='utf8',engine='python',usecols=['Item','Description','establishment_type','primary','secondary'])\n",
    "df1=df.sample(frac=1, random_state=42)\n",
    "df1 = df1.fillna('')\n",
    "df1['input_str'] = df1[['Item', 'Description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "df1['cleanText']=df1['input_str'].map(lambda s:preprocess_text(s)) \n",
    "df1 = df1.reset_index(drop=True)\n",
    "X=df1[['Item','Description','establishment_type','cleanText']]\n",
    "Y_primary=df1['primary']\n",
    "Y_secondary=df1['secondary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4165d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train_primary, y_test_primary = train_test_split(X,\n",
    "                                                    Y_primary,\n",
    "                                                    test_size = .20, \n",
    "                                                    random_state = 42\n",
    "                                                    )\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test,y_train_secondary, y_test_secondary = train_test_split(X,\n",
    "                                                    Y_secondary,\n",
    "                                                    test_size = .20, \n",
    "                                                    random_state = 42\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f022c8",
   "metadata": {},
   "source": [
    "####cicd part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2444bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv('TaxML-CICD - Prod_Data_after_preprocess.csv',encoding='utf8',engine='python',usecols=['Item','Description','establishment_type','primary','secondary'])\n",
    "df2['input_str'] = df2[['Item','Description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "df2['cleanText']=df2['input_str'].map(lambda s:preprocess_text(s))\n",
    "X_cicd=df2[['Item','Description','establishment_type','cleanText']]\n",
    "Y_primary_cicd=df2['primary']\n",
    "Y_secondary_cicd=df2['secondary']\n",
    "X_train_cicd, X_test_cicd, y_train_primary_cicd, y_test_primary_cicd = train_test_split(X_cicd,\n",
    "                                                    Y_primary_cicd,\n",
    "                                                    test_size = .20, \n",
    "                                                    random_state = 42\n",
    "                                                    )\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train_cicd, X_test_cicd,y_train_secondary_cicd, y_test_secondary_cicd = train_test_split(X_cicd,\n",
    "                                                    Y_secondary_cicd,\n",
    "                                                    test_size = .20, \n",
    "                                                    random_state = 42\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ece7e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Description</th>\n",
       "      <th>establishment_type</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74328</th>\n",
       "      <td>Exotico Blanco, 750mL bottle (40% ABV)</td>\n",
       "      <td></td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>exotico blanco bottle abv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93071</th>\n",
       "      <td>Cortas Halva Original (16 oz)</td>\n",
       "      <td></td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>cortas halva original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160229</th>\n",
       "      <td>Meiomi Pinot Noir, 750mL wine (13.7% ABV)</td>\n",
       "      <td></td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>meiomi pinot noir wine abv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33442</th>\n",
       "      <td>Ito en Peach Veggie Shot</td>\n",
       "      <td>30.36 fluid ounces.</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>ito en peach veggie shot fluid ounce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129506</th>\n",
       "      <td>Val Di Giulia Barbaresco, 750mL italian red wi...</td>\n",
       "      <td></td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>val di giulia barbaresco italian red wine abv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>Half &amp; Half Quart</td>\n",
       "      <td></td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>half half quart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>Alpine Beer Company Duet Pale Ale</td>\n",
       "      <td>This West Coast pale ale made with Simcoe and ...</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>alpine beer company duet pale ale west coast p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>Romance Flowers Medium Red</td>\n",
       "      <td></td>\n",
       "      <td>FLOWERS</td>\n",
       "      <td>romance flower medium red flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>Renal Care (32 oz)</td>\n",
       "      <td>Our renal care recipe has low protein. It cont...</td>\n",
       "      <td>PET</td>\n",
       "      <td>renal care renal care recipe low protein conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>Orbit Peppermint Gum</td>\n",
       "      <td>Suger free gum naturally and artificially flav...</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>orbit peppermint gum suger free gum naturally ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135956 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Item  \\\n",
       "74328              Exotico Blanco, 750mL bottle (40% ABV)   \n",
       "93071                       Cortas Halva Original (16 oz)   \n",
       "160229          Meiomi Pinot Noir, 750mL wine (13.7% ABV)   \n",
       "33442                            Ito en Peach Veggie Shot   \n",
       "129506  Val Di Giulia Barbaresco, 750mL italian red wi...   \n",
       "...                                                   ...   \n",
       "119879                                  Half & Half Quart   \n",
       "103694                  Alpine Beer Company Duet Pale Ale   \n",
       "131932                         Romance Flowers Medium Red   \n",
       "146867                                 Renal Care (32 oz)   \n",
       "121958                               Orbit Peppermint Gum   \n",
       "\n",
       "                                              Description establishment_type  \\\n",
       "74328                                                                GROCERY   \n",
       "93071                                                                GROCERY   \n",
       "160229                                                               GROCERY   \n",
       "33442                                 30.36 fluid ounces.            GROCERY   \n",
       "129506                                                               GROCERY   \n",
       "...                                                   ...                ...   \n",
       "119879                                                               GROCERY   \n",
       "103694  This West Coast pale ale made with Simcoe and ...            GROCERY   \n",
       "131932                                                               FLOWERS   \n",
       "146867  Our renal care recipe has low protein. It cont...                PET   \n",
       "121958  Suger free gum naturally and artificially flav...            GROCERY   \n",
       "\n",
       "                                                cleanText  \n",
       "74328                           exotico blanco bottle abv  \n",
       "93071                               cortas halva original  \n",
       "160229                         meiomi pinot noir wine abv  \n",
       "33442                ito en peach veggie shot fluid ounce  \n",
       "129506      val di giulia barbaresco italian red wine abv  \n",
       "...                                                   ...  \n",
       "119879                                    half half quart  \n",
       "103694  alpine beer company duet pale ale west coast p...  \n",
       "131932                   romance flower medium red flower  \n",
       "146867  renal care renal care recipe low protein conta...  \n",
       "121958  orbit peppermint gum suger free gum naturally ...  \n",
       "\n",
       "[135956 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83c5ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final=X_train['cleanText'].append(X_train_cicd['cleanText'])\n",
    "y_train_final_primary=y_train_primary.append(y_train_primary_cicd)\n",
    "y_train_final_secondary=y_train_secondary.append(y_train_secondary_cicd)\n",
    "X_test_final=X_test['cleanText'].append(X_test_cicd['cleanText'])\n",
    "y_test_final_primary=y_test_primary.append(y_test_primary_cicd)\n",
    "y_test_final_secondary=y_test_secondary.append(y_test_secondary_cicd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54dd607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_end = int(len(df1)*train_size)\n",
    "df_train = df1[:train_end]\n",
    "df_test = df1[train_end:]\n",
    "df_train.to_csv('df_train.csv')\n",
    "df_test.to_csv('df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09ef4acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test_final_primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27817cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (34135) does not match length of index (33989)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-29321895b0cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_final_primary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original_cat_primary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test_final_primary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction_cat_primary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction_cat_primary_confscore'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3240\u001b[0m         \"\"\"\n\u001b[1;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3242\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3243\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3898\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3899\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \"\"\"\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (34135) does not match length of index (33989)"
     ]
    }
   ],
   "source": [
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "dimention=['y_train_final_primary','y_train_final_secondary']\n",
    "\n",
    "result=X_test\n",
    "for i in dimention:\n",
    "    if i =='y_train_final_primary':\n",
    "        rf = Pipeline([('vect', CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', lowercase=True, stop_words='english')),\n",
    "               ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "               ('clf', RandomForestClassifier(oob_score=True,n_jobs=-1)),\n",
    "              ])\n",
    "        rf.fit(X_train_final, y_train_final_primary)\n",
    "        y_pred= rf.predict(X_test_final)\n",
    "        result['original_cat_primary']=y_test_final_primary\n",
    "        result['prediction_cat_primary']=y_pred\n",
    "        result['prediction_cat_primary_confscore']=rf.predict_proba(X_test_final)\n",
    "        output={'accuracy':accuracy_score(y_pred,y_test_final_primary),'precision_score':precision_score(y_pred,y_test_final_primary,average='macro'),'recall_score':recall_score(y_pred,y_test_final_primary,average='macro')\n",
    ",'f1_score':f1_score(y_pred,y_test_final_primary,average='macro')}\n",
    "        result['confusion_matrix_primary']=str(output)\n",
    "        \n",
    "    else:\n",
    "        rf1 = Pipeline([('vect', CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', lowercase=True, stop_words='english')),\n",
    "               ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "               ('clf', RandomForestClassifier(oob_score=True,n_jobs=-1)),\n",
    "              ])\n",
    "        rf1.fit(X_train_final, y_train_final_secondary)\n",
    "        y_pred= rf1.predict(X_test_final)\n",
    "        result['original_cat_secondary']=y_test_final_secondary\n",
    "        result['prediction_cat_secondary']=y_pred\n",
    "        result['prediction_cat_secondary_confscore']=rf1.predict_proba(X_test_final) \n",
    "        output={'accuracy':accuracy_score(y_pred,y_test_final_secondary),'precision_score':precision_score(y_pred,y_test_final_secondary,average='macro'),'recall_score':recall_score(y_pred,y_test_final_secondary,average='macro')\n",
    ",'f1_score':f1_score(y_pred,y_test_final_secondary,average='macro')}\n",
    "        result['confusion_matrix_secondary']=str(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af9888f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= rf.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb227846",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d2c9cac9f4f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original_cat_primary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test_final_primary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3240\u001b[0m         \"\"\"\n\u001b[1;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3242\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3243\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3875\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3876\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreindexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3878\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindexer\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   3865\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3866\u001b[0m                         \u001b[0;31m# duplicate axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3867\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3869\u001b[0m                     \u001b[0;31m# other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindexer\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   3860\u001b[0m                 \u001b[0;31m# GH 4107\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3861\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3862\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3863\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3864\u001b[0m                     \u001b[0;31m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   4343\u001b[0m     )\n\u001b[1;32m   4344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4347\u001b[0m     def drop(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4810\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4811\u001b[0;31m         return self._reindex_axes(\n\u001b[0m\u001b[1;32m   4812\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4813\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4831\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4832\u001b[0;31m             obj = obj._reindex_with_indexers(\n\u001b[0m\u001b[1;32m   4833\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4834\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4876\u001b[0m             \u001b[0;31m# TODO: speed up on homogeneous DataFrame objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4877\u001b[0;31m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[1;32m   4878\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4879\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3474\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3476\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "result['original_cat_primary']=y_test_final_primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1191add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications_primary= result.loc[result['original_cat_primary']!=result['prediction_cat_primary']]\n",
    "misclassifications_secondary= result.loc[result['original_cat_secondary']!=result['prediction_cat_secondary']]\n",
    "misclassification=pd.merge(misclassifications_primary,misclassifications_secondary,how='inner',on=['item_name','description','establishment_type','cleanText'])\n",
    "misclassification.to_csv('misclassification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e515c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9327df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Description</th>\n",
       "      <th>establishment_type</th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>input_str</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pure Happiness</td>\n",
       "      <td>A sunny sunflower bouquet gets an autumnal spi...</td>\n",
       "      <td>FLOWERS</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>Pure Happiness A sunny sunflower bouquet gets ...</td>\n",
       "      <td>pure happiness sunny sunflower bouquet get aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Snow Bouquet</td>\n",
       "      <td>Like a quiet walk through a snowy forest, this...</td>\n",
       "      <td>FLOWERS</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>Silver Snow Bouquet Like a quiet walk through ...</td>\n",
       "      <td>silver snow bouquet like quiet walk snowy fore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful in Blue</td>\n",
       "      <td>Brighten the home with the beauty of bright bl...</td>\n",
       "      <td>FLOWERS</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>Beautiful in Blue Brighten the home with the b...</td>\n",
       "      <td>beautiful blue brighten home beauty bright blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blush Life Bouquet</td>\n",
       "      <td>Put a spring in their step with this beautiful...</td>\n",
       "      <td>FLOWERS</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>Blush Life Bouquet Put a spring in their step ...</td>\n",
       "      <td>blush life bouquet put spring step beautifully...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red Tulips</td>\n",
       "      <td>Call ahead for this arrangement before orderin...</td>\n",
       "      <td>FLOWERS</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>CAT_TPP,531</td>\n",
       "      <td>Red Tulips Call ahead for this arrangement bef...</td>\n",
       "      <td>red tulip call ahead arrangement ordering tuli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Misko (1 lb)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_PASTA,737</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_PASTA,737</td>\n",
       "      <td>Misko (1 lb) GROCERY</td>\n",
       "      <td>misko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Chunky Chocolates (2.4 oz)</td>\n",
       "      <td>Chunks of chocolate with premium ingredients m...</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_CONFECTIONARY,707</td>\n",
       "      <td>CAT_CONFECTIONARY,707</td>\n",
       "      <td>Chunky Chocolates (2.4 oz) Chunks of chocolate...</td>\n",
       "      <td>chunky chocolate chunk chocolate premium ingre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Essential Everyday Salsa, Restaurant Style, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_CONDIMENTS,740</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_CONDIMENTS,740</td>\n",
       "      <td>Essential Everyday Salsa, Restaurant Style, an...</td>\n",
       "      <td>essential everyday salsa restaurant style medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>Woodbridge Chardonnay, 1.5L white wine (13.5% ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_WINE,534</td>\n",
       "      <td>CAT_WINE,534</td>\n",
       "      <td>Woodbridge Chardonnay, 1.5L white wine (13.5% ...</td>\n",
       "      <td>woodbridge chardonnay white wine abv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>Fireball, 1.75L whiskey (33.0% ABV)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_LIQUOR,535</td>\n",
       "      <td>CAT_LIQUOR,535</td>\n",
       "      <td>Fireball, 1.75L whiskey (33.0% ABV) GROCERY</td>\n",
       "      <td>fireball whiskey abv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Item  \\\n",
       "0                                       Pure Happiness   \n",
       "1                                  Silver Snow Bouquet   \n",
       "2                                    Beautiful in Blue   \n",
       "3                                   Blush Life Bouquet   \n",
       "4                                           Red Tulips   \n",
       "..                                                 ...   \n",
       "722                                       Misko (1 lb)   \n",
       "723                         Chunky Chocolates (2.4 oz)   \n",
       "724  Essential Everyday Salsa, Restaurant Style, an...   \n",
       "725  Woodbridge Chardonnay, 1.5L white wine (13.5% ...   \n",
       "726                Fireball, 1.75L whiskey (33.0% ABV)   \n",
       "\n",
       "                                           Description establishment_type  \\\n",
       "0    A sunny sunflower bouquet gets an autumnal spi...            FLOWERS   \n",
       "1    Like a quiet walk through a snowy forest, this...            FLOWERS   \n",
       "2    Brighten the home with the beauty of bright bl...            FLOWERS   \n",
       "3    Put a spring in their step with this beautiful...            FLOWERS   \n",
       "4    Call ahead for this arrangement before orderin...            FLOWERS   \n",
       "..                                                 ...                ...   \n",
       "722                                                NaN            GROCERY   \n",
       "723  Chunks of chocolate with premium ingredients m...            GROCERY   \n",
       "724                                                NaN            GROCERY   \n",
       "725                                                NaN            GROCERY   \n",
       "726                                                NaN            GROCERY   \n",
       "\n",
       "                                 primary                            secondary  \\\n",
       "0                            CAT_TPP,531                          CAT_TPP,531   \n",
       "1                            CAT_TPP,531                          CAT_TPP,531   \n",
       "2                            CAT_TPP,531                          CAT_TPP,531   \n",
       "3                            CAT_TPP,531                          CAT_TPP,531   \n",
       "4                            CAT_TPP,531                          CAT_TPP,531   \n",
       "..                                   ...                                  ...   \n",
       "722       CAT_PREPACKAGED_FOOD_PASTA,737       CAT_PREPACKAGED_FOOD_PASTA,737   \n",
       "723                CAT_CONFECTIONARY,707                CAT_CONFECTIONARY,707   \n",
       "724  CAT_PREPACKAGED_FOOD_CONDIMENTS,740  CAT_PREPACKAGED_FOOD_CONDIMENTS,740   \n",
       "725                         CAT_WINE,534                         CAT_WINE,534   \n",
       "726                       CAT_LIQUOR,535                       CAT_LIQUOR,535   \n",
       "\n",
       "                                             input_str  \\\n",
       "0    Pure Happiness A sunny sunflower bouquet gets ...   \n",
       "1    Silver Snow Bouquet Like a quiet walk through ...   \n",
       "2    Beautiful in Blue Brighten the home with the b...   \n",
       "3    Blush Life Bouquet Put a spring in their step ...   \n",
       "4    Red Tulips Call ahead for this arrangement bef...   \n",
       "..                                                 ...   \n",
       "722                               Misko (1 lb) GROCERY   \n",
       "723  Chunky Chocolates (2.4 oz) Chunks of chocolate...   \n",
       "724  Essential Everyday Salsa, Restaurant Style, an...   \n",
       "725  Woodbridge Chardonnay, 1.5L white wine (13.5% ...   \n",
       "726        Fireball, 1.75L whiskey (33.0% ABV) GROCERY   \n",
       "\n",
       "                                             cleanText  \n",
       "0    pure happiness sunny sunflower bouquet get aut...  \n",
       "1    silver snow bouquet like quiet walk snowy fore...  \n",
       "2    beautiful blue brighten home beauty bright blu...  \n",
       "3    blush life bouquet put spring step beautifully...  \n",
       "4    red tulip call ahead arrangement ordering tuli...  \n",
       "..                                                 ...  \n",
       "722                                              misko  \n",
       "723  chunky chocolate chunk chocolate premium ingre...  \n",
       "724   essential everyday salsa restaurant style medium  \n",
       "725               woodbridge chardonnay white wine abv  \n",
       "726                               fireball whiskey abv  \n",
       "\n",
       "[727 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7627789",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e0efc8a6c283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# save the model to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename_primary\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'finalized_model_rf.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfilename_secondary\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'finalized_model_rf1.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_secondary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename_primary= 'finalized_model_rf.sav'\n",
    "pickle.dump(rf, open(filename_primary, 'wb'))\n",
    "filename_secondary= 'finalized_model_rf1.sav'\n",
    "pickle.dump(rf1, open(filename_secondary, 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1552257a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(stop_words='english', strip_accents='ascii',\n",
       "                                 token_pattern='(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', RandomForestClassifier(n_jobs=-1, oob_score=True))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# load the model from disk\n",
    "loaded_model_primary= pickle.load(open('finalized_model_rf.sav', 'rb'))\n",
    "loaded_model_primary.fit(df2['cleanText'].values, df2['primary'].values)\n",
    "loaded_model_secondary= pickle.load(open('finalized_model_rf1.sav', 'rb'))\n",
    "loaded_model_secondary.fit(df2['cleanText'].values, df2['secondary'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, x_val, y_train, y_val = train_test_split(X,\n",
    "                                                    Y_primary,\n",
    "                                                    test_size =.7\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = rf.score(x_val['cleanText'], y_val)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95920eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_demo(item_name, description,establishment_type):\n",
    "\n",
    "        message=item_name + \" \" +description+ \" \"+establishment_type\n",
    "        sw =nltk.corpus.stopwords.words('english')   \n",
    "        new_stopwords=['ml','oz','pk','grocery','lb']\n",
    "        sw.extend(new_stopwords) \n",
    "        # 1. Init Lemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        #lowering and removing punctuation\n",
    "        message = re.sub(r'[^\\w\\s]','', message.lower())\n",
    "        #removing the numerical values and working only with text values\n",
    "        message = re.sub('[^a-zA-Z]', \" \", message )\n",
    "        #removing the stopwords\n",
    "        message = ' '.join([word for word in message.split() if word not in sw and len(word)>1])\n",
    "        #lemmatizing the text\n",
    "        message =  \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(message) if w not in string.punctuation])\n",
    "        #print(\"message is : \",message)\n",
    "        return message\n",
    "item_name='Jameson Irish Whiskey.1.75L Bottle Size'\n",
    "description=''\n",
    "establishment_type='GROCERY'\n",
    "\n",
    "message=preprocess_text_demo(item_name, description,establishment_type)\n",
    "message=[message]\n",
    "predictions_primary= rf.predict(message)\n",
    "#res=type(predictions_primary)\n",
    "print(predictions_primary)\n",
    "conf_score_primary= rf.predict_proba(message).max()\n",
    "print(conf_score_primary)\n",
    "predictions_secondary= rf1.predict(message)\n",
    "print(predictions_secondary)\n",
    "conf_score_secondary= rf1.predict_proba(message).max()\n",
    "print(conf_score_secondary)\n",
    "predictions_primary= rf.predict(message)\n",
    "conf_score_primary= rf.predict_proba(message).max()\n",
    "#print(predictions_primary)\n",
    "predictions_secondary= rf1.predict(message)\n",
    "conf_score_secondary= rf1.predict_proba(message).max()\n",
    "#print(predictions_secondary)\n",
    "if predictions_primary==predictions_secondary:\n",
    "    categories=predictions_primary[0].split(',')[0]\n",
    "    categories_integer=predictions_primary[0].split(',')[1]\n",
    "else:\n",
    "    categories = ','.join([predictions_primary[0].split(',')[0],predictions_secondary[0].split(',')[0]])\n",
    "    categories_integer= ','.join([predictions_primary[0].split(',')[1],predictions_secondary[0].split(',')[1]])\n",
    "conf_score=round((conf_score_primary+conf_score_secondary)/2,2)\n",
    "\n",
    "#'conf_score':conf_score_primary,conf_score_secondary\n",
    "#success_msg = [predictions_primary,predictions_secondary]\n",
    "success_msg = {'cat_name':categories,'integer':categories_integer,'conf_score':conf_score}\n",
    "print(success_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4880230",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {'Random Forest': Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('rf', RandomForestClassifier()),\n",
    "              ]),\n",
    "             \n",
    "             'naive bayas': Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ]),\n",
    "              'logistic': Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('lg', LogisticRegression()),\n",
    "              ])\n",
    "             }\n",
    "            \n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in tqdm(model_dict.items()):   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train_final, y_train_final)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a462b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################redundent code###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondlevel= df.loc[df['primary']!=df['secondary']]\n",
    "#secondlevel=secondlevel['secondary'].unique()\n",
    "#mapping={}\n",
    "#mapping_primary=pd.Series(df1.cat_name_primary.values,index=df1.Primary_Integer).to_dict()\n",
    "#mapping_secondary=pd.Series(df1.cat_name_secondary.values,index=df1.Secondary_Integer).to_dict()\n",
    "#df1['cat_multilevel_count'] = df1.groupby('cat_multilevel')['cat_multilevel'].transform('count')\n",
    "#df1['cat_name_primary_count'] = df1.groupby('cat_name_primary')['cat_name_primary'].transform('count')\n",
    "#df1['cat_name_secondary_count'] = df1.groupby('cat_name_secondary')['cat_name_secondary'].transform('count')\n",
    "#df2_primary=df1[df1['cat_name_primary_count']<5].reset_index()\n",
    "#df3_primary=df1[df1['cat_name_primary_count']>5].reset_index()\n",
    "#X_primary=df3_primary[['item_name','description','establishment_type','cleanText']]\n",
    "#Y_primary=df3_primary['cat_name_primary']\n",
    "#df2_secondary=df1[df1['cat_name_secondary_count']<5].reset_index()\n",
    "#df3_secondary=df1[df1['cat_name_secondary_count']>5].reset_index()\n",
    "#X_secondary=df3_primary[['item_name','description','establishment_type','cleanText']]\n",
    "#Y_secondary=df3_primary['cat_name_secondary']\n",
    "#X_train_final_primary=pd.concat([X_train_primary['cleanText'], df2_primary['cleanText']])\n",
    "#y_train_final_primary=pd.concat([y_train_primary, df2_primary['cat_name_primary']])\n",
    "#X_train_final_secondary=pd.concat([X_train_secondary['cleanText'], df2_secondary['cleanText']])\n",
    "#y_train_final_secondary=pd.concat([y_train_secondary, df2_secondary['cat_name_secondary']])\n",
    "#X_train_final_secondary=X_train_final_secondary.values\n",
    "#result['final_cat']=result['prediction_cat_primary']+ \" ,\" +result['prediction_cat_secondary']\n",
    "#result['final_cat'] =  result[['prediction_cat_primary', 'prediction_cat_secondary']].apply(lambda x: ','.join(str(x)), axis=0)\n",
    "#result['final_cat_int']=result['prediction_cat_primary_integer']+','+result['prediction_cat_secondary_integer']\n",
    "#result['final_cat']=result['final_cat'].apply(lambda x:','.join(list(set(x.split(',')))))\n",
    "#result['final_accuracy']=accuracy_score(result['final_cat'],result['cat_multilevel'])\n",
    "#result['final_cat'] = result['prediction_cat_primary'].astype(str) +\",\" +result['prediction_cat_secondary'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features (tf-idf weights) for the processed text\n",
    "\n",
    "#texts = df1['input_str'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),max_df = .95)\n",
    "LE = LabelEncoder()\n",
    "#tfidf\n",
    "tfv = TfidfVectorizer(strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',ngram_range=(1,2), use_idf=1,smooth_idf=1,sublinear_tf=1,max_df = .95,stop_words = 'english')\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train) #features\n",
    "X_test_tfidf= tfidf_vectorizer.fit_transform(X_test) #features\n",
    "\n",
    "tfv.fit(list(X_train) + list(X_test))\n",
    "xtrain_tfv =  tfv.transform(X_train) \n",
    "xvalid_tfv = tfv.transform(X_test)\n",
    "\n",
    "#countvec\n",
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "X_train_ctv = ctv.fit_transform(X_train) #features\n",
    "X_test_ctv= ctv.fit_transform(X_test) #features\n",
    "\n",
    "\n",
    "\n",
    "y_train_final=LE.fit_transform(y_train)\n",
    "y_test_final=LE.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341fc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X_train_final = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_final = lsa.fit_transform(X_test_tfidf)\n",
    "\n",
    "X_train_final_ctv= lsa.fit_transform(X_train_ctv)\n",
    "X_test_final_ctv= lsa.fit_transform(X_test_ctv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "randomforestmodel=RandomForestClassifier(random_state=3)\n",
    "#tfidf\n",
    "#randomforestmodel.fit(xtrain_tfv, y_train_final)\n",
    "#y_pred = randomforestmodel.predict(xvalid_tfv)\n",
    "#countvec\n",
    "#randomforestmodel.fit(X_train_final_ctv, y_train_final)\n",
    "#y_pred = randomforestmodel.predict(X_test_final_ctv)\n",
    "#svd\n",
    "randomforestmodel.fit(X_train_final, y_train_final)\n",
    "y_pred = randomforestmodel.predict(X_test_final)\n",
    "\n",
    "ac_score_list.append(accuracy_score(y_test_final, y_pred))\n",
    "p_score_list.append(precision_score(y_test_final, y_pred, average='macro'))\n",
    "r_score_list.append(recall_score(y_test_final, y_pred, average='macro'))\n",
    "f1_score_list.append(f1_score(y_test_final, y_pred, average='macro'))\n",
    "model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e053b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Preliminary model evaluation using default parameters\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Creating a dict of the models\n",
    "model_dict = {'Random Forest': RandomForestClassifier(random_state=3)}\n",
    "            \n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in tqdm(model_dict.items()):   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train_final, y_train_final)\n",
    "        y_pred = v.predict(X_test_final)\n",
    "        ac_score_list.append(accuracy_score(y_test_final, y_pred))\n",
    "        p_score_list.append(precision_score(y_test_final, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test_final, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test_final, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df,v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b26c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f703ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = RandomForestClassifier()\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "rf=Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', RandomForestClassifier()),\n",
    "              ])\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigramslf__\n",
    "     \"clf__bootstrap\":[True, False],\n",
    "     \"clf__max_depth\":[10, 50, 100,500, None],\n",
    "     \"clf__max_features\":['auto', 'sqrt'],\n",
    "     \"clf__min_samples_leaf\":[1,2,4],\n",
    "     \"clf__min_samples_split\":[2,5,10],\n",
    "     \"clf__n_estimators\":[400,600,800],\n",
    "     \"clf__random_state\":[3]\n",
    "\n",
    "}\n",
    "\n",
    "RandomizedSearch = RandomizedSearchCV(rf,\n",
    "                          parameters, \n",
    "                          cv=5,\n",
    "                          verbose=1, \n",
    "                          n_jobs=-1)\n",
    "\n",
    "t0 = time()\n",
    "rf_best_model = RandomizedSearch.fit(X_train_final, y_train_final)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "#print()\n",
    "print(\"Best score: %0.3f\" % rf_best_model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = rf_best_model.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7413f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_model = RandomForestClassifier(bootstrap = False,\n",
    "                                       max_depth = 50,\n",
    "                                       max_features = 'auto',\n",
    "                                       min_samples_leaf = 1,\n",
    "                                       n_estimators = 1400,\n",
    "                                       random_state=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
