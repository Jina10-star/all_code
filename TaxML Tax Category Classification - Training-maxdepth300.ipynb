{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa18879",
   "metadata": {},
   "source": [
    "# <h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import Requirements\" data-toc-modified-id=\"Import-Requirements-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Requirements</a></span></li><li><span><a href=\"#Prepare Training Data\" data-toc-modified-id=\"Prepare-Training-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prepare Training Data</a></span><ul class=\"toc-item\"></ul></li><li><span><a href=\"#Model Training\" data-toc-modified-id=\"Model Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Training</a></span></li><li><span><a href=\"#Model Saving\" data-toc-modified-id=\"Model Saving-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model Saving</a></span><ul class=\"toc-item\"></ul></li><li><span><a href=\"#Validation and Results\" data-toc-modified-id=\"Validation and Results-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Validation and Results</a></span><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe6d0d",
   "metadata": {},
   "source": [
    "<a id='Import Requirements'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971b37a",
   "metadata": {},
   "source": [
    "# Import Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca994c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4342ccbd",
   "metadata": {},
   "source": [
    "<a id='Prepare Training Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4230c",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0d0ec",
   "metadata": {},
   "source": [
    "Input data for training consists of both historical data and CICD data( Production run data for which manual agent validation has been done for the ML prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322e3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(message):\n",
    "\n",
    "    #stopwords\n",
    "    stpwrd = nltk.corpus.stopwords.words('english')\n",
    "    #stpwrd.extend(new_stopwords)\n",
    "    # 1. Init Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #lowering and removing punctuation\n",
    "    message = re.sub(r'[^\\w\\s]','', message.lower())\n",
    "    #removing the numerical values and working only with text values\n",
    "    message = re.sub('[^a-zA-Z]', \" \", message )\n",
    "    #removing the stopwords\n",
    "    message = ' '.join([word for word in message.split() if word not in stpwrd and len(word)>2])\n",
    "    #lemmatizing the text\n",
    "    message =  \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(message) if w not in string.punctuation])\n",
    "    #print(\"message is : \",message)\n",
    "    message=message.split()[0:15]\n",
    "    message = \" \".join([word for word in message])\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4a91f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35365, 5)\n",
      "(1383, 5)\n",
      "(32714, 5)\n",
      "(34097, 6)\n"
     ]
    }
   ],
   "source": [
    "#read input from cicd data into dataframe\n",
    "data_cicd=pd.read_csv('../data/TaxML-CICD - Prod_Data (12).csv', usecols = ['Item','Description','establishment_type','Confidence Score','Agent Corrected CAT Name', 'Agent Corrected Integer','CAT NAME_ ValidationScore [0-100]','Integer_ValidationScore[0-100]'])\n",
    "#low conf and correcr predicted data\n",
    "data_cicd_low_conf=data_cicd[(data_cicd['Confidence Score']<0.6)]\n",
    "data_cicd_low_conf=data_cicd_low_conf[(data_cicd_low_conf['CAT NAME_ ValidationScore [0-100]']==100) &(data_cicd_low_conf['Integer_ValidationScore[0-100]']==100)]\n",
    "#misclassified data                                        \n",
    "data_cicd_misclassification=data_cicd[(data_cicd['CAT NAME_ ValidationScore [0-100]']!=100) &(data_cicd['Integer_ValidationScore[0-100]']!=100)]\n",
    "data_cicd_latest=data_cicd_low_conf.append(data_cicd_misclassification)\n",
    "data_cicd_latest=data_cicd_latest[['Item','Description','establishment_type','Agent Corrected CAT Name', 'Agent Corrected Integer']]\n",
    "\n",
    "ongoing_phase1_cicd=pd.read_csv('../data/Ongoing Training_Duplicate Data.csv', usecols = ['Item','Description','establishment_type','Agent Corrected CAT Name', 'Agent Corrected Integer'])\n",
    "\n",
    "#remove empty rows from dataframe\n",
    "data_cicd_latest.dropna(how='all',inplace=True)\n",
    "ongoing_phase1_cicd.dropna(how='all',inplace=True)\n",
    "\n",
    "#remove rows having empty 'Agent Corrected CAT Name', ''Agent Corrected Integer'\n",
    "data_cicd_latest.dropna(subset=['Agent Corrected CAT Name', 'Agent Corrected Integer'],inplace=True)\n",
    "ongoing_phase1_cicd.dropna(subset=['Agent Corrected CAT Name', 'Agent Corrected Integer'],inplace=True)\n",
    "#removing all duplicate rows\n",
    "data_cicd_latest=data_cicd_latest.drop_duplicates(subset=['Item','establishment_type','Agent Corrected CAT Name', 'Agent Corrected Integer'],keep='first')\n",
    "print(data_cicd_latest.shape)\n",
    "ongoing_phase1_cicd=ongoing_phase1_cicd.drop_duplicates(subset=['Item','establishment_type','Agent Corrected CAT Name', 'Agent Corrected Integer'],keep='first')\n",
    "print(ongoing_phase1_cicd.shape)\n",
    "#fresh data of cicd\n",
    "data_cicd_without_duplicate=data_cicd_latest.drop_duplicates(subset=['Item','establishment_type'],keep=False)\n",
    "print(data_cicd_without_duplicate.shape)\n",
    "\n",
    "#append two dataframe\n",
    "data_cicd_final=data_cicd_without_duplicate.append(ongoing_phase1_cicd)\n",
    "#creat target string which will be used for prediction \n",
    "data_cicd_final['target']= data_cicd_final['Agent Corrected CAT Name'] + \":\" + data_cicd_final['Agent Corrected Integer']\n",
    "print(data_cicd_final.shape)\n",
    "#data_cicd_duplicate=data_cicd[data_cicd.duplicated(subset=['Item','establishment_type'],keep=False)]\n",
    "#data_cicd_duplicate.to_csv('data_cicd_duplicate.csv')\n",
    "#print(data_cicd_duplicate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767be0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31540, 8)\n"
     ]
    }
   ],
   "source": [
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "data_cicd_final['combined_text'] = data_cicd_final[['Item','establishment_type','Description']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "\n",
    "# apply data preprocessing steps on the prepared column\n",
    "data_cicd_final['processed_text']= data_cicd_final['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "\n",
    "data_cicd_final = data_cicd_final.reset_index(drop=True)\n",
    "# prepare the target column by combining 'Agent Corrected CAT Name' and 'Agent Corrected Integer'\n",
    "\n",
    "data_cicd_final=data_cicd_final.drop_duplicates(subset=['processed_text','target'],keep='first')\n",
    "print(data_cicd_final.shape)\n",
    "\n",
    "#remove rows having empty target column\n",
    "data_cicd_final.dropna(subset=['target'],inplace=True)\n",
    "\n",
    "data_cicd_final = data_cicd_final[data_cicd_final['target']!= '#REF!:#REF!']\n",
    "data_cicd_final.to_csv('data_cicd_final.csv')\n",
    "X_cicd= data_cicd_final[['Item','Description','establishment_type','processed_text']]\n",
    "y_cicd= data_cicd_final['target']\n",
    "\n",
    "# split the cicd data into train and test \n",
    "X_train_cicd, X_test_cicd, y_train_cicd, y_test_cicd = train_test_split(X_cicd, y_cicd,shuffle=True, test_size = .02, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a549eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204725, 6)\n",
      "(160865, 6)\n"
     ]
    }
   ],
   "source": [
    "#read input from historical data into dataframe\n",
    "data_df = pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/historical_data_14_01_22.csv', encoding='utf8',engine='python',usecols=['Item','Description','establishment_type','target'])\n",
    "#choose sample data from entire data\n",
    "data_df = data_df.sample(frac=1, random_state=42)\n",
    "\n",
    "#fill blanks with ''\n",
    "data_df = data_df.fillna('')\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "data_df['combined_text'] = data_df[['Item','establishment_type','Description']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "data_df['processed_text'] = data_df['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "print(data_df.shape)\n",
    "data_df=data_df.drop_duplicates(subset=['processed_text','target'],keep='first')\n",
    "print(data_df.shape)\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "X = data_df[['Item','Description','establishment_type','processed_text']]\n",
    "y = data_df['target']\n",
    "\n",
    "# split the cicd data into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20,shuffle=True, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a27ed",
   "metadata": {},
   "source": [
    "We will append the CICD data to the historical data to create the final train and test data.\n",
    "Train set has 80% of all historical data and 90% of all cicd data.\n",
    "Test set consists of 20% of historic data and 10% of all cicd data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dceeea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train.append(X_train_cicd)\n",
    "X_test_final = X_test.append(X_test_cicd)\n",
    "y_train_final = y_train.append(y_train_cicd)\n",
    "y_test_final = y_test.append(y_test_cicd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65ca7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.to_csv('final_xtrain.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123f453",
   "metadata": {},
   "source": [
    "<a id='Model Training'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd540e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 159597\n",
      "Test data size: 32804\n"
     ]
    }
   ],
   "source": [
    "print('Training data size: {}'.format(len(X_train_final)))\n",
    "print('Test data size: {}'.format(len(X_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2e6c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels : 350\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique labels : {}'.format(len(y_train.unique().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f664ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CAT_LIQUOR:535</th>\n",
       "      <td>21161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_WINE:534</th>\n",
       "      <td>15628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_TPP:531</th>\n",
       "      <td>12477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_PREPARED_FOOD,TEMP_HEATED:101,1</th>\n",
       "      <td>11158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_BEER:533</th>\n",
       "      <td>9966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_TPP_AIR_FRESHENER,TEMP_UNHEATED:773,1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_SPARKLING_WINE,TEMP_HEATED:716,1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_PREPACKAGED_FOOD_CAKES,TEMP_HEATED:718,1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_CHOCOLATE,TEMP_HEATED:706,1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_PREPACKAGED_FOOD_FRESH_BREAD,TEMP_UNHEATED:729,1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count\n",
       "target                                                   \n",
       "CAT_LIQUOR:535                                      21161\n",
       "CAT_WINE:534                                        15628\n",
       "CAT_TPP:531                                         12477\n",
       "CAT_PREPARED_FOOD,TEMP_HEATED:101,1                 11158\n",
       "CAT_BEER:533                                         9966\n",
       "...                                                   ...\n",
       "CAT_TPP_AIR_FRESHENER,TEMP_UNHEATED:773,1               1\n",
       "CAT_SPARKLING_WINE,TEMP_HEATED:716,1                    1\n",
       "CAT_PREPACKAGED_FOOD_CAKES,TEMP_HEATED:718,1            1\n",
       "CAT_CHOCOLATE,TEMP_HEATED:706,1                         1\n",
       "CAT_PREPACKAGED_FOOD_FRESH_BREAD,TEMP_UNHEATED:...      1\n",
       "\n",
       "[360 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_count = data_df.groupby(['target'],sort=False).agg({'target':'count'})\n",
    "category_count.rename(columns={'target':'count'},inplace=True)\n",
    "category_count.sort_values('count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc1a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_count.to_csv('category_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371d9c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "# Check on how the training data sets perform with varying split percentages and 1000 shuffles\n",
    "def acc_check(X1,y1):\n",
    "    t = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
    "    rf = Pipeline([('vect', CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', stop_words='english', max_df=0.85)),\n",
    "       ('tfidf', TfidfTransformer()),\n",
    "       ('clf', RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42))])\n",
    "    plt.figure()\n",
    "    for s in t:\n",
    "        scores = []\n",
    "        for i in range(1,1000):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 1-s,random_state=42)\n",
    "            rf.fit(X_train, y_train)\n",
    "            scores.append(rf.score(X_test, y_test))\n",
    "        plt.plot(s, np.mean(scores), 'bo')\n",
    "    plt.xlabel('Training set proportion (%)')\n",
    "    plt.ylabel('accuracy');\n",
    "\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba9892c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c1 = acc_check(X['processed_text'],y)\n",
    "#print('tax category',c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6d97a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75af4ab",
   "metadata": {},
   "source": [
    "The Model Pipeline consists of 1. CountVectorizer, 2. Tfidf-Transformer 3. RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a6991e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50347"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(strip_accents='ascii',token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', stop_words='english', max_df=0.85)\n",
    "\n",
    "X = vectorizer.fit_transform(X_train_final['processed_text'].values)\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69bdc710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a result dataframe to store final results\n",
    "result=X_test_final\n",
    "\n",
    "#create the model pipeline\n",
    "rf = Pipeline([('vect', CountVectorizer(strip_accents='ascii',token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', stop_words='english')),\n",
    "             #('pca',  PCA(n_components=2)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            #('auto', AutoSklearnClassifier(time_left_for_this_task=2*60, per_run_time_limit=30, n_jobs=8)),\n",
    "            ('clf', RandomForestClassifier(class_weight='balanced',n_jobs=-1,random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f66314de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents='ascii',\n",
       "                                 token_pattern='(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',\n",
       "                                 tokenizer=Non...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform model training\n",
    "rf.fit(X_train_final['processed_text'].values, y_train_final.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8d3ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "result=X_test_final\n",
    "y_pred = rf.predict(X_test_final['processed_text'].values)\n",
    "\n",
    "result['original_cat']= y_test_final.values\n",
    "result['predicted_cat'] = y_pred\n",
    "result['prediction_cat_confscore'] = rf.predict_proba(X_test_final['processed_text']).max()\n",
    "\n",
    "#\n",
    "output = {'accuracy': accuracy_score(y_pred,y_test_final),'precision_score':precision_score(y_pred,y_test_final,average='weighted'),'recall_score':recall_score(y_pred,y_test_final,average='weighted')\n",
    ",'f1_score':f1_score(y_pred,y_test_final,average='weighted')}\n",
    "\n",
    "result['confusion_matrix'] = str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbaf4402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"{'accuracy': 0.6906474820143885, 'precision_score': 0.7129271150817615, 'recall_score': 0.6906474820143885, 'f1_score': 0.6973517725442497}\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['confusion_matrix'][5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ff34487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import datetime\n",
    "# save the model to disk\n",
    "filename_primary= 'finalized_model.sav'\n",
    "joblib.dump(rf, open(filename_primary, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68dbf83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f65cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f01f76e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=10, n_jobs=-1, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771b04b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2569\n"
     ]
    }
   ],
   "source": [
    "#Check the depth of the first tree in the Random Forest\n",
    "print(rf.named_steps['clf'].estimators_[0].tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4afb1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Mean tree depth in the Random Forest: 2564.0\n"
     ]
    }
   ],
   "source": [
    "#Let’s check the depth of all the trees in the Forest:\n",
    "depths = [tree.tree_.max_depth for tree in rf.named_steps['clf'].estimators_]\n",
    "print(len(depths))\n",
    "print(f\"Mean tree depth in the Random Forest: {np.round(np.mean(depths))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a1bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "826cb6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single tree size: 379.02 MB\n"
     ]
    }
   ],
   "source": [
    "#Check the size of single tree in the disk after saving with joblib:\n",
    "\n",
    "joblib.dump(rf.named_steps['clf'].estimators_[0], \"first_tree_from_RF.joblib\") \n",
    "print(f\"Single tree size: {np.round(os.path.getsize('first_tree_from_RF.joblib') / 1024 / 1024, 2) } MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09e6cc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest size: 3755.42 MB\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(rf.named_steps['clf'].estimators_, \"RandomForest_100_trees.joblib\") \n",
    "print(f\"Random Forest size: {np.round(os.path.getsize('RandomForest_100_trees.joblib') / 1024 / 1024, 2) } MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3532caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cc457fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6906474820143885\n"
     ]
    }
   ],
   "source": [
    "#accuracy score of the model\n",
    "accuracy = rf.score(X_test_final['processed_text'].values, y_test_final)\n",
    "print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "902ef68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predicted = rf.predict_proba(X_test_final['processed_text'].values)\n",
    "# rf_loss = log_loss(y_test_final, y_predicted)\n",
    "# print(rf_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44e05685",
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_rf = Pipeline([('vect', CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', stop_words='english', max_df=0.85)),\n",
    "       ('tfidf', TfidfTransformer()),\n",
    "       ('clf', RandomForestClassifier(n_jobs=-1, random_state=42,class_weight='balanced_subsample'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96006cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.85,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents='ascii',\n",
       "                                 token_pattern='(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',\n",
       "                                 tokenizer=No...\n",
       "                 RandomForestClassifier(bootstrap=True,\n",
       "                                        class_weight='balanced_subsample',\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shallow_rf = RandomForestClassifier(max_depth=6)\n",
    "# shallow_rf.fit(X_train, y_train)\n",
    "# perform model training\n",
    "shallow_rf.fit(X_train_final['processed_text'].values, y_train_final.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f100d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352\n"
     ]
    }
   ],
   "source": [
    "#Check the depth of the first tree in the Random Forest\n",
    "print(shallow_rf.named_steps['clf'].estimators_[0].tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92e9d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single tree size: 374.66 MB\n"
     ]
    }
   ],
   "source": [
    "#Check the size of single tree in the disk after saving with joblib:\n",
    "\n",
    "joblib.dump(shallow_rf.named_steps['clf'].estimators_[0], \"first_tree_from_RF.joblib\") \n",
    "print(f\"Single tree size: {np.round(os.path.getsize('first_tree_from_RF.joblib') / 1024 / 1024, 2) } MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ccf9c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single tree size: 3748.89 MB\n"
     ]
    }
   ],
   "source": [
    "#Check the size of single tree in the disk after saving with joblib:\n",
    "\n",
    "joblib.dump(shallow_rf.named_steps['clf'].estimators_, \"all_tree_from_RF.joblib\") \n",
    "print(f\"Single tree size: {np.round(os.path.getsize('all_tree_from_RF.joblib') / 1024 / 1024, 2) } MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bec21b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6861053530057311\n"
     ]
    }
   ],
   "source": [
    "#accuracy score of the model\n",
    "accuracy = shallow_rf.score(X_test_final['processed_text'].values, y_test_final)\n",
    "print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d33f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = shallow_rf.predict(X_test_final['processed_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "033c7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "817d94ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "classification_report = metrics.classification_report(y_test_final, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef4944c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CAT_ALCOHOL,TEMP_COLD:109,1</th>\n",
       "      <td>0.234483</td>\n",
       "      <td>0.251852</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_ALCOHOL,TEMP_HEATED:109,1</th>\n",
       "      <td>0.582569</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.535865</td>\n",
       "      <td>1280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_ALCOHOL,TEMP_UNHEATED:109,1</th>\n",
       "      <td>0.165605</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_BABY_FORMULA:515</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_BABY_WIPES:513</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_WINE,TEMP_UNHEATED:534,1</th>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_WINE:534</th>\n",
       "      <td>0.865049</td>\n",
       "      <td>0.865329</td>\n",
       "      <td>0.865189</td>\n",
       "      <td>3089.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.686105</td>\n",
       "      <td>0.686105</td>\n",
       "      <td>0.686105</td>\n",
       "      <td>0.686105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.445018</td>\n",
       "      <td>0.417342</td>\n",
       "      <td>0.417562</td>\n",
       "      <td>32804.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.682442</td>\n",
       "      <td>0.686105</td>\n",
       "      <td>0.679358</td>\n",
       "      <td>32804.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 precision    recall  f1-score       support\n",
       "CAT_ALCOHOL,TEMP_COLD:109,1       0.234483  0.251852  0.242857    135.000000\n",
       "CAT_ALCOHOL,TEMP_HEATED:109,1     0.582569  0.496094  0.535865   1280.000000\n",
       "CAT_ALCOHOL,TEMP_UNHEATED:109,1   0.165605  0.091873  0.118182    283.000000\n",
       "CAT_BABY_FORMULA:515              1.000000  1.000000  1.000000      3.000000\n",
       "CAT_BABY_WIPES:513                0.555556  0.625000  0.588235      8.000000\n",
       "...                                    ...       ...       ...           ...\n",
       "CAT_WINE,TEMP_UNHEATED:534,1      0.108108  0.042105  0.060606     95.000000\n",
       "CAT_WINE:534                      0.865049  0.865329  0.865189   3089.000000\n",
       "accuracy                          0.686105  0.686105  0.686105      0.686105\n",
       "macro avg                         0.445018  0.417342  0.417562  32804.000000\n",
       "weighted avg                      0.682442  0.686105  0.679358  32804.000000\n",
       "\n",
       "[303 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(classification_report).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b959d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow_rf2 = Pipeline([('vect', CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', stop_words='english', max_df=0.85)),\n",
    "#        ('tfidf', TfidfTransformer()),\n",
    "#        ('clf', RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42, max_depth = 200, n_estimators=20 ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5bd0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow_rf2.fit(X_train_final['processed_text'].values, y_train_final.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0437705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check the size of single tree in the disk after saving with joblib:\n",
    "\n",
    "# joblib.dump(shallow_rf2.named_steps['clf'].estimators_[0], \"first_tree_from_RF.joblib\") \n",
    "# print(f\"Single tree size: {np.round(os.path.getsize('first_tree_from_RF.joblib') / 1024 / 1024, 2) } MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61ec1ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(rf.named_steps['clf'].estimators_, \"RandomForest_100_trees.joblib\") \n",
    "# print(f\"Random Forest size: {np.round(os.path.getsize('RandomForest_100_trees.joblib') / 1024 / 1024, 2) } MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04c678d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #accuracy score of the model\n",
    "# accuracy = shallow_rf2.score(X_test_final['processed_text'].values, y_test_final)\n",
    "# print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d043639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "result=X_test_final\n",
    "y_pred = shallow_rf.predict(X_test_final['processed_text'].values)\n",
    "\n",
    "result['original_cat']= y_test_final\n",
    "result['predicted_cat'] = y_pred\n",
    "\n",
    "result['prediction_cat_confscore'] = shallow_rf.predict_proba(X_test_final['processed_text'].values).max()\n",
    "\n",
    "#\n",
    "output = {'accuracy': accuracy_score(y_pred,y_test_final),'precision_score':precision_score(y_pred,y_test_final,average='weighted'),'recall_score':recall_score(y_pred,y_test_final,average='weighted')\n",
    ",'f1_score':f1_score(y_pred,y_test_final,average='weighted')}\n",
    "\n",
    "result['confusion_matrix'] = str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e9f1edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import datetime\n",
    "# # save the model to disk\n",
    "# filename_primary= 'finalized_model.sav'\n",
    "# pickle.dump(shallow_rf2, open(filename_primary, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa3c79",
   "metadata": {},
   "source": [
    "<a id='Model Saving'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dab90b",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54abd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import datetime\n",
    "# save the model to disk\n",
    "filename_primary= 'finalized_model.sav'\n",
    "joblib.dump(shallow_rf, open(filename_primary, 'wb'),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39fa7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "x=joblib.load('finalized_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f44b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x.predict(X_test_final['processed_text'].values)\n",
    "\n",
    "result['original_cat']= y_test_final\n",
    "result['predicted_cat'] = y_pred\n",
    "\n",
    "result['prediction_cat_confscore'] = x.predict_proba(X_test_final['processed_text'].values).max()\n",
    "\n",
    "#\n",
    "output = {'accuracy': accuracy_score(y_pred,y_test_final),'precision_score':precision_score(y_pred,y_test_final,average='weighted'),'recall_score':recall_score(y_pred,y_test_final,average='weighted')\n",
    ",'f1_score':f1_score(y_pred,y_test_final,average='weighted')}\n",
    "\n",
    "result['confusion_matrix'] = str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54f74d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"{'accuracy': 0.6861053530057311, 'precision_score': 0.7091731522419424, 'recall_score': 0.6861053530057311, 'f1_score': 0.6928526114294886}\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['confusion_matrix'] [5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1dd2aff3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-cf0480fe5e63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m array([\"{'accuracy': 0.7656088560885609, 'precision_score': 0.795161345923433, 'recall_score': 0.7656088560885609, 'f1_score': 0.7773461118314546}\"],\n\u001b[0m\u001b[1;32m      2\u001b[0m       dtype=object)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "array([\"{'accuracy': 0.7656088560885609, 'precision_score': 0.795161345923433, 'recall_score': 0.7656088560885609, 'f1_score': 0.7773461118314546}\"],\n",
    "      dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0273b",
   "metadata": {},
   "source": [
    "<a id='Validation and Results'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4c028",
   "metadata": {},
   "source": [
    "# Validation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score of the model\n",
    "accuracy = x.score(X_test_final['processed_text'].values, y_test_final)\n",
    "print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c11bfb",
   "metadata": {},
   "source": [
    "# Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda72230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score of the model of regression\n",
    "accuracy = x.score(X_cicd['processed_text'].values, y_cicd)\n",
    "print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8a0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b64ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report \n",
    "classification_report = metrics.classification_report(y_test_final, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ecdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(classification_report).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e978a",
   "metadata": {},
   "source": [
    "Saving the train and test data for reference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d91cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_end = int(len(data_df)*train_size)\n",
    "df_train = data_df[:train_end]\n",
    "df_test = data_df[train_end:]\n",
    "train_size_cicd=0.9\n",
    "train_end_cicd = int(len(data_cicd)*train_size_cicd)\n",
    "df2_train = data_cicd[:train_end_cicd]\n",
    "df2_test = data_cicd[train_end_cicd:]\n",
    "df2_train = df2_train[['Item','Description','establishment_type','combined_text','processed_text','target']]\n",
    "df2_test = df2_test[['Item','Description','establishment_type','combined_text','processed_text','target']]\n",
    "X_train_save = df_train.append(df2_train)\n",
    "X_test_save = df_test.append(df2_test)\n",
    "X_train_save['label'] = 'train'\n",
    "X_test_save['label'] = 'test'\n",
    "X_data = X_train_save.append(X_test_save)\n",
    "X_data.to_csv('df_traintestdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1801c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f174cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['confusion_matrix'][5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "array([\"{'accuracy': 0.7351734317343174, 'precision_score': 0.7736218733293683, 'recall_score': 0.7351734317343174, 'f1_score': 0.749379108225673}\"],\n",
    "      dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the misclassifications\n",
    "misclassifications= result.loc[result['original_cat']!=result['predicted_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(misclassifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications.to_csv('misclassifications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d9a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'accuracy': accuracy_score(y_pred,y_test_final),'precision_score':precision_score(y_pred,y_test_final,average='weighted'),'recall_score':recall_score(y_pred,y_test_final,average='weighted')\n",
    ",'f1_score':f1_score(y_pred,y_test_final,average='weighted')}\n",
    "\n",
    "result['confusion_matrix'] = str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa5e4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbe5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
