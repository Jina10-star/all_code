{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCE Refresh Newsletter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, ujson\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime, timedelta\n",
    "from tchannel import thrift\n",
    "from tchannel.sync import TChannel\n",
    "from pyspark.sql.functions import col\n",
    "import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_dir = '/mnt/cephfs/hadoop-compute/phoenix/'.format(os.environ['USER'])\n",
    "#os.chdir(user_dir)\n",
    "#print(user_dir)\n",
    "# print os.listdir(user_dir)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postmaster service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the service being used, postmaster in this case. The postmaster.thrift is an IDL\n",
    "# file. You can find it at engdoc https://engdocs.uberinternal.com/postmaster/get_started.html\n",
    "postmaster_service = thrift.load(path=\"postmaster.thrift\".format(cwd), service=\"postmaster\")\n",
    "\n",
    "# open the ujson file in hyperbahn\n",
    "# with open(\"/etc/uber/hyperbahn/hosts.json\") as f:\n",
    "#     known_peers = ujson.load(f)\n",
    "\n",
    "#     print known_peers\n",
    "# create a tchannel session in order to make use of the thrift docs\n",
    "# tchannel = TChannel(name=\"places\",known_peers=known_peers)\n",
    "tchannel = TChannel(name=\"places\", known_peers=[\"127.0.0.1:5437\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"SELECT * FROM rawdata.kafka_hp_places_workflow_controller_pe_se_comparison_nodedup\").show()\n",
    "# spark.sparkContext.getConf().getAll()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query for refreshed places last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = datetime.now()\n",
    "last_week = current + timedelta(days=-7)\n",
    "\n",
    "refresh_query = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "        W.datestr,\n",
    "        W.msg.channel,\n",
    "        W.msg.se_id,\n",
    "        W.msg.pe_id,\n",
    "        W.msg.has_name_diff,\n",
    "        W.msg.has_address_location_diff,\n",
    "        W.msg.has_status_diff,\n",
    "        T.msg.edit_task_id,\n",
    "        T.msg.is_new_task,\n",
    "        W.msg.provider,\n",
    "        P.country AS country\n",
    "    FROM\n",
    "        rawdata.kafka_hp_places_workflow_controller_pe_se_comparison_nodedup W\n",
    "    LEFT JOIN\n",
    "      rawdata_user.kafka_hp_places_workflow_controller_edit_task_from_change_request_nodedup T\n",
    "    ON\n",
    "        W.msg.request_uuid = T.msg.request_uuid\n",
    "    JOIN\n",
    "        (\n",
    "            SELECT \n",
    "                countrycode As country,\n",
    "                placeuuid AS pe_id\n",
    "            FROM\n",
    "                map_creation.mce_places_build\n",
    "            WHERE\n",
    "                buidversion in (SELECT max(buidversion) FROM map_creation.mce_places_build)\n",
    "        ) P\n",
    "    ON\n",
    "      W.msg.pe_id = P.pe_id\n",
    "   WHERE\n",
    "        T.msg.is_prod_run = true AND\n",
    "        T.datestr > '{start_date}' AND \n",
    "        T.datestr <=  '{end_date}' AND\n",
    "        W.datestr > '{start_date}' AND \n",
    "        W.datestr <=  '{end_date}' AND\n",
    "        W.msg.has_new_content = true\n",
    "\"\"\".format(start_date = last_week.strftime(\"%Y-%m-%d\"), end_date=current.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "#print refresh_query\n",
    "refreshed_place_df = spark.sql(refresh_query)\n",
    "#refreshed_place_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place curation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = refreshed_place_df.count()\n",
    "\n",
    "uniq_curation_task_count = refreshed_place_df \\\n",
    "    .where(col('edit_task_id').isNotNull()) \\\n",
    "    .select('edit_task_id') \\\n",
    "    .distinct() \\\n",
    "    .count()\n",
    "\n",
    "new_curation_task_count = refreshed_place_df \\\n",
    "    .filter(refreshed_place_df['is_new_task'] == True) \\\n",
    "    .select('edit_task_id') \\\n",
    "    .distinct() \\\n",
    "    .count()\n",
    "\n",
    "print 'Total refreshed places: ', total\n",
    "print 'Unique curation task: ', uniq_curation_task_count\n",
    "print 'New curation task: ', new_curation_task_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refreshed place channel  breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_count_df = refreshed_place_df.groupBy('channel') \\\n",
    "    .count() \\\n",
    "    .orderBy('channel')\n",
    "\n",
    "channel_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_count_dict = channel_count_df.rdd.map(lambda row: row.asDict()).collect()\n",
    "print channel_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provider channel refresh summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_refresh_count = refreshed_place_df.filter(refreshed_place_df[\"channel\"] == 'PROVIDER').count()\n",
    "name_diff_count = refreshed_place_df.filter(refreshed_place_df[\"has_name_diff\"] == True).count()\n",
    "address_diff_count = refreshed_place_df.filter(refreshed_place_df[\"has_address_location_diff\"] == True).count()\n",
    "status_diff_count = refreshed_place_df.filter(refreshed_place_df[\"has_status_diff\"] == True).count()\n",
    "print 'Provider refresh count: ', provider_refresh_count\n",
    "print 'Name diff count: ', name_diff_count\n",
    "print 'Address diff count: ', address_diff_count\n",
    "print 'Status diff count: ', status_diff_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provider channel refresh breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_breakdown_df = refreshed_place_df \\\n",
    "   .filter(refreshed_place_df[\"channel\"] == 'PROVIDER') \\\n",
    "   .groupBy('country', 'provider', 'is_new_task') \\\n",
    "   .count() \\\n",
    "   .orderBy('country', 'provider', 'is_new_task')\n",
    "\n",
    "provider_breakdown_dict = provider_breakdown_df.rdd.map(lambda row: row.asDict()).collect()\n",
    "\n",
    "#provider_breakdown_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other channel refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_refresh_count_df = refreshed_place_df \\\n",
    "    .filter(refreshed_place_df[\"channel\"] != 'PROVIDER') \\\n",
    "    .groupBy('channel') \\\n",
    "    .count() \\\n",
    "    .orderBy('channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_refresh_count_dict = other_refresh_count_df.rdd.map(lambda row: row.asDict()).collect()\n",
    "print other_refresh_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other channel breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_breakdown_df = refreshed_place_df \\\n",
    "    .filter(refreshed_place_df[\"channel\"] != 'PROVIDER') \\\n",
    "    .groupBy('country', 'channel', 'is_new_task') \\\n",
    "    .count() \\\n",
    "    .orderBy('country', 'channel', 'is_new_task')\n",
    "other_breakdown_dict = other_breakdown_df.rdd.map(lambda row: row.asDict()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_email_content = StringIO.StringIO()\n",
    "today_text = current.strftime('%Y-%m-%d')\n",
    "\n",
    "top_text = '''\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "        <head>\n",
    "            <meta charset=\"utf-8\">\n",
    "            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "            <title>Places MCE Refresh of Week from {week_start} to {week_end}</title>\n",
    "            <meta name=\"description\" content=\"Places MCE Refresh Weekly Newletter\">\n",
    "        </head>\n",
    "        <body>\n",
    "            <em>This is an autogenerated email on MCE refresh for week from {week_start} to {week_end}</em>\n",
    "\n",
    "            <div>\n",
    "                <h2>Weekly refresh totals</h2>\n",
    "                <div>Total curation tasks: <b>{refreshed_place_total}</b></div>\n",
    "                <div>Unique curation tasks: <b>{uniq_curation_task_count}</b></div>\n",
    "                <div>New curation tasks: <b>{new_curation_task_count}</b></div>\n",
    "            </div>\n",
    "'''.format(week_start=last_week.strftime(\"%Y-%m-%d\"),\n",
    "           week_end=today_text, \n",
    "           refreshed_place_total=total,\n",
    "           uniq_curation_task_count=uniq_curation_task_count,\n",
    "           new_curation_task_count=new_curation_task_count)\n",
    "refresh_email_content.write(top_text)\n",
    "\n",
    "# Provider channel refresh\n",
    "refresh_email_content.write('''\n",
    "            <div>\n",
    "                <h2>Provider Refresh</h2>\n",
    "''')\n",
    "\n",
    "# Provider channel refresh summary\n",
    "provider_summary_text = '''\n",
    "                <div>\n",
    "                    <h3>Summary</h3>\n",
    "                    <table>\n",
    "                        <tr><td>Total: </td><td>{}</td></tr>\n",
    "                        <tr><td>Name diff: </td><td>{}</td></tr>\n",
    "                        <tr><td>Address diff: </td><td>{}</td></tr>\n",
    "                        <tr><td>Status diff: </td><td>{}</td></tr>\n",
    "                    </table>\n",
    "                </div>\n",
    "                '''.format(provider_refresh_count, name_diff_count, address_diff_count, status_diff_count)\n",
    "refresh_email_content.write(provider_summary_text)\n",
    "\n",
    "# Provider channel refresh breakdowns start\n",
    "refresh_email_content.write('''\n",
    "                <div>\n",
    "                    <h3>Breakdowns</h3>\n",
    "                    <div>\n",
    "                        <table>\n",
    "                            <tr>\n",
    "                                <th>Country</th><th>Provider</th><th>Task Type</th><th>Count</th>\n",
    "                            </tr>''')\n",
    "\n",
    "\n",
    "for row in provider_breakdown_dict:\n",
    "    refresh_email_content.write('''\n",
    "                           <tr>\n",
    "                                <td>{country}</td><td>{provider}</td><td>{task_type}</td><td>{count}</td>\n",
    "                           </tr>\n",
    "                '''.format(country=row['country'],\n",
    "                           provider=row['provider'],\n",
    "                           task_type='New' if row['is_new_task'] else 'Updated',\n",
    "                           count=row['count']))\n",
    "\n",
    "# Provider channel refresh end\n",
    "refresh_email_content.write('''\n",
    "                        </table>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>''')\n",
    "\n",
    "\n",
    "# Other channel refresh\n",
    "refresh_email_content.write('''\n",
    "            <div>\n",
    "            <h2>Other Channels Refresh</h2>\n",
    "                <div>\n",
    "                    <h3>Summary</h3>\n",
    "                    <div>\n",
    "                        <table>\n",
    "                            <tr><th>Channel</th><th>Count</th></tr>''')\n",
    "\n",
    "for row in other_refresh_count_dict:\n",
    "    refresh_email_content.write('''\n",
    "                           <tr><td>{channel}</td><td>{count}</td></tr>\n",
    "                '''.format(channel=row['channel'], count=row['count'])\n",
    "    )\n",
    "\n",
    "\n",
    "# Other channel refresh breakdowns start\n",
    "refresh_email_content.write('''\n",
    "                        </table>\n",
    "                    </div>\n",
    "                </div>\n",
    "                <div>\n",
    "                    <h3>Breakdowns</h3>\n",
    "                    <div>\n",
    "                        <table>\n",
    "                            <tr>\n",
    "                                <th>Country</th><th>Channel</th><th>Task Type</th><th>Count</th>\n",
    "                            </tr>''')\n",
    "\n",
    "for row in other_breakdown_dict:\n",
    "    refresh_email_content.write('''\n",
    "                           <tr>\n",
    "                                <td>{country}</td><td>{channel}</td><td>{task_type}</td><td>{count}</td>\n",
    "                           </tr>\n",
    "                '''.format(country=row['country'],\n",
    "                           channel=row['channel'],\n",
    "                           task_type='New' if row['is_new_task'] else 'Updated',\n",
    "                           count=row['count']))\n",
    "\n",
    "    \n",
    "# Provider channel refresh breakdowns end\n",
    "refresh_email_content.write('''\n",
    "                        </table>\n",
    "                    </div>\n",
    "                </div>''')\n",
    "\n",
    "# Bottom text\n",
    "refresh_email_content.write('''\n",
    "            </div>\n",
    "        </body>\n",
    "    </html>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print refresh_email_content.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_arg = current.strftime('Places MCE Refresh Email of Week %Y-%m-%d')\n",
    "\n",
    "rawEmail_struct = postmaster_service.RawEmail(subject = subject_arg, richBody = refresh_email_content.getvalue())\n",
    "content_arg = postmaster_service.Content(rawEmail = rawEmail_struct)\n",
    "\n",
    "to_arg = postmaster_service.Recipient(emailAddress = 'maps-places@uber.com')\n",
    "cc_arg = [postmaster_service.Recipient(emailAddress = 'maps-places-pgms@uber.com')]\n",
    "\n",
    "recipients_struct = postmaster_service.Recipients(to = to_arg, cc = cc_arg)\n",
    "\n",
    "fromEmail_arg = 'noreply@uber.com'\n",
    "messageType_arg = 'internal'\n",
    "request_struct = postmaster_service.Request(fromEmail = fromEmail_arg, recipients = recipients_struct, content = content_arg, messageType=messageType_arg)\n",
    "\n",
    "future = tchannel.thrift(postmaster_service.Postmaster.testEmail(request = request_struct))\n",
    "print future.result(timeout = 30000).body"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (phx2 Client Mode Secure)",
   "language": "python",
   "name": "pyspark_phx2_secure"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
