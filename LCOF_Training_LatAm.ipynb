{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data: features & labels\n",
    "df_features_dict = {}\n",
    "df_labels_dict = {}\n",
    "\n",
    "num_feature_files = 15\n",
    "num_label_files = 15\n",
    "\n",
    "for i in range(1, num_feature_files):\n",
    "    df_features_dict[i] = pd.read_csv(f'lcof_hourly_features_{i}.csv')\n",
    "\n",
    "for i in range(1, num_label_files):\n",
    "    df_labels_dict[i] = pd.read_csv(f'lcof_hourly_labels_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_frames = [df_features_dict[1], df_features_dict[2], df_features_dict[3],\n",
    "                      df_features_dict[4], df_features_dict[5], df_features_dict[6],\n",
    "                      df_features_dict[7], df_features_dict[8], df_features_dict[9],\n",
    "                      df_features_dict[10], df_features_dict[11], df_features_dict[12],\n",
    "                      df_features_dict[13], df_features_dict[14]\n",
    "                     ]\n",
    "\n",
    "df_labels_frames = [df_labels_dict[1], df_labels_dict[2], df_labels_dict[3],\n",
    "                    df_labels_dict[4], df_labels_dict[5], df_labels_dict[6],\n",
    "                    df_labels_dict[7], df_labels_dict[8], df_labels_dict[9],\n",
    "                    df_labels_dict[10], df_labels_dict[11], df_labels_dict[12],\n",
    "                    df_labels_dict[13], df_labels_dict[14]\n",
    "                   ]\n",
    "\n",
    "df_features = pd.concat(df_features_frames, ignore_index=True)\n",
    "df_labels = pd.concat(df_labels_frames, ignore_index=True)\n",
    "\n",
    "df_features.drop('num_plans', axis=1, inplace=True)\n",
    "df_labels.drop('num_plans', axis=1, inplace=True)\n",
    "\n",
    "df = pd.merge(df_features, df_labels,\n",
    "              how='inner',\n",
    "              left_on=['datestr', 'city_id', 'hour_of_day'],\n",
    "              right_on=['datestr', 'city_id', 'hour_of_day']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset size = 20933; the new dataset size = 20509\n"
     ]
    }
   ],
   "source": [
    "# Filter out outliers\n",
    "df_clean = df[df['hour_gb_gamma_95'] < 3].reset_index(drop=True)\n",
    "print(f\"The original dataset size = {len(df)}; the new dataset size = {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "gb_100 = df_clean['hour_gb_gamma_100']\n",
    "gb_99 = df_clean['hour_gb_gamma_99']\n",
    "gb_95 = df_clean['hour_gb_gamma_95']\n",
    "gb_90 = df_clean['hour_gb_gamma_90']\n",
    "\n",
    "fare_100 = df_clean['hour_fare_gamma_100']\n",
    "fare_99 = df_clean['hour_fare_gamma_99']\n",
    "fare_95 = df_clean['hour_fare_gamma_95']\n",
    "fare_90 = df_clean['hour_fare_gamma_90']\n",
    "\n",
    "y = gb_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df_clean.loc[:, ['market_log_cr',\n",
    "                     'market_log_eta',\n",
    "                     'market_log_fare_p50_scale',\n",
    "                     'market_surge'\n",
    "                    ]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training & Test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x1, x2, x3, x, y, b0, b1, b2, b3):\n",
    "    alpha = 1 - 1/np.maximum(x, 1)**b3\n",
    "    return np.mean((b0 + b1*x1 + b2*x2 + alpha*x3 - y)**2 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x1, x2, x3, x, y, b0, b1, b2, b3):\n",
    "    alpha = 1 - 1/np.maximum(x, 1)**b3\n",
    "    re = b0 + b1*x1 + b2*x2 + alpha*x3 - y\n",
    "    \n",
    "    db0 = np.mean(re)\n",
    "    db1 = np.mean(re * x1)\n",
    "    db2 = np.mean(re * x2)\n",
    "    db3 = np.mean(re * x3 * b3 * np.maximum(x, 1)**(-b3-1))\n",
    "    \n",
    "    return db0, db1, db2, db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(n_iter=20, step_size=400, lr=0.01, tol=1e-03):\n",
    "    N = len(X_train)\n",
    "    num_iters = N // step_size\n",
    "    \n",
    "    b0 = 0.0\n",
    "    b1 = 1.0\n",
    "    b2 = 2.0\n",
    "    b3 = 1.0\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    best_b0 = b0\n",
    "    best_b1 = b1\n",
    "    best_b2 = b2\n",
    "    best_b3 = b3\n",
    "    \n",
    "    best_test_loss = np.inf\n",
    "    best_iter = 0\n",
    "    \n",
    "    for it in range(n_iter):\n",
    "        print(f\"We are in iteration: {it+1} ...\")\n",
    "        \n",
    "        # Reshuffle\n",
    "        ids = list(range(N))\n",
    "        np.random.shuffle(ids)\n",
    "        \n",
    "        X_train_ids = X_train.reset_index(drop=True)\n",
    "        y_train_ids = y_train.reset_index(drop=True)\n",
    "        \n",
    "        train_loss = 0\n",
    "        for idx in range(num_iters):\n",
    "            y = y_train_ids[ids][idx*step_size:(idx+1)*step_size]\n",
    "            x1 = X_train_ids['market_log_cr'][ids][idx*step_size:(idx+1)*step_size]\n",
    "            x2 = X_train_ids['market_log_eta'][ids][idx*step_size:(idx+1)*step_size]\n",
    "            x3 = X_train_ids['market_log_fare_p50_scale'][ids][idx*step_size:(idx+1)*step_size]\n",
    "            x = X_train_ids['market_surge'][ids][idx*step_size:(idx+1)*step_size]\n",
    "            \n",
    "            cur_loss = calculate_loss(x1, x2, x3, x, y, b0, b1, b2, b3)\n",
    "            train_loss += cur_loss\n",
    "            \n",
    "            db0, db1, db2, db3 = grad(x1, x2, x3, x, y, b0, b1, b2, b3)\n",
    "            \n",
    "            if np.all(np.abs([lr*db0, lr*db1, lr*db2, lr*db3]) <= tol):\n",
    "                break\n",
    "            \n",
    "            b0 -= lr * db0\n",
    "            b1 -= lr * db1\n",
    "            b2 -= lr * db2\n",
    "            b3 -= lr * db3\n",
    "        \n",
    "        train_loss /= num_iters\n",
    "        print(f\"Train Loss = {train_loss}\")\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Test loss\n",
    "        y = y_test\n",
    "        x1 = X_test['market_log_cr']\n",
    "        x2 = X_test['market_log_eta']\n",
    "        x3 = X_test['market_log_fare_p50_scale']\n",
    "        x = X_test['market_surge']\n",
    "        test_loss = calculate_loss(x1, x2, x3, x, y, b0, b1, b2, b3)\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_iter = it\n",
    "\n",
    "            best_b0 = b0\n",
    "            best_b1 = b1\n",
    "            best_b2 = b2\n",
    "            best_b3 = b3\n",
    "        \n",
    "        print(f\"Test Loss = {test_loss}\")\n",
    "        \n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    return best_b0, best_b1, best_b2, best_b3, best_test_loss, best_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are in iteration: 1 ...\n",
      "Train Loss = 2.240583912689002\n",
      "Test Loss = 1.2694832042738755\n",
      "We are in iteration: 2 ...\n",
      "Train Loss = 0.8524069818960224\n",
      "Test Loss = 0.5667851869333339\n",
      "We are in iteration: 3 ...\n",
      "Train Loss = 0.44763645496636906\n",
      "Test Loss = 0.3538453644433986\n",
      "We are in iteration: 4 ...\n",
      "Train Loss = 0.3217792809653806\n",
      "Test Loss = 0.2812166598652775\n",
      "We are in iteration: 5 ...\n",
      "Train Loss = 0.2743957681108104\n",
      "Test Loss = 0.2488689777848725\n",
      "We are in iteration: 6 ...\n",
      "Train Loss = 0.24959195533458386\n",
      "Test Loss = 0.22906880278937847\n",
      "We are in iteration: 7 ...\n",
      "Train Loss = 0.23198174672013303\n",
      "Test Loss = 0.21368926386867979\n",
      "We are in iteration: 8 ...\n",
      "Train Loss = 0.04540479300887465\n",
      "Test Loss = 0.21112446541782745\n",
      "We are in iteration: 9 ...\n",
      "Train Loss = 0.10508775388092803\n",
      "Test Loss = 0.2040166980367939\n",
      "We are in iteration: 10 ...\n",
      "Train Loss = 0.12904449239825538\n",
      "Test Loss = 0.19652619256256382\n",
      "We are in iteration: 11 ...\n",
      "Train Loss = 0.025375777930928087\n",
      "Test Loss = 0.19526408357386896\n",
      "We are in iteration: 12 ...\n",
      "Train Loss = 0.0030019032275652164\n",
      "Test Loss = 0.19526408357386896\n",
      "We are in iteration: 13 ...\n",
      "Train Loss = 0.009428809850656894\n",
      "Test Loss = 0.19513625971799706\n",
      "We are in iteration: 14 ...\n",
      "Train Loss = 0.05704591586977887\n",
      "Test Loss = 0.19242251098182156\n",
      "We are in iteration: 15 ...\n",
      "Train Loss = 0.0037189034297813667\n",
      "Test Loss = 0.19242251098182156\n",
      "We are in iteration: 16 ...\n",
      "Train Loss = 0.008410297798515643\n",
      "Test Loss = 0.19210468414265366\n",
      "We are in iteration: 17 ...\n",
      "Train Loss = 0.14196107338326622\n",
      "Test Loss = 0.18430057746771936\n",
      "We are in iteration: 18 ...\n",
      "Train Loss = 0.025451495562932705\n",
      "Test Loss = 0.18313034223458427\n",
      "We are in iteration: 19 ...\n",
      "Train Loss = 0.0038500971846759467\n",
      "Test Loss = 0.18313034223458427\n",
      "We are in iteration: 20 ...\n",
      "Train Loss = 0.0226983498234619\n",
      "Test Loss = 0.18199665464578518\n",
      "We are in iteration: 21 ...\n",
      "Train Loss = 0.05128792612186241\n",
      "Test Loss = 0.1792059691155343\n",
      "We are in iteration: 22 ...\n",
      "Train Loss = 0.054383337869105194\n",
      "Test Loss = 0.1767620473798205\n",
      "We are in iteration: 23 ...\n",
      "Train Loss = 0.007344877870621904\n",
      "Test Loss = 0.1765221999936614\n",
      "We are in iteration: 24 ...\n",
      "Train Loss = 0.05702852510408566\n",
      "Test Loss = 0.1737840951670153\n",
      "We are in iteration: 25 ...\n",
      "Train Loss = 0.03229049232447873\n",
      "Test Loss = 0.17237878764886996\n",
      "We are in iteration: 26 ...\n",
      "Train Loss = 0.0041394629785684945\n",
      "Test Loss = 0.17237878764886996\n",
      "We are in iteration: 27 ...\n",
      "Train Loss = 0.022068319615809167\n",
      "Test Loss = 0.1715410039682666\n",
      "We are in iteration: 28 ...\n",
      "Train Loss = 0.06635204568297608\n",
      "Test Loss = 0.16814030710968403\n",
      "We are in iteration: 29 ...\n",
      "Train Loss = 0.027367915247892092\n",
      "Test Loss = 0.16696088861794112\n",
      "We are in iteration: 30 ...\n",
      "Train Loss = 0.01826553621772705\n",
      "Test Loss = 0.166256530164529\n",
      "We are in iteration: 31 ...\n",
      "Train Loss = 0.03701203849678828\n",
      "Test Loss = 0.16447349583950083\n",
      "We are in iteration: 32 ...\n",
      "Train Loss = 0.02543560130818219\n",
      "Test Loss = 0.16352844718730397\n",
      "We are in iteration: 33 ...\n",
      "Train Loss = 0.0033939824117856536\n",
      "Test Loss = 0.16352844718730397\n",
      "We are in iteration: 34 ...\n",
      "Train Loss = 0.011487411458750207\n",
      "Test Loss = 0.16313383063775197\n",
      "We are in iteration: 35 ...\n",
      "Train Loss = 0.01305940580755902\n",
      "Test Loss = 0.16263322130483365\n",
      "We are in iteration: 36 ...\n",
      "Train Loss = 0.021738487911921282\n",
      "Test Loss = 0.16173982384010835\n",
      "We are in iteration: 37 ...\n",
      "Train Loss = 0.009373245134169721\n",
      "Test Loss = 0.16149471682319005\n",
      "We are in iteration: 38 ...\n",
      "Train Loss = 0.007402564721420059\n",
      "Test Loss = 0.16131375023367442\n",
      "We are in iteration: 39 ...\n",
      "Train Loss = 0.003011850885561295\n",
      "Test Loss = 0.16131375023367442\n",
      "We are in iteration: 40 ...\n",
      "Train Loss = 0.03208943256761403\n",
      "Test Loss = 0.15976694512776154\n",
      "We are in iteration: 41 ...\n",
      "Train Loss = 0.007526465994529276\n",
      "Test Loss = 0.15953005559873829\n",
      "We are in iteration: 42 ...\n",
      "Train Loss = 0.02531836214560311\n",
      "Test Loss = 0.15855604819292068\n",
      "We are in iteration: 43 ...\n",
      "Train Loss = 0.055447125139608436\n",
      "Test Loss = 0.1562459273029264\n",
      "We are in iteration: 44 ...\n",
      "Train Loss = 0.023473764768718937\n",
      "Test Loss = 0.155294636340335\n",
      "We are in iteration: 45 ...\n",
      "Train Loss = 0.03895925310073319\n",
      "Test Loss = 0.15348889148913902\n",
      "We are in iteration: 46 ...\n",
      "Train Loss = 0.01711828705835255\n",
      "Test Loss = 0.15278911459919275\n",
      "We are in iteration: 47 ...\n",
      "Train Loss = 0.011132560323687209\n",
      "Test Loss = 0.15239768673076057\n",
      "We are in iteration: 48 ...\n",
      "Train Loss = 0.024684512062289197\n",
      "Test Loss = 0.15152723869500237\n",
      "We are in iteration: 49 ...\n",
      "Train Loss = 0.031680644515406975\n",
      "Test Loss = 0.15038166802050368\n",
      "We are in iteration: 50 ...\n",
      "Train Loss = 0.011378298180573749\n",
      "Test Loss = 0.15006950579190126\n",
      "We are in iteration: 51 ...\n",
      "Train Loss = 0.0027137519551654323\n",
      "Test Loss = 0.15006950579190126\n",
      "We are in iteration: 52 ...\n",
      "Train Loss = 0.010931187216098438\n",
      "Test Loss = 0.14970768357806385\n",
      "We are in iteration: 53 ...\n",
      "Train Loss = 0.010284222325332559\n",
      "Test Loss = 0.14929354543111933\n",
      "We are in iteration: 54 ...\n",
      "Train Loss = 0.021701897764043212\n",
      "Test Loss = 0.14845104948460514\n",
      "We are in iteration: 55 ...\n",
      "Train Loss = 0.013240227632231948\n",
      "Test Loss = 0.14795734650145317\n",
      "We are in iteration: 56 ...\n",
      "Train Loss = 0.0066693603730359876\n",
      "Test Loss = 0.14779708192675117\n",
      "We are in iteration: 57 ...\n",
      "Train Loss = 0.021711606976643864\n",
      "Test Loss = 0.14707813853733143\n",
      "We are in iteration: 58 ...\n",
      "Train Loss = 0.003603739702178857\n",
      "Test Loss = 0.14707813853733143\n",
      "We are in iteration: 59 ...\n",
      "Train Loss = 0.00786514349711154\n",
      "Test Loss = 0.1469070957263089\n",
      "We are in iteration: 60 ...\n",
      "Train Loss = 0.0028558475473134106\n",
      "Test Loss = 0.1469070957263089\n",
      "We are in iteration: 61 ...\n",
      "Train Loss = 0.01017939619493753\n",
      "Test Loss = 0.14660171507331068\n",
      "We are in iteration: 62 ...\n",
      "Train Loss = 0.003306800169745592\n",
      "Test Loss = 0.14660171507331068\n",
      "We are in iteration: 63 ...\n",
      "Train Loss = 0.003713017118253251\n",
      "Test Loss = 0.14660171507331068\n",
      "We are in iteration: 64 ...\n",
      "Train Loss = 0.012133110695431286\n",
      "Test Loss = 0.14627778939949915\n",
      "We are in iteration: 65 ...\n",
      "Train Loss = 0.006986313955875395\n",
      "Test Loss = 0.14606243331387472\n",
      "We are in iteration: 66 ...\n",
      "Train Loss = 0.014612673390631705\n",
      "Test Loss = 0.14569787216410846\n",
      "We are in iteration: 67 ...\n",
      "Train Loss = 0.014831200133571571\n",
      "Test Loss = 0.14514374058483112\n",
      "We are in iteration: 68 ...\n",
      "Train Loss = 0.004087991681776375\n",
      "Test Loss = 0.14514374058483112\n",
      "We are in iteration: 69 ...\n",
      "Train Loss = 0.003797485989325283\n",
      "Test Loss = 0.14514374058483112\n",
      "We are in iteration: 70 ...\n",
      "Train Loss = 0.022936741556481854\n",
      "Test Loss = 0.1442971251534882\n",
      "We are in iteration: 71 ...\n",
      "Train Loss = 0.006754221900316479\n",
      "Test Loss = 0.1441056091053821\n",
      "We are in iteration: 72 ...\n",
      "Train Loss = 0.002792870125699216\n",
      "Test Loss = 0.1441056091053821\n",
      "We are in iteration: 73 ...\n",
      "Train Loss = 0.00982779500361961\n",
      "Test Loss = 0.14381744693869966\n",
      "We are in iteration: 74 ...\n",
      "Train Loss = 0.006971175446085937\n",
      "Test Loss = 0.14380734628776465\n",
      "We are in iteration: 75 ...\n",
      "Train Loss = 0.015856952729833947\n",
      "Test Loss = 0.1432722301200785\n",
      "We are in iteration: 76 ...\n",
      "Train Loss = 0.0030504643647007268\n",
      "Test Loss = 0.1432722301200785\n",
      "We are in iteration: 77 ...\n",
      "Train Loss = 0.00320465001519701\n",
      "Test Loss = 0.1432722301200785\n",
      "We are in iteration: 78 ...\n",
      "Train Loss = 0.0067653759873130435\n",
      "Test Loss = 0.1431173558624157\n",
      "We are in iteration: 79 ...\n",
      "Train Loss = 0.006711058813259595\n",
      "Test Loss = 0.14295775315476275\n",
      "We are in iteration: 80 ...\n",
      "Train Loss = 0.010938649384543874\n",
      "Test Loss = 0.1425797904227595\n",
      "We are in iteration: 81 ...\n",
      "Train Loss = 0.00605908901993441\n",
      "Test Loss = 0.1424581178718182\n",
      "We are in iteration: 82 ...\n",
      "Train Loss = 0.014016626378465048\n",
      "Test Loss = 0.14200043745159427\n",
      "We are in iteration: 83 ...\n",
      "Train Loss = 0.011643860349615764\n",
      "Test Loss = 0.14170289623189022\n",
      "We are in iteration: 84 ...\n",
      "Train Loss = 0.01894496882552844\n",
      "Test Loss = 0.14106423948946434\n",
      "We are in iteration: 85 ...\n",
      "Train Loss = 0.015436070062181801\n",
      "Test Loss = 0.1406547538864515\n",
      "We are in iteration: 86 ...\n",
      "Train Loss = 0.0027023339031338922\n",
      "Test Loss = 0.1406547538864515\n",
      "We are in iteration: 87 ...\n",
      "Train Loss = 0.0028097483012561176\n",
      "Test Loss = 0.1406547538864515\n",
      "We are in iteration: 88 ...\n",
      "Train Loss = 0.006566992298398706\n",
      "Test Loss = 0.14042332931109933\n",
      "We are in iteration: 89 ...\n",
      "Train Loss = 0.0038202847654067763\n",
      "Test Loss = 0.14042332931109933\n",
      "We are in iteration: 90 ...\n",
      "Train Loss = 0.014913445267632395\n",
      "Test Loss = 0.1398215777646895\n",
      "We are in iteration: 91 ...\n",
      "Train Loss = 0.004282689878145509\n",
      "Test Loss = 0.1398215777646895\n",
      "We are in iteration: 92 ...\n",
      "Train Loss = 0.0032501241162310756\n",
      "Test Loss = 0.1398215777646895\n",
      "We are in iteration: 93 ...\n",
      "Train Loss = 0.006449421505683136\n",
      "Test Loss = 0.13966425335557622\n",
      "We are in iteration: 94 ...\n",
      "Train Loss = 0.007270036124491072\n",
      "Test Loss = 0.13955761804893885\n",
      "We are in iteration: 95 ...\n",
      "Train Loss = 0.01431005440588788\n",
      "Test Loss = 0.1390695679589132\n",
      "We are in iteration: 96 ...\n",
      "Train Loss = 0.046516693775541025\n",
      "Test Loss = 0.1373178332972052\n",
      "We are in iteration: 97 ...\n",
      "Train Loss = 0.006732322965708953\n",
      "Test Loss = 0.1371994574386069\n",
      "We are in iteration: 98 ...\n",
      "Train Loss = 0.013826932650984426\n",
      "Test Loss = 0.13676601670636251\n",
      "We are in iteration: 99 ...\n",
      "Train Loss = 0.0031451103990416036\n",
      "Test Loss = 0.13676601670636251\n",
      "We are in iteration: 100 ...\n",
      "Train Loss = 0.01444430739697995\n",
      "Test Loss = 0.13642031467885057\n"
     ]
    }
   ],
   "source": [
    "best_b0, best_b1, best_b2, best_b3, best_test_loss, best_iter = main(n_iter=100, lr=0.01, step_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3664190120791024 0.046007235456259656 0.4023823860464308 1.305831223967143 0.13642031467885057 99\n"
     ]
    }
   ],
   "source": [
    "print(best_b0, best_b1, best_b2, best_b3, best_test_loss, best_iter)\n",
    "# gamma = 0.95, fare_scaling = p50\n",
    "# -- 1.386476124588059 0.05494968988410009 0.4444485446726071 1.3957356824560634 0.1446741220723692 49\n",
    "# -- 1.3664190120791024 0.046007235456259656 0.4023823860464308 1.305831223967143 0.13642031467885057 99"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "03. Python 3.6 (General DS)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
