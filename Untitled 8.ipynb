{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a065862",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "thanking_words = ['thanks', 'kind regards', 'sincerely', 'thank you','best regards','thanks regards', 'regards', 'all the best', 'thank you best regards', 'best']\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def get_email_body(x):\n",
    "    for word in thanking_words:\n",
    "        if x.find(word+'\\n') != -1:\n",
    "            return x.split(word)[0]\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_text(subject, email_body):\n",
    "\n",
    "    sw = set(stopwords.words('english'))\n",
    "    # 1. Init Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    message = subject + \" \" + email_body\n",
    "    if message.find('[ar-freight]')!= -1:\n",
    "        message = message.replace('[ar-freight]','')\n",
    "    #lowering and removing punctuation\n",
    "    message = re.sub(r'[^\\w\\s]','', message.lower())\n",
    "    #removing extra email text after thanking salutations\n",
    "    message = get_email_body(message)\n",
    "    #removing the numerical values and working only with text values\n",
    "    message = re.sub('[^a-zA-Z]', \" \", message )\n",
    "    #removing the stopwords\n",
    "    message = ' '.join([word for word in message.split() if word not in sw ])\n",
    "    #lemmatizing the text\n",
    "    message =  \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(message) if w not in string.punctuation])\n",
    "    print(\"message is : \",message)\n",
    "    return message\n",
    "\n",
    "def classify_email_intent(subject, email_body):\n",
    "    # def get_intent(message):\n",
    "    message = preprocess_text(subject, email_body)\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    payload = '{\"text\": \"'+message+'\",\"message_id\": \"a\"}'\n",
    "    raw_response = requests.post(\n",
    "        \"http://localhost:5050/model/parse\",\n",
    "        verify=False,data=payload,headers=headers).json()\n",
    "\n",
    "    #print(raw_response)\n",
    "\n",
    "    \n",
    "    if raw_response['intent']['name'] == 'nlu_fallback':\n",
    "        return 'Others',raw_response['intent']['confidence']\n",
    "\n",
    "    elif raw_response['intent']['name'] == 'Account_Information_Intent':\n",
    "        if raw_response['intent']['confidence'] <= 0.85:\n",
    "            return 'Others',1-raw_response['intent']['confidence']\n",
    "\n",
    "        if message.find('credit')!= -1 and message.find('increase')!= -1:\n",
    "            return 'Others',1 - raw_response['intent']['confidence']\n",
    "            \n",
    "        if message.find('block') != -1:\n",
    "            return 'Others',1 - raw_response['intent']['confidence']\n",
    "        \n",
    "        if message.find('suspension') != -1:\n",
    "            return 'Others',1 - raw_response['intent']['confidence']\n",
    "\n",
    "    \n",
    "    elif raw_response['intent']['name'] == None:\n",
    "        return 'Others',0\n",
    "    \n",
    "    \n",
    "    \n",
    "    return raw_response['intent']['name'],raw_response['intent']['confidence']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33889c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37c572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a065515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f38e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
