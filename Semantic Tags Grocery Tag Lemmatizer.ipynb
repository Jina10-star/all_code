{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Thanks for using Drogon for your interactive Spark application. We update Drogon/SparkMagic as often as possible to make it easier, faster and more reliable for you. Have a question or feedback? Ping us on [uChat](https://uchat.uberinternal.com/uber/channels/spark).</span>\n",
    "\n",
    "What's New\n",
    "- Now you can use `%%configure` and `%%spark` magics to configure and start a Spark session (deprecating hard-to-use `%load_ext sparkmagic.magics` and `manage_spark` magics). Check out [this example](https://workbench.uberinternal.com/explore/knowledge/localfile/cwang/sparkmagic_python2_example.ipynb) for more details.\n",
    "- Improved `%%configure` magic. You now can use it to make all Spark and Drogon configurations from within notebook itself. Check out our [latest documentation & examples](https://docs.google.com/document/d/1mkYtDHquh4FjqTeA0Fxii8lyV-P6qzmoABhmmRwm_00/edit#heading=h.xn14pmoorsn0) for more details.\n",
    "- Bug fixes and performance updates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Tags Grocery Tag Lemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs:\n",
       "<pre>{\n",
       "  \"pyFiles\": [], \n",
       "  \"kind\": \"spark\", \n",
       "  \"proxyUser\": \"radhesh\", \n",
       "  \"sparkEnv\": \"SPARK_24\", \n",
       "  \"driverMemory\": \"8g\", \n",
       "  \"queue\": \"uber_eats_ml\", \n",
       "  \"conf\": {\n",
       "    \"spark.dynamicAllocation.enabled\": \"true\", \n",
       "    \"spark.driver.memory\": \"12g\", \n",
       "    \"spark.dynamicAllocation.maxExecutors\": 200, \n",
       "    \"spark.driver.memoryOverhead\": \"4g\", \n",
       "    \"spark.executor.memoryOverhead\": \"4g\", \n",
       "    \"spark.hadoop.hadoop.security.authentication\": \"simple\", \n",
       "    \"spark.dynamicAllocation.minExecutors\": 100, \n",
       "    \"spark.executor.memory\": \"12g\", \n",
       "    \"spark.dynamicAllocation.initialExecutors\": 100, \n",
       "    \"spark.shuffle.service.enabled\": true, \n",
       "    \"spark.sql.shuffle.partitions\": 500\n",
       "  }, \n",
       "  \"executorCores\": 2, \n",
       "  \"driverCores\": 2, \n",
       "  \"jars\": [\n",
       "    \"/user/radhesh/spark-corenlp-0.4.0-spark2.4-scala2.11.jar\", \n",
       "    \"/user/radhesh/stanford-corenlp-3.9.1-models.jar\"\n",
       "  ], \n",
       "  \"executorMemory\": \"12g\", \n",
       "  \"drogonHeaders\": {\n",
       "    \"X-DROGON-CLUSTER\": \"phx2/secure\"\n",
       "  }\n",
       "}</pre><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "  \"pyFiles\": [],\n",
    "  \"kind\": \"spark\",\n",
    "  \"proxyUser\": \"radhesh\",\n",
    "  \"sparkEnv\": \"SPARK_24\",\n",
    "  \"driverMemory\": \"8g\",\n",
    "  \"queue\": \"uber_eats_ml\",\n",
    "  \"conf\": { \n",
    "      \"spark.dynamicAllocation.enabled\": \"true\",\n",
    "      \"spark.dynamicAllocation.initialExecutors\":100,\n",
    "      \"spark.dynamicAllocation.minExecutors\":100,\n",
    "      \"spark.dynamicAllocation.maxExecutors\" : 200,\n",
    "      \"spark.executor.memory\": \"12g\",\n",
    "      \"spark.executor.memoryOverhead\": \"4g\",\n",
    "      \"spark.driver.memory\": \"12g\",\n",
    "      \"spark.driver.memoryOverhead\" : \"4g\",\n",
    "      \"spark.hadoop.hadoop.security.authentication\": \"simple\",\n",
    "      \"spark.shuffle.service.enabled\" : true,\n",
    "      \"spark.sql.shuffle.partitions\" : 500\n",
    "},\n",
    "  \"executorCores\": 2,\n",
    "  \"driverCores\": 2,\n",
    "  \"executorMemory\": \"12g\",\n",
    "    \"jars\": [\"/user/radhesh/spark-corenlp-0.4.0-spark2.4-scala2.11.jar\",\n",
    "            \"/user/radhesh/stanford-corenlp-3.9.1-models.jar\"],\n",
    "   \"drogonHeaders\": {\n",
    "    \"X-DROGON-CLUSTER\": \"phx2/secure\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application (can take 60s or more)...\n",
      "Starting heartbeat thread...done.\n",
      "Waiting for Drogon session to be ready.....................................\n",
      "Drogon session is ready.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>Drogon Session ID</th><th>Spark Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>543414791</td><td>application_1670874807583_3088162</td><td>spark</td><td>idle</td><td></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "\n",
      "\n",
      "Cell execution took 71 seconds.\n",
      "res1: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@4ffcfee2"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [semantic_tags: string]"
     ]
    }
   ],
   "source": [
    "var input = spark.sql(\"SELECT DISTINCT semantic_tags FROM uber_eats.semantic_tags_grocery_data\").filter(row => !(row.mkString(\"\").isEmpty && row.length>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       semantic_tags|\n",
      "+--------------------+\n",
      "|               water|\n",
      "|spice pickle:spic...|\n",
      "|liquor:drink:alco...|\n",
      "|dairy egg:concess...|\n",
      "|    candy gum:market|\n",
      "|popcorn pretzel n...|\n",
      "|spirit:spirit gin...|\n",
      "|alcohlic beverage...|\n",
      "|snack:cake biscui...|\n",
      "|liquor:booze:beve...|\n",
      "|import drink:exot...|\n",
      "|flour:frozen pizz...|\n",
      "|essential:milk:mi...|\n",
      "|spice season:froz...|\n",
      "|bottle beer ale l...|\n",
      "|toy:board game:adult|\n",
      "|clean:laundry:cle...|\n",
      "|health beauty:ski...|\n",
      "|bone chew:pet:dog...|\n",
      "|drink:beverage:li...|\n",
      "+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "input.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [semantic_tags: string, tag_name: string]"
     ]
    }
   ],
   "source": [
    "input = input.withColumn(\"tag_name\", explode(split(col(\"semantic_tags\"),\":\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|       semantic_tags|            tag_name|\n",
      "+--------------------+--------------------+\n",
      "|wine white wine:w...|     wine white wine|\n",
      "|wine white wine:w...|          white wine|\n",
      "|wine white wine:w...|        pinot grigio|\n",
      "|wine white wine:w...|white wine pinot ...|\n",
      "|wine white wine:w...|   wine pinot grigio|\n",
      "|wine white wine:w...|                wine|\n",
      "|wine white wine:w...|             alcohol|\n",
      "|liquor market:sco...|       liquor market|\n",
      "|liquor market:sco...|              scotch|\n",
      "|liquor market:sco...|              liquor|\n",
      "|liquor market:sco...|             whiskey|\n",
      "|liquor market:sco...|               sprit|\n",
      "|liquor market:sco...|      spirit alcohol|\n",
      "|liquor market:sco...|        blend scotch|\n",
      "|liquor market:sco...|bob discount liqu...|\n",
      "|liquor market:sco...|      alcohol bottle|\n",
      "|liquor market:sco...|       whiskey buddy|\n",
      "|liquor market:sco...|   alcohol miniature|\n",
      "|liquor market:sco...|             alcohol|\n",
      "|liquor market:sco...|     whiskey bourbon|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "input.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [tag_name: string]"
     ]
    }
   ],
   "source": [
    "input = input.select(\"tag_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            tag_name|\n",
      "+--------------------+\n",
      "|      american drink|\n",
      "|            beverage|\n",
      "|american snack drink|\n",
      "|          drink soda|\n",
      "|              cereal|\n",
      "|          cough cold|\n",
      "|          frozenfood|\n",
      "|             instant|\n",
      "|              frozen|\n",
      "|            red wine|\n",
      "|                wine|\n",
      "|          beer cider|\n",
      "|wine sparkling wi...|\n",
      "|   bottle beer cider|\n",
      "|         beer larger|\n",
      "|     alesstout lager|\n",
      "|         bottle beer|\n",
      "|  lager stout bottle|\n",
      "|              seller|\n",
      "|          beer cider|\n",
      "+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "input.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res5: Long = 3764850"
     ]
    }
   ],
   "source": [
    "input.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import com.databricks.spark.corenlp.functions._"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import com.databricks.spark.corenlp.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopWordsDf: org.apache.spark.sql.DataFrame = [stop_word: string]"
     ]
    }
   ],
   "source": [
    "var stopWordsDf = spark.sql(\"SELECT DISTINCT stop_word from kirby_external_data.semantic_tag_stop_words_master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopWords: Array[String] = Array(doesn, thanx, wholl, everyday, highest, presents, parts, slightly, hundred, indicated, items, 7, en, whats, bo, nl, we'd, ye, dishes, doubtful, forward, ad, hows, parted, quickly, states, thought, sub, l, twice, got, needing, extra, eg, herself, mug, ``, find, appreciate, ll, anywhere, box, regarding, al, except, always, becoming, thatve, there're, thereto, combination, entrante, gu, name, see, downs, tn, whys, april, beforehand, causes, not, twenty, i'd, certain, cv, show, 50g, couldn't, mt, sorry, there'd, jp, mv, sec, Wednesday, ain, oz., sensible, 350, ao, must, needn't, much, opposite, ref, di, hasn, make, namely, new, th, ups, cant, hadn, neither, u, what, widely, further, work, hour, omitted, desayuno, wasn, neednt, whichever, eight, fx, resulted,..."
     ]
    }
   ],
   "source": [
    "var stopWords = stopWordsDf.collect.map(row=>row.getString(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res6: Array[String] = Array(doesn, thanx, wholl, everyday, highest, presents, parts, slightly, hundred, indicated, items, 7, en, whats, bo, nl, we'd, ye, dishes, doubtful, forward, ad, hows, parted, quickly, states, thought, sub, l, twice, got, needing, extra, eg, herself, mug, ``, find, appreciate, ll, anywhere, box, regarding, al, except, always, becoming, thatve, there're, thereto, combination, entrante, gu, name, see, downs, tn, whys, april, beforehand, causes, not, twenty, i'd, certain, cv, show, 50g, couldn't, mt, sorry, there'd, jp, mv, sec, Wednesday, ain, oz., sensible, 350, ao, must, needn't, much, opposite, ref, di, hasn, make, namely, new, th, ups, cant, hadn, neither, u, what, widely, further, work, hour, omitted, desayuno, wasn, neednt, whichever, eight, fx, resulted, they..."
     ]
    }
   ],
   "source": [
    "stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalInput: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [tag_name: string]"
     ]
    }
   ],
   "source": [
    "val finalInput = input.select(col(\"tag_name\")).where(length(regexp_replace($\"tag_name\", \" \",\"\")) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res7: Long = 3764850"
     ]
    }
   ],
   "source": [
    "finalInput.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            tag_name|\n",
      "+--------------------+\n",
      "|          coffee tea|\n",
      "|  bonisoir laprairie|\n",
      "|               drink|\n",
      "|            starbuck|\n",
      "|              coffee|\n",
      "|coffee coffee filter|\n",
      "|    coffee tea drink|\n",
      "|         coffee milk|\n",
      "|            beverage|\n",
      "|           jus drink|\n",
      "|                 tea|\n",
      "|        energy drink|\n",
      "|depanneur quartie...|\n",
      "|                soda|\n",
      "|          soda drink|\n",
      "|        frozen snack|\n",
      "|             sto dep|\n",
      "|         freshly fry|\n",
      "|              frozen|\n",
      "|             grocery|\n",
      "+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "finalInput.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas: org.apache.spark.sql.DataFrame = [tag_name: string, tag_lemma: array<string>]"
     ]
    }
   ],
   "source": [
    "val lemmas = finalInput.withColumn(\"tag_lemma\",lemma('tag_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res9: Long = 3764850"
     ]
    }
   ],
   "source": [
    "lemmas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            tag_name|           tag_lemma|\n",
      "+--------------------+--------------------+\n",
      "|             grocery|           [grocery]|\n",
      "|         honey syrup|      [honey, syrup]|\n",
      "|                 tag|               [tag]|\n",
      "|condiment spice bake|[condiment, spice...|\n",
      "|          consumable|        [consumable]|\n",
      "|         noodle soup|      [noodle, soup]|\n",
      "|             grocery|           [grocery]|\n",
      "|        asian import|     [asian, import]|\n",
      "|              noodle|            [noodle]|\n",
      "|               snack|             [snack]|\n",
      "|             instant|           [instant]|\n",
      "|     krystal express|  [krystal, express]|\n",
      "|             product|           [product]|\n",
      "|                soup|              [soup]|\n",
      "|                 pet|               [pet]|\n",
      "|              yogurt|            [yogurt]|\n",
      "|           dairy egg|        [dairy, egg]|\n",
      "|           ice cream|        [ice, cream]|\n",
      "|          toiletries|        [toiletries]|\n",
      "|            haircare|          [haircare]|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "lemmas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patternString: String = ^\\d+[A-Za-z]{1,2}$|^\\d+pcs$|^\\d+pc$|^\\d+g$|^\\d+gm$|^\\d+ml$|^\\d+kg$|^\\d+oz$|^\\d+oz.$|^\\d+mg$|^\\d+lb$|^d+”$|^\\d+’$|^\\d+cm$|^\\d+gms$|^\\d+pk$|^\\d+mm$|^\\d+lt$|"
     ]
    }
   ],
   "source": [
    "var patternString =\n",
    "        \"^\\\\d+[A-Za-z]{1,2}$|^\\\\d+pcs$|^\\\\d+pc$|^\\\\d+g$|^\\\\d+gm$|^\\\\d+ml$|^\\\\d+kg$|^\\\\d+oz$|^\\\\d+oz.$|^\\\\d+mg$|^\\\\d+lb$|^d+”$|^\\\\d+’$|^\\\\d+cm$|^\\\\d+gms$|^\\\\d+pk$|^\\\\d+mm$|^\\\\d+lt$|\";\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "patternString +=\"^\\\\d+g.$|^\\\\d+gm.$|^\\\\d+ml.$|^\\\\d+kg.$|^\\\\d+mg.$|^\\\\d+lb.$|^d+”.$|^\\\\d+’.$|^\\\\d+cm.$|^\\\\d+gms.$|^\\\\d+pk.$|^\\\\d+mm.$|^\\\\d+lt.$|^\\\\d+$|^\\\\d*\\\\.?\\\\d$|\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " patternString += \"^\\\\d+cl$|^\\\\d+am|^\\\\d+pm|^[0-2][0-3]:[0-5][0-9]$\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res13: String = ^\\d+[A-Za-z]{1,2}$|^\\d+pcs$|^\\d+pc$|^\\d+g$|^\\d+gm$|^\\d+ml$|^\\d+kg$|^\\d+oz$|^\\d+oz.$|^\\d+mg$|^\\d+lb$|^d+”$|^\\d+’$|^\\d+cm$|^\\d+gms$|^\\d+pk$|^\\d+mm$|^\\d+lt$|^\\d+g.$|^\\d+gm.$|^\\d+ml.$|^\\d+kg.$|^\\d+mg.$|^\\d+lb.$|^d+”.$|^\\d+’.$|^\\d+cm.$|^\\d+gms.$|^\\d+pk.$|^\\d+mm.$|^\\d+lt.$|^\\d+$|^\\d*\\.?\\d$|^\\d+cl$|^\\d+am|^\\d+pm|^[0-2][0-3]:[0-5][0-9]$"
     ]
    }
   ],
   "source": [
    "patternString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.ml.feature.StopWordsRemover"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remover: org.apache.spark.ml.feature.StopWordsRemover = stopWords_bbdd82e3ceda"
     ]
    }
   ],
   "source": [
    "val remover = new StopWordsRemover().setStopWords(stopWords).setInputCol(\"tag_lemma\").setOutputCol(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: org.apache.spark.sql.DataFrame = [tag_name: string, tag_lemma: array<string> ... 1 more field]"
     ]
    }
   ],
   "source": [
    "var df = remover.transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res14: Long = 3764850"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|            tag_name|           tag_lemma|                test|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|        meat seafood|     [meat, seafood]|     [meat, seafood]|\n",
      "|          white wine|       [white, wine]|       [white, wine]|\n",
      "|          gallo wine|       [gallo, wine]|       [gallo, wine]|\n",
      "|      wine wite rise|  [wine, wite, rise]|  [wine, wite, rise]|\n",
      "|    chill white wine|[chill, white, wine]|[chill, white, wine]|\n",
      "|   alcholic beverage|[alcholic, beverage]|[alcholic, beverage]|\n",
      "|   convenience store|[convenience, store]|[convenience, store]|\n",
      "|     krystal express|  [krystal, express]|  [krystal, express]|\n",
      "|spirit champagne ...|[spirit, champagn...|[spirit, champagn...|\n",
      "|     white rise wine| [white, rise, wine]| [white, rise, wine]|\n",
      "|    californian wine| [californian, wine]| [californian, wine]|\n",
      "|wine champagne pr...|[wine, champagne,...|[wine, champagne,...|\n",
      "|   price weight live|[price, weight, l...|[price, weight, l...|\n",
      "|    wine californium| [wine, californium]| [wine, californium]|\n",
      "|             alcohol|           [alcohol]|           [alcohol]|\n",
      "|                wine|              [wine]|              [wine]|\n",
      "|   white wine bottle|[white, wine, bot...|[white, wine, bot...|\n",
      "|     wine white wine| [wine, white, wine]| [wine, white, wine]|\n",
      "|        alcohol wine|     [alcohol, wine]|     [alcohol, wine]|\n",
      "|chill white wine usa|[chill, white, wi...|[chill, white, wi...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removeRegex: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,ArrayType(StringType,true),Some(List(ArrayType(StringType,true))))"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.udf\n",
    "import java.util.regex.Pattern\n",
    "val pattern = Pattern.compile(patternString)\n",
    "val removeRegex = udf {\n",
    "  (array: Seq[String]) =>\n",
    "    \n",
    "    val cleanArray = array.filter((text) => ( text.length >= 3 && !pattern.matcher(text).find()) )\n",
    "    cleanArray\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regexdf: org.apache.spark.sql.DataFrame = [tag_name: string, tag_lemma: array<string> ... 2 more fields]"
     ]
    }
   ],
   "source": [
    "var regexdf = df.withColumn(\"removeregex\",removeRegex(df.col(\"test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|            tag_name|           tag_lemma|                test|         removeregex|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                milk|              [milk]|              [milk]|              [milk]|\n",
      "|           dairy egg|        [dairy, egg]|        [dairy, egg]|        [dairy, egg]|\n",
      "|   topping condiment|    [top, condiment]|         [condiment]|         [condiment]|\n",
      "|             grocery|           [grocery]|           [grocery]|           [grocery]|\n",
      "|           condiment|         [condiment]|         [condiment]|         [condiment]|\n",
      "|             barcode|           [barcode]|           [barcode]|           [barcode]|\n",
      "|               pasta|             [pasta]|             [pasta]|             [pasta]|\n",
      "|           dry pasta|        [dry, pasta]|        [dry, pasta]|        [dry, pasta]|\n",
      "|           soda shop|        [soda, shop]|        [soda, shop]|        [soda, shop]|\n",
      "|               mixer|             [mixer]|             [mixer]|             [mixer]|\n",
      "|            beverage|          [beverage]|          [beverage]|          [beverage]|\n",
      "|     essential drink|  [essential, drink]|  [essential, drink]|  [essential, drink]|\n",
      "|energy electrolyt...|[energy, electrol...|[energy, electrol...|[energy, electrol...|\n",
      "|    soda juice mixer|[soda, juice, mixer]|[soda, juice, mixer]|[soda, juice, mixer]|\n",
      "|        energy drink|     [energy, drink]|     [energy, drink]|     [energy, drink]|\n",
      "|                 hot|               [hot]|               [hot]|               [hot]|\n",
      "|                soda|              [soda]|              [soda]|              [soda]|\n",
      "|               drink|             [drink]|             [drink]|             [drink]|\n",
      "|            beverage|          [beverage]|          [beverage]|          [beverage]|\n",
      "|            wine red|         [wine, red]|         [wine, red]|         [wine, red]|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "regexdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------+------------------------+------------------------+\n",
      "|tag_name            |tag_lemma               |test                    |removeregex             |\n",
      "+--------------------+------------------------+------------------------+------------------------+\n",
      "|alcoholic drink     |[alcoholic, drink]      |[alcoholic, drink]      |[alcoholic, drink]      |\n",
      "|booze               |[booze]                 |[booze]                 |[booze]                 |\n",
      "|alcohol             |[alcohol]               |[alcohol]               |[alcohol]               |\n",
      "|liquor              |[liquor]                |[liquor]                |[liquor]                |\n",
      "|cocktail            |[cocktail]              |[cocktail]              |[cocktail]              |\n",
      "|spirit              |[spirit]                |[spirit]                |[spirit]                |\n",
      "|cocktail soda       |[cocktail, soda]        |[cocktail, soda]        |[cocktail, soda]        |\n",
      "|monaco              |[monaco]                |[monaco]                |[monaco]                |\n",
      "|cocktail ready drink|[cocktail, ready, drink]|[cocktail, ready, drink]|[cocktail, ready, drink]|\n",
      "|beer                |[beer]                  |[beer]                  |[beer]                  |\n",
      "+--------------------+------------------------+------------------------+------------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "regexdf.show(10,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res18: Long = 3764850"
     ]
    }
   ],
   "source": [
    "regexdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputDf: org.apache.spark.sql.DataFrame = [tag_name: string, tag_lemma: array<string> ... 3 more fields]"
     ]
    }
   ],
   "source": [
    "val outputDf = regexdf.withColumn(\"final_tag_name\",concat_ws(\" \", $\"removeregex\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [tag_name: string, final_tag_name: string]"
     ]
    }
   ],
   "source": [
    "val finalDf = outputDf.select(col(\"tag_name\"),col(\"final_tag_name\")).where(length(regexp_replace($\"final_tag_name\", \" \",\"\")) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            tag_name|      final_tag_name|\n",
      "+--------------------+--------------------+\n",
      "|   drink drink mixer|   drink drink mixer|\n",
      "|               juice|               juice|\n",
      "|                 wet|                 wet|\n",
      "|                 pet|                 pet|\n",
      "|chocolatesweetsca...|chocolatesweetsca...|\n",
      "|    import chocolate|    import chocolate|\n",
      "|           chocolate|           chocolate|\n",
      "|chocolate snack c...|chocolate snack c...|\n",
      "|            choclate|            choclate|\n",
      "|               sweet|               sweet|\n",
      "|                cake|                cake|\n",
      "|  ice cream popsicle|  ice cream popsicle|\n",
      "|              frozen|              frozen|\n",
      "|     brew tea coffee|     brew tea coffee|\n",
      "|            brew tea|            brew tea|\n",
      "|            beverage|            beverage|\n",
      "|     alcoholic drink|     alcoholic drink|\n",
      "|              liquor|              liquor|\n",
      "|             alcohol|             alcohol|\n",
      "|              spirit|              spirit|\n",
      "|            beverage|            beverage|\n",
      "|               drink|               drink|\n",
      "|               booze|               booze|\n",
      "|           vodka gin|           vodka gin|\n",
      "|               vodka|               vodka|\n",
      "|          white wine|          white wine|\n",
      "|white wine rise wine|white wine rise wine|\n",
      "|                wine|                wine|\n",
      "|white wine rise w...|white wine rise w...|\n",
      "|          wine white|          wine white|\n",
      "|     wine white wine|     wine white wine|\n",
      "|           dry pasta|           dry pasta|\n",
      "|               pasta|               pasta|\n",
      "|        pasta legume|        pasta legume|\n",
      "|     alcoholic drink|     alcoholic drink|\n",
      "|         canada wine|         canada wine|\n",
      "|               drink|               drink|\n",
      "|               booze|               booze|\n",
      "|         wine canada|         wine canada|\n",
      "|              spirit|              spirit|\n",
      "|             alcohol|             alcohol|\n",
      "|              liquor|              liquor|\n",
      "|            beverage|            beverage|\n",
      "|             alcohol|             alcohol|\n",
      "|               booze|               booze|\n",
      "|            red wine|            red wine|\n",
      "|     alcoholic drink|     alcoholic drink|\n",
      "|            beverage|            beverage|\n",
      "|              liquor|              liquor|\n",
      "|              spirit|              spirit|\n",
      "|               drink|               drink|\n",
      "|                soup|                soup|\n",
      "|              packet|              packet|\n",
      "|               juice|               juice|\n",
      "|         chill drink|         chill drink|\n",
      "|              merlot|              merlot|\n",
      "|      red wine chile|      red wine chile|\n",
      "|            wine red|            wine red|\n",
      "|           promotion|           promotion|\n",
      "|      wine champagne|      wine champagne|\n",
      "|         wine spirit|         wine spirit|\n",
      "|      casillero wine|      casillero wine|\n",
      "|             alcohol|             alcohol|\n",
      "|            red wine|            red wine|\n",
      "|                wine|                wine|\n",
      "|alcohol wine beer...|alcohol wine beer...|\n",
      "|white wine rise w...|white wine rise w...|\n",
      "|            beverage|            beverage|\n",
      "|              spirit|              spirit|\n",
      "|               booze|               booze|\n",
      "|         magnum wine|         magnum wine|\n",
      "|             alcohol|             alcohol|\n",
      "|            red wine|            red wine|\n",
      "|              liquor|              liquor|\n",
      "|                wine|                wine|\n",
      "|            usa wine|            usa wine|\n",
      "|               drink|               drink|\n",
      "|     alcoholic drink|     alcoholic drink|\n",
      "| california cab sauv| california cab sauv|\n",
      "|           selection|           selection|\n",
      "|      alcohol bottle|      alcohol bottle|\n",
      "|               mixer|               mixer|\n",
      "|      alcohol spirit|      alcohol spirit|\n",
      "| whiskey liqueur rum| whiskey liqueur rum|\n",
      "|    alcoholic spirit|    alcoholic spirit|\n",
      "|              market|              market|\n",
      "|                wine|                wine|\n",
      "|liqueur aperitif ...|liqueur aperitif ...|\n",
      "|     tonic wine root|     tonic wine root|\n",
      "|              spirit|              spirit|\n",
      "|               cream|               cream|\n",
      "|             alcohol|             alcohol|\n",
      "|             liqueur|             liqueur|\n",
      "| chocolate king size| chocolate king size|\n",
      "|chocolate confect...|chocolate confect...|\n",
      "|chocolate sweet p...|chocolate sweet p...|\n",
      "|        cake rebecca|        cake rebecca|\n",
      "|sweet chocolate s...|sweet chocolate s...|\n",
      "|  chocolat chocolate|  chocolat chocolate|\n",
      "|             grocery|             grocery|\n",
      "+--------------------+--------------------+\n",
      "only showing top 100 rows"
     ]
    }
   ],
   "source": [
    "finalDf.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res20: Long = 3763079"
     ]
    }
   ],
   "source": [
    "finalDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|final_tag_name          |\n",
      "+------------------------+\n",
      "|bacon sausage hot dog   |\n",
      "|roller grill            |\n",
      "|meat                    |\n",
      "|sausage                 |\n",
      "|deli                    |\n",
      "|sausage bacon           |\n",
      "|concession              |\n",
      "|beef                    |\n",
      "|meat seafood            |\n",
      "|meat poultry seafood    |\n",
      "|grocery                 |\n",
      "|meat seafood plant base |\n",
      "|deli meat cold cut      |\n",
      "|vegetable               |\n",
      "|scotch                  |\n",
      "|prepared                |\n",
      "|dessert                 |\n",
      "|international           |\n",
      "|indian                  |\n",
      "|beverage                |\n",
      "|liquor                  |\n",
      "|super                   |\n",
      "|liqueur                 |\n",
      "|alcoholic drink         |\n",
      "|booze                   |\n",
      "|spirit                  |\n",
      "|drink                   |\n",
      "|alcohol                 |\n",
      "|beer domestic import    |\n",
      "|liquor                  |\n",
      "|beverage                |\n",
      "|spirit                  |\n",
      "|booze                   |\n",
      "|rise dry hard cider beer|\n",
      "|cider                   |\n",
      "|beer cider              |\n",
      "|alcoholic drink         |\n",
      "|drink                   |\n",
      "|alcohol                 |\n",
      "|iced beverage           |\n",
      "|chocolate sweet gum     |\n",
      "|sweet                   |\n",
      "|chocolate               |\n",
      "|gum candy               |\n",
      "|single chocolate        |\n",
      "|reese                   |\n",
      "|candy                   |\n",
      "|chocolate confectionery |\n",
      "|chocolate sweet         |\n",
      "|harry newsagent         |\n",
      "+------------------------+\n",
      "only showing top 50 rows"
     ]
    }
   ],
   "source": [
    "finalDf.select(col(\"final_tag_name\")).show(50,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequentItem: org.apache.spark.sql.DataFrame = [final_tag_name: string]"
     ]
    }
   ],
   "source": [
    "var frequentItem = finalDf.select(col(\"final_tag_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequentItem: org.apache.spark.sql.DataFrame = [final_tag_name: string, word: string]"
     ]
    }
   ],
   "source": [
    "frequentItem = frequentItem.withColumn(\"word\", explode(split(col(\"final_tag_name\"),\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequentItem: org.apache.spark.sql.DataFrame = [word: string]"
     ]
    }
   ],
   "source": [
    "frequentItem = frequentItem.drop(\"final_tag_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|word     |count |\n",
      "+---------+------+\n",
      "|drink    |397235|\n",
      "|wine     |235236|\n",
      "|beverage |195946|\n",
      "|alcohol  |193792|\n",
      "|spirit   |188976|\n",
      "|liquor   |178225|\n",
      "|snack    |173984|\n",
      "|alcoholic|154472|\n",
      "|booze    |142165|\n",
      "|beer     |138674|\n",
      "|candy    |71022 |\n",
      "|chocolate|68065 |\n",
      "|cookie   |61248 |\n",
      "|frozen   |59246 |\n",
      "|sweet    |56168 |\n",
      "|red      |48215 |\n",
      "|grocery  |47993 |\n",
      "|whiskey  |46401 |\n",
      "|meat     |45031 |\n",
      "|chip     |42517 |\n",
      "|cream    |42477 |\n",
      "|health   |41429 |\n",
      "|dairy    |40331 |\n",
      "|product  |38583 |\n",
      "|fruit    |38305 |\n",
      "|ice      |37815 |\n",
      "|cracker  |35341 |\n",
      "|juice    |34975 |\n",
      "|crisp    |34331 |\n",
      "|personal |34222 |\n",
      "|cider    |33403 |\n",
      "|fresh    |32178 |\n",
      "|beauty   |32146 |\n",
      "|white    |31673 |\n",
      "|sauce    |29751 |\n",
      "|vegetable|28937 |\n",
      "|mixer    |28414 |\n",
      "|tea      |27721 |\n",
      "|household|27667 |\n",
      "|ready    |26900 |\n",
      "|american |26600 |\n",
      "|spice    |26148 |\n",
      "|vodka    |26112 |\n",
      "|bakery   |25450 |\n",
      "|gum      |24857 |\n",
      "|coffee   |24535 |\n",
      "|sparkling|24224 |\n",
      "|water    |23922 |\n",
      "|nut      |23608 |\n",
      "|bread    |23534 |\n",
      "+---------+------+\n",
      "only showing top 50 rows"
     ]
    }
   ],
   "source": [
    "frequentItem.groupBy(\"word\").count().sort(col(\"count\").desc).show(50,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "07. SparkMagic (Remote Scala)",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
