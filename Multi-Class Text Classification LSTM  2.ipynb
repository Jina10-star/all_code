{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40d09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdba3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Taxml_Integers_Verified.csv', index_col=None, header=0,dtype={'item_name': str, 'description': str,'establishment_type': str, 'CAT_Name':str},usecols=['item_name','description','establishment_type','CAT_Name'])\n",
    "#df_duplicates = df_integers[df_integers.duplicated(subset=['item_name','description','establishment_type'],keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22a5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_name_sorted(text):\n",
    "    text=sorted(text.split(','))\n",
    "    text=','.join([x for x in text])\n",
    "    return text\n",
    "def cat_name_without_temp(text):\n",
    "    if ',TEMP_HEATED' in text:\n",
    "        text=re.sub(',TEMP_HEATED','', text)\n",
    "    if ',TEMP_UNHEATED' in text:\n",
    "        text=re.sub(',TEMP_UNHEATED','', text)\n",
    "    if ',TEMP_COLD' in text:\n",
    "        text=re.sub(',TEMP_COLD','', text)\n",
    "    if 'TEMP_HEATED' in text:\n",
    "        text=re.sub('TEMP_HEATED','', text)\n",
    "    if 'TEMP_UNHEATED' in text:\n",
    "        text=re.sub('TEMP_UNHEATED','', text)\n",
    "    if 'TEMP_COLD' in text:\n",
    "        text=re.sub('TEMP_COLD','', text)\n",
    "    else:\n",
    "        pass\n",
    "    #text=re.sub('TEMP_UNHEATED','', text)\n",
    "    #text=re.sub('TEMP_UNHEATED','', text)\n",
    "    return text\n",
    "le=WordNetLemmatizer()\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    #print(tag,word)\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    #print( tag_dict.get(tag, wordnet.NOUN))\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93764930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f303bc8df84a958e5f587f6e10e10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0639aabc8a472e85db2d0d36256191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df1 = df.sample(n=10000,random_state=1)\n",
    "df1=df.copy()\n",
    "df1['CAT_Name']=df1['CAT_Name'].progress_apply(lambda x: cat_name_sorted(x))\n",
    "df1['CAT_Name']=df1['CAT_Name'].progress_apply(lambda x: cat_name_without_temp(x))\n",
    "df1=df1.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df1 = df1.dropna(subset=['CAT_Name'])\n",
    "df1=df1.drop_duplicates(subset=['item_name','description','establishment_type','CAT_Name'],ignore_index=True,keep='first')\n",
    "df1=df1.drop_duplicates(subset=['item_name','description','establishment_type'],ignore_index=True,keep='first')\n",
    "df1['input_str'] = df1[['item_name', 'description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad0638a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.value_counts(df1['CAT_Name']).plot.bar()\n",
    "#plt.title('cat histogram')\n",
    "#plt.xlabel('Class')\n",
    "#plt.ylabel('Frequency')\n",
    "#df1['CAT_Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b799c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "#from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2957679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-8fbbb139b23f>:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df1['input_str'] = df1['input_str'].str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = list(set(stopwords.words('english')))\n",
    "STOPWORDS.append('n')\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    #text = text.replace('x', '')\n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)# remove stopwors from text\n",
    "    text =  \" \".join([le.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text) if w not in string.punctuation])\n",
    "    return text\n",
    "df1['input_str'] = df1['input_str'].apply(clean_text)\n",
    "df1['input_str'] = df1['input_str'].str.replace('\\d+', '')\n",
    "df1 = df1[df1['input_str'].apply(lambda x: len(str(x))>1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9104b230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167440, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcea678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('final_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afe41b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH=-1\n",
    "for i,rev in enumerate(df1['input_str']):\n",
    "    tokens=rev.split()\n",
    "    if(len(tokens)>MAX_SEQUENCE_LENGTH):\n",
    "        MAX_SEQUENCE_LENGTH=len(tokens)\n",
    "print(MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS=20000\n",
    "# Max number of words in each complaint.\n",
    "#MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df1['input_str'].values)\n",
    "word_index = tokenizer.word_index\n",
    "word_counts = tokenizer.word_counts\n",
    "#print('Found %s unique tokens.' % len(word_index))\n",
    "#print('Found %s  tokens.' % len(word_counts))\n",
    "#print(' the number of times words occur in the text corpus' % tokenizer.word_counts)\n",
    "#print(\"The word docs\",tokenizer.word_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a1b07f39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-c84126c4ec95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m      \u001b[0mtext_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b27f9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (9540, 293)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df1['input_str'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed0d38bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  306,  382,    1],\n",
       "       [   0,    0,    0, ...,  914,   81,    1],\n",
       "       [   0,    0,    0, ..., 6569, 1242,    1],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   14,    4,    1],\n",
       "       [   0,    0,    0, ...,   31, 2926,    1],\n",
       "       [   0,    0,    0, ...,  659, 1544,    1]], dtype=int32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a72db10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (9540, 161)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df1['CAT_Name']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fbf92fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (8586, 293)\n",
      "Number transactions y_train dataset:  (8586, 161)\n",
      "Number transactions X_test dataset:  (954, 293)\n",
      "Number transactions y_test dataset:  (954, 161)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "41f8cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 293, 100)          2000000   \n",
      "                                                                 \n",
      " spatial_dropout1d_8 (Spatia  (None, 293, 100)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 161)               16261     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,096,661\n",
      "Trainable params: 2,096,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS,EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(LSTM(128,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ac4a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 40s 312ms/step - loss: 3.6268 - accuracy: 0.2060 - val_loss: 3.3326 - val_accuracy: 0.2247\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 36s 299ms/step - loss: 3.0800 - accuracy: 0.2741 - val_loss: 2.8305 - val_accuracy: 0.3108\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 37s 303ms/step - loss: 2.6540 - accuracy: 0.3809 - val_loss: 2.4779 - val_accuracy: 0.4319\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 36s 298ms/step - loss: 2.2962 - accuracy: 0.4803 - val_loss: 2.2345 - val_accuracy: 0.4843\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 36s 301ms/step - loss: 2.0148 - accuracy: 0.5373 - val_loss: 2.0521 - val_accuracy: 0.5204\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.10,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f89612c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 41ms/step - loss: 1.9395 - accuracy: 0.5828\n",
      "Test set\n",
      "  Loss: 1.939\n",
      "  Accuracy: 0.583\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4375b913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ej brandy grand blue vsop ml grocery'] CAT_PREPACKAGED_FOOD_HONEY\n"
     ]
    }
   ],
   "source": [
    "new_complaint = ['ej brandy grand blue vsop ml grocery']\n",
    "seq = tokenizer.texts_to_sequences(new_complaint)\n",
    "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred = model.predict(padded)\n",
    "#labels = ['Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', 'Mortgage', 'Credit card or prepaid card', 'Student loan', 'Bank account or service', 'Checking or savings account', 'Consumer Loan', 'Payday loan, title loan, or personal loan', 'Vehicle loan or lease', 'Money transfer, virtual currency, or money service', 'Money transfers', 'Prepaid card']\n",
    "labels=list(set(df1['CAT_Name']))\n",
    "print(new_complaint,labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "10a551f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-5ffcf27e1eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original_cat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "result=pd.DataFrame()\n",
    "#seq = tokenizer.texts_to_sequences(X_test)\n",
    "padded = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred = model.predict(padded)\n",
    "labels=list(set(df1['CAT_Name']))\n",
    "result['input']=tokenizer.sequences_to_texts(X_test)\n",
    "result['original_cat']=labels[np.argmax(y_test)]\n",
    "result['pred']=labels[np.argmax(pred)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "da32e1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04657657, 0.00423859, 0.00316973, ..., 0.00173439, 0.00862304,\n",
       "        0.11367816],\n",
       "       [0.04646255, 0.00416791, 0.00315172, ..., 0.00171035, 0.00858124,\n",
       "        0.11470422],\n",
       "       [0.04643726, 0.0041702 , 0.00314348, ..., 0.00170727, 0.00856694,\n",
       "        0.11452761],\n",
       "       ...,\n",
       "       [0.04646696, 0.00418247, 0.00314667, ..., 0.00171043, 0.00859642,\n",
       "        0.11440453],\n",
       "       [0.04640952, 0.00418446, 0.00314905, ..., 0.00171597, 0.00857454,\n",
       "        0.11437099],\n",
       "       [0.04635875, 0.00418249, 0.00315512, ..., 0.00170454, 0.00861294,\n",
       "        0.11461134]], dtype=float32)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8b4d64fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CAT_TPP_PERFUMES'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[np.argmax(y_test[7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "089d10a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698196c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c74ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
