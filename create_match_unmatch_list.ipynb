{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from sets import Set\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pair_list_5-6-7_2018.json and taskid_list_5-6-7-2018.txt are created by get_merged_tasks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pair_list_5-6-7_2018.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create set_list from duplicate key value pair\n",
    "## remove the pair that contains ticket outside snaptask 5-7 2018 (data.keys())\n",
    "set_list = []\n",
    "for k in data.keys():\n",
    "    for i in data[k]:\n",
    "        if i in data.keys():\n",
    "            set_list.append(Set([k,i]))\n",
    "\n",
    "# tickets outside snaptask\n",
    "m_list = []\n",
    "for k in data.keys():\n",
    "    for i in data[k]:\n",
    "        if i not in data.keys():\n",
    "            m_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if keyword 'snaptask' is in description, we think the task is created by snaptask\n",
    "def taskid_to_issnap(taskid):\n",
    "    datat = [\n",
    "              ('api.token', 'cli-XXX'),\n",
    "              ('task_id', taskid),\n",
    "            ]\n",
    "    response = requests.post('https://code.uberinternal.com/api/maniphest.info', data=datat)\n",
    "    jresponse = json.loads(response.text)\n",
    "    return 'snaptask' in jresponse['result']['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find tickets not from snaptask 5-7 2018\n",
    "## (1) manually created master tasks\n",
    "## (2) snaptask tickets created outside this time range \n",
    "manual_list = []\n",
    "snap_list = []\n",
    "for i in set(m_list):\n",
    "    js = taskid_to_issnap(i)\n",
    "    if js is True:\n",
    "        snap_list.append(i)\n",
    "    else:\n",
    "        manual_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each m_master, get the snap tickets that linked with them\n",
    "ct_manual = []\n",
    "for m in set(manual_list):\n",
    "    merged = [key for key, value in data.iteritems() if m in value]\n",
    "    ct_manual.append(len(merged)-1)\n",
    "    \n",
    "for m in set(manual_list):\n",
    "    merged = [key for key, value in data.iteritems() if m in value]\n",
    "    merged_key = merged[0]\n",
    "    for i in range(len(merged)-1):\n",
    "        set_list.append(Set([merged_key,merged[i+1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each snap ticket outside date range, get the snap tickets that linked with them\n",
    "ct_snap = []\n",
    "for m in set(snap_list):\n",
    "    merged = [key for key, value in data.iteritems() if m in value]\n",
    "    ct_snap.append(len(merged))\n",
    "\n",
    "for m in set(snap_list):\n",
    "    merged = [key for key, value in data.iteritems() if m in value]\n",
    "    for i in merged:\n",
    "        set_list.append(Set([m , i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_training = []\n",
    "for l in Set(set_list):\n",
    "    lst = list(l)\n",
    "    pair_training.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump(pair_training, open('5-6-7_2018_duplicated_pairs.p', 'wb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dup_pairs = cPickle.load(open('5-6-7_2018_duplicated_pairs.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dup_pairs = pd.DataFrame.from_records(dup_pairs, columns=['task1','task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_snaptask_ids = pd.read_csv('taskid_list_5-6-7-2018.txt', sep=\" \", header=None)\n",
    "df_snaptask_ids.columns = [\"taskid\"]\n",
    "list_snaptaskids = [i[1:] for i in df_snaptask_ids.taskid.values.tolist()]\n",
    "df_dup_pairs = df_dup_pairs[(df_dup_pairs.task1.isin(list_snaptaskids) & df_dup_pairs.task2.isin(list_snaptaskids) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('5-6-7_matched_list.txt', 'a') as the_file:\n",
    "    for i,j in zip(df_dup_pairs.task1.values.tolist(),df_dup_pairs.task2.values.tolist() ) :\n",
    "        the_file.write(i+' '+j+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_dup_pairs\n",
    "d1 = df['task1'].tolist()\n",
    "d2 = df['task2'].tolist()\n",
    "random_list = []\n",
    "for i in range(5000):\n",
    "    p = random.sample(set(d1+d2), 2)\n",
    "    if (df[(df['task1']==p[0]) & (df['task2']==p[1])].empty) \\\n",
    "       and (df[(df['task2']==p[0]) & (df['task1']==p[1])].empty):\n",
    "        random_list.append(p)\n",
    "df_random = pd.DataFrame.from_records(random_list, columns=['task1','task2'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1lst = df_random.task1.values.tolist()\n",
    "df2lst = df_random.task2.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('5-6-7_unmatched_list.txt', 'a') as the_file:\n",
    "    for i,j in zip(df1lst, df2lst):\n",
    "        the_file.write(i+' '+j+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (General DS)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
