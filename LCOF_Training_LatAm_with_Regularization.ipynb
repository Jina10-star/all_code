{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data: features & labels\n",
    "df_features_dict = {}\n",
    "df_labels_dict = {}\n",
    "\n",
    "num_feature_files = 15\n",
    "num_label_files = 15\n",
    "\n",
    "for i in range(1, num_feature_files):\n",
    "    df_features_dict[i] = pd.read_csv(f'lcof_hourly_features_{i}.csv')\n",
    "\n",
    "for i in range(1, num_label_files):\n",
    "    df_labels_dict[i] = pd.read_csv(f'lcof_hourly_labels_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_frames = [df_features_dict[1], df_features_dict[2], df_features_dict[3],\n",
    "                      df_features_dict[4], df_features_dict[5], df_features_dict[6],\n",
    "                      df_features_dict[7], df_features_dict[8], df_features_dict[9],\n",
    "                      df_features_dict[10], df_features_dict[11], df_features_dict[12],\n",
    "                      df_features_dict[13], df_features_dict[14]\n",
    "                     ]\n",
    "\n",
    "df_labels_frames = [df_labels_dict[1], df_labels_dict[2], df_labels_dict[3],\n",
    "                    df_labels_dict[4], df_labels_dict[5], df_labels_dict[6],\n",
    "                    df_labels_dict[7], df_labels_dict[8], df_labels_dict[9],\n",
    "                    df_labels_dict[10], df_labels_dict[11], df_labels_dict[12],\n",
    "                    df_labels_dict[13], df_labels_dict[14]\n",
    "                   ]\n",
    "\n",
    "df_features = pd.concat(df_features_frames, ignore_index=True)\n",
    "df_labels = pd.concat(df_labels_frames, ignore_index=True)\n",
    "\n",
    "df_features.drop('num_plans', axis=1, inplace=True)\n",
    "df_labels.drop('num_plans', axis=1, inplace=True)\n",
    "\n",
    "df = pd.merge(df_features, df_labels,\n",
    "              how='inner',\n",
    "              left_on=['datestr', 'city_id', 'hour_of_day'],\n",
    "              right_on=['datestr', 'city_id', 'hour_of_day']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset size = 20933; the new dataset size = 20509\n"
     ]
    }
   ],
   "source": [
    "# Filter out outliers\n",
    "df_clean = df[df['hour_gb_gamma_95'] < 3].reset_index(drop=True)\n",
    "print(f\"The original dataset size = {len(df)}; the new dataset size = {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "gb_100 = df_clean['hour_gb_gamma_100']\n",
    "gb_99 = df_clean['hour_gb_gamma_99']\n",
    "gb_95 = df_clean['hour_gb_gamma_95']\n",
    "gb_90 = df_clean['hour_gb_gamma_90']\n",
    "\n",
    "fare_100 = df_clean['hour_fare_gamma_100']\n",
    "fare_99 = df_clean['hour_fare_gamma_99']\n",
    "fare_95 = df_clean['hour_fare_gamma_95']\n",
    "fare_90 = df_clean['hour_fare_gamma_90']\n",
    "\n",
    "y = gb_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df_clean.loc[:, ['market_log_cr',\n",
    "                     'market_log_eta',\n",
    "                     'market_log_fare_p50_scale',\n",
    "                     'market_surge'\n",
    "                    ]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training & Test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x1, x2, x3, x, y, b0, b1, b2, b3):\n",
    "    alpha = 1 - 1/np.power(np.maximum(x, 1), b3)\n",
    "    return np.mean(np.power(b0 + b1*x1 + b2*x2 + alpha*x3 - y, 2) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x1, x2, x3, x, y, b0, b1, b2, b3):\n",
    "    alpha = 1 - 1/np.power(np.maximum(x, 1), b3)\n",
    "    re = b0 + b1*x1 + b2*x2 + alpha*x3 - y\n",
    "    \n",
    "    db0 = np.mean(re)\n",
    "    db1 = np.mean(re * x1 - 0.2 * b1)\n",
    "    db2 = np.mean(re * x2 - 0.2 * b2)\n",
    "    db3 = np.mean(re * x3 * b3 * np.power(np.maximum(x, 1), -b3-1) - 0.2 * b3)\n",
    "    \n",
    "    return db0, db1, db2, db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(n_iter=20, step_size=400, lr=0.01, tol=1e-03):\n",
    "    N = len(X_train)\n",
    "    num_iters = N // step_size\n",
    "    \n",
    "    b0 = 0.0\n",
    "    b1 = 1.0\n",
    "    b2 = 2.0\n",
    "    b3 = 1.0\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    best_b0 = b0\n",
    "    best_b1 = b1\n",
    "    best_b2 = b2\n",
    "    best_b3 = b3\n",
    "    \n",
    "    best_test_loss = np.inf\n",
    "    best_iter = 0\n",
    "    \n",
    "    for it in range(n_iter):\n",
    "        print(f\"We are in iteration: {it+1} ...\")\n",
    "        \n",
    "        # Reshuffle\n",
    "        ids = list(range(N))\n",
    "        np.random.shuffle(ids)\n",
    "        \n",
    "        X_train_ids = X_train.reset_index(drop=True)\n",
    "        y_train_ids = y_train.reset_index(drop=True)\n",
    "        \n",
    "        train_loss = 0\n",
    "        for idx in range(num_iters):\n",
    "            y = y_train_ids[ids][idx*step_size:(idx+1)*step_size]\n",
    "            x1 = X_train_ids['market_log_cr'][ids][idx*step_size:(idx+1)*step_size]\n",
    "            x2 = X_train_ids['market_log_eta'][ids][idx*step_size:(idx+1)*step_size]\n",
    "            x3 = X_train_ids['market_log_fare_p50_scale'][ids][idx*step_size:(idx+1)*step_size]\n",
    "            x = X_train_ids['market_surge'][ids][idx*step_size:(idx+1)*step_size]\n",
    "            \n",
    "            cur_loss = calculate_loss(x1, x2, x3, x, y, b0, b1, b2, b3)\n",
    "            train_loss += cur_loss\n",
    "            \n",
    "            db0, db1, db2, db3 = grad(x1, x2, x3, x, y, b0, b1, b2, b3)\n",
    "            \n",
    "            if np.all(np.abs([lr*db0, lr*db1, lr*db2, lr*db3]) <= tol):\n",
    "                break\n",
    "            \n",
    "            b0 -= lr * db0\n",
    "            b1 -= lr * db1\n",
    "            b2 -= lr * db2\n",
    "            b3 -= lr * db3\n",
    "        \n",
    "        train_loss /= num_iters\n",
    "        print(f\"Train Loss = {train_loss}\")\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Test loss\n",
    "        y = y_test\n",
    "        x1 = X_test['market_log_cr']\n",
    "        x2 = X_test['market_log_eta']\n",
    "        x3 = X_test['market_log_fare_p50_scale']\n",
    "        x = X_test['market_surge']\n",
    "        test_loss = calculate_loss(x1, x2, x3, x, y, b0, b1, b2, b3)\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_iter = it\n",
    "\n",
    "            best_b0 = b0\n",
    "            best_b1 = b1\n",
    "            best_b2 = b2\n",
    "            best_b3 = b3\n",
    "        \n",
    "        print(f\"Test Loss = {test_loss}\")\n",
    "        \n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    return best_b0, best_b1, best_b2, best_b3, best_test_loss, best_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are in iteration: 1 ...\n",
      "Train Loss = 2.3323057919906893\n",
      "Test Loss = 1.4134222698040684\n",
      "We are in iteration: 2 ...\n",
      "Train Loss = 1.0018397748030892\n",
      "Test Loss = 0.7146950493105182\n",
      "We are in iteration: 3 ...\n",
      "Train Loss = 0.598591309855348\n",
      "Test Loss = 0.5014664424124013\n",
      "We are in iteration: 4 ...\n",
      "Train Loss = 0.4785619228325616\n",
      "Test Loss = 0.43723636656985754\n",
      "We are in iteration: 5 ...\n",
      "Train Loss = 0.38155194955592586\n",
      "Test Loss = 0.4207939762998643\n",
      "We are in iteration: 6 ...\n",
      "Train Loss = 0.03848624987776011\n",
      "Test Loss = 0.4204112503748586\n",
      "We are in iteration: 7 ...\n",
      "Train Loss = 0.2082439042819725\n",
      "Test Loss = 0.4192252588804633\n",
      "We are in iteration: 8 ...\n",
      "Train Loss = 0.10467701799529712\n",
      "Test Loss = 0.418500053918642\n",
      "We are in iteration: 9 ...\n",
      "Train Loss = 0.02126249666823967\n",
      "Test Loss = 0.4186447054033014\n",
      "We are in iteration: 10 ...\n",
      "Train Loss = 0.08081877424061491\n",
      "Test Loss = 0.4173528656492568\n",
      "We are in iteration: 11 ...\n",
      "Train Loss = 0.2140919834426107\n",
      "Test Loss = 0.4164968643411749\n",
      "We are in iteration: 12 ...\n",
      "Train Loss = 0.28239014627076303\n",
      "Test Loss = 0.41674450096010496\n",
      "We are in iteration: 13 ...\n",
      "Train Loss = 0.04350241226852284\n",
      "Test Loss = 0.4167921658142512\n",
      "We are in iteration: 14 ...\n",
      "Train Loss = 0.44462727470349944\n",
      "Test Loss = 0.4178339230317176\n",
      "We are in iteration: 15 ...\n",
      "Train Loss = 0.032249819645138685\n",
      "Test Loss = 0.41805995885409203\n",
      "We are in iteration: 16 ...\n",
      "Train Loss = 0.07345957542803301\n",
      "Test Loss = 0.41963384496100714\n",
      "We are in iteration: 17 ...\n",
      "Train Loss = 0.052938098255576355\n",
      "Test Loss = 0.4187907465103894\n",
      "We are in iteration: 18 ...\n",
      "Train Loss = 0.02899427792454483\n",
      "Test Loss = 0.41958373132026255\n",
      "We are in iteration: 19 ...\n",
      "Train Loss = 0.01123582893488273\n",
      "Test Loss = 0.41958373132026255\n",
      "We are in iteration: 20 ...\n",
      "Train Loss = 0.35215316155771187\n",
      "Test Loss = 0.4200708457813087\n",
      "We are in iteration: 21 ...\n",
      "Train Loss = 0.22027041593513536\n",
      "Test Loss = 0.4202434576728143\n",
      "We are in iteration: 22 ...\n",
      "Train Loss = 0.01180388308990063\n",
      "Test Loss = 0.4202434576728143\n",
      "We are in iteration: 23 ...\n",
      "Train Loss = 0.054247732835965144\n",
      "Test Loss = 0.41880034822151535\n",
      "We are in iteration: 24 ...\n",
      "Train Loss = 0.3347740631748254\n",
      "Test Loss = 0.418656861731573\n",
      "We are in iteration: 25 ...\n",
      "Train Loss = 0.21400789455500518\n",
      "Test Loss = 0.42039358311208874\n",
      "We are in iteration: 26 ...\n",
      "Train Loss = 0.14654759631909695\n",
      "Test Loss = 0.422477863872027\n",
      "We are in iteration: 27 ...\n",
      "Train Loss = 0.22994173703552262\n",
      "Test Loss = 0.42264179873256286\n",
      "We are in iteration: 28 ...\n",
      "Train Loss = 0.09318627795407317\n",
      "Test Loss = 0.4227233169441057\n",
      "We are in iteration: 29 ...\n",
      "Train Loss = 0.011076017738793369\n",
      "Test Loss = 0.4227233169441057\n",
      "We are in iteration: 30 ...\n",
      "Train Loss = 0.021946623395799628\n",
      "Test Loss = 0.4226125591714685\n",
      "We are in iteration: 31 ...\n",
      "Train Loss = 0.013338378473653097\n",
      "Test Loss = 0.4226125591714685\n",
      "We are in iteration: 32 ...\n",
      "Train Loss = 0.24464790978298104\n",
      "Test Loss = 0.42462284249342996\n",
      "We are in iteration: 33 ...\n",
      "Train Loss = 0.457375401869459\n",
      "Test Loss = 0.4278971171093153\n",
      "We are in iteration: 34 ...\n",
      "Train Loss = 0.4611432635559695\n",
      "Test Loss = 0.4314889698697506\n",
      "We are in iteration: 35 ...\n",
      "Train Loss = 0.07520382726690816\n",
      "Test Loss = 0.43228669388455215\n",
      "We are in iteration: 36 ...\n",
      "Train Loss = 0.03966701809127768\n",
      "Test Loss = 0.43311086386012254\n",
      "We are in iteration: 37 ...\n",
      "Train Loss = 0.1800379606049536\n",
      "Test Loss = 0.4338321331830133\n",
      "We are in iteration: 38 ...\n",
      "Train Loss = 0.2625668771038051\n",
      "Test Loss = 0.43526785500928844\n",
      "We are in iteration: 39 ...\n",
      "Train Loss = 0.34172874505380546\n",
      "Test Loss = 0.4376566646649346\n",
      "We are in iteration: 40 ...\n",
      "Train Loss = 0.4329554921984221\n",
      "Test Loss = 0.4418051187712235\n",
      "We are in iteration: 41 ...\n",
      "Train Loss = 0.3471076373833432\n",
      "Test Loss = 0.44795583513568815\n",
      "We are in iteration: 42 ...\n",
      "Train Loss = 0.48767973572173773\n",
      "Test Loss = 0.45281922815216075\n",
      "We are in iteration: 43 ...\n",
      "Train Loss = 0.3129480112737288\n",
      "Test Loss = 0.4545916496322577\n",
      "We are in iteration: 44 ...\n",
      "Train Loss = 0.4963646142439877\n",
      "Test Loss = 0.4600442642786839\n",
      "We are in iteration: 45 ...\n",
      "Train Loss = 0.024072041443937223\n",
      "Test Loss = 0.46065770197277\n",
      "We are in iteration: 46 ...\n",
      "Train Loss = 0.5035629255882612\n",
      "Test Loss = 0.4664932978937671\n",
      "We are in iteration: 47 ...\n",
      "Train Loss = 0.5105412483339802\n",
      "Test Loss = 0.47270363590295555\n",
      "We are in iteration: 48 ...\n",
      "Train Loss = 0.5211443899834555\n",
      "Test Loss = 0.4793301124168075\n",
      "We are in iteration: 49 ...\n",
      "Train Loss = 0.5298170645307875\n",
      "Test Loss = 0.48637063005712694\n",
      "We are in iteration: 50 ...\n",
      "Train Loss = 0.5354468069933631\n",
      "Test Loss = 0.4939800179103436\n",
      "We are in iteration: 51 ...\n",
      "Train Loss = 0.5481252841225427\n",
      "Test Loss = 0.502079383540913\n",
      "We are in iteration: 52 ...\n",
      "Train Loss = 0.5586535595469626\n",
      "Test Loss = 0.5107884757148562\n",
      "We are in iteration: 53 ...\n",
      "Train Loss = 0.5687996994000605\n",
      "Test Loss = 0.5201416537920238\n",
      "We are in iteration: 54 ...\n",
      "Train Loss = 0.5822416967383391\n",
      "Test Loss = 0.5301403827574828\n",
      "We are in iteration: 55 ...\n",
      "Train Loss = 0.5941370507728589\n",
      "Test Loss = 0.5409389889817338\n",
      "We are in iteration: 56 ...\n",
      "Train Loss = 0.6102264500470019\n",
      "Test Loss = 0.5525341971678414\n",
      "We are in iteration: 57 ...\n",
      "Train Loss = 0.623425460991831\n",
      "Test Loss = 0.5650953103956727\n",
      "We are in iteration: 58 ...\n",
      "Train Loss = 0.6444359972644096\n",
      "Test Loss = 0.5786381724647595\n",
      "We are in iteration: 59 ...\n",
      "Train Loss = 0.6565202762911191\n",
      "Test Loss = 0.5933367665936968\n",
      "We are in iteration: 60 ...\n",
      "Train Loss = 0.6817348306541674\n",
      "Test Loss = 0.6092392338242293\n",
      "We are in iteration: 61 ...\n",
      "Train Loss = 0.7033920379024373\n",
      "Test Loss = 0.6264938968987106\n",
      "We are in iteration: 62 ...\n",
      "Train Loss = 0.7259828829099167\n",
      "Test Loss = 0.6452566380673196\n",
      "We are in iteration: 63 ...\n",
      "Train Loss = 0.749679921773834\n",
      "Test Loss = 0.6657350977256947\n",
      "We are in iteration: 64 ...\n",
      "Train Loss = 0.7732138699345313\n",
      "Test Loss = 0.6880344437273519\n",
      "We are in iteration: 65 ...\n",
      "Train Loss = 0.8045313469321844\n",
      "Test Loss = 0.7125295380733938\n",
      "We are in iteration: 66 ...\n",
      "Train Loss = 0.8362989393293152\n",
      "Test Loss = 0.7392293996966521\n",
      "We are in iteration: 67 ...\n",
      "Train Loss = 0.8768072409377207\n",
      "Test Loss = 0.7684967926784082\n",
      "We are in iteration: 68 ...\n",
      "Train Loss = 0.9132147883807319\n",
      "Test Loss = 0.80076235927464\n",
      "We are in iteration: 69 ...\n",
      "Train Loss = 0.959672210947561\n",
      "Test Loss = 0.8361609005781119\n",
      "We are in iteration: 70 ...\n",
      "Train Loss = 1.0090096932385197\n",
      "Test Loss = 0.875116881228244\n",
      "We are in iteration: 71 ...\n",
      "Train Loss = 1.0578694132248765\n",
      "Test Loss = 0.9179243639317375\n",
      "We are in iteration: 72 ...\n",
      "Train Loss = 1.1122879486104957\n",
      "Test Loss = 0.9651862861503925\n",
      "We are in iteration: 73 ...\n",
      "Train Loss = 1.1781997537633109\n",
      "Test Loss = 1.0173597759690447\n",
      "We are in iteration: 74 ...\n",
      "Train Loss = 1.2409249425697748\n",
      "Test Loss = 1.0748907408208837\n",
      "We are in iteration: 75 ...\n",
      "Train Loss = 1.316815586721943\n",
      "Test Loss = 1.13852138114263\n",
      "We are in iteration: 76 ...\n",
      "Train Loss = 1.4070675156525785\n",
      "Test Loss = 1.209132882570727\n",
      "We are in iteration: 77 ...\n",
      "Train Loss = 1.4941223623064317\n",
      "Test Loss = 1.2871537798937727\n",
      "We are in iteration: 78 ...\n",
      "Train Loss = 1.6015686091778314\n",
      "Test Loss = 1.3736938473269058\n",
      "We are in iteration: 79 ...\n",
      "Train Loss = 1.7159589974305458\n",
      "Test Loss = 1.4696435881238448\n",
      "We are in iteration: 80 ...\n",
      "Train Loss = 1.836985325097676\n",
      "Test Loss = 1.576332722125342\n",
      "We are in iteration: 81 ...\n",
      "Train Loss = 1.9909596395366844\n",
      "Test Loss = 1.6950855217318186\n",
      "We are in iteration: 82 ...\n",
      "Train Loss = 2.11956171777578\n",
      "Test Loss = 1.8264060957784871\n",
      "We are in iteration: 83 ...\n",
      "Train Loss = 2.3078919788237306\n",
      "Test Loss = 1.9731347857838335\n",
      "We are in iteration: 84 ...\n",
      "Train Loss = 2.507065155214186\n",
      "Test Loss = 2.136257650533101\n",
      "We are in iteration: 85 ...\n",
      "Train Loss = 2.717943364803843\n",
      "Test Loss = 2.3178674921479034\n",
      "We are in iteration: 86 ...\n",
      "Train Loss = 2.9401646684208953\n",
      "Test Loss = 2.5197179334272763\n",
      "We are in iteration: 87 ...\n",
      "Train Loss = 3.2347177802227023\n",
      "Test Loss = 2.7453122849243226\n",
      "We are in iteration: 88 ...\n",
      "Train Loss = 3.530290960795128\n",
      "Test Loss = 2.9967371542010373\n",
      "We are in iteration: 89 ...\n",
      "Train Loss = 3.8207632239629734\n",
      "Test Loss = 3.276354311576659\n",
      "We are in iteration: 90 ...\n",
      "Train Loss = 4.212837191041696\n",
      "Test Loss = 3.589374502181925\n",
      "We are in iteration: 91 ...\n",
      "Train Loss = 4.6352873897446125\n",
      "Test Loss = 3.9385901435243063\n",
      "We are in iteration: 92 ...\n",
      "Train Loss = 5.067690971207232\n",
      "Test Loss = 4.3268853338696\n",
      "We are in iteration: 93 ...\n",
      "Train Loss = 5.546014177329387\n",
      "Test Loss = 4.760900761406714\n",
      "We are in iteration: 94 ...\n",
      "Train Loss = 6.129536316053838\n",
      "Test Loss = 5.245835718278261\n",
      "We are in iteration: 95 ...\n",
      "Train Loss = 6.710301412271919\n",
      "Test Loss = 5.785472237452348\n",
      "We are in iteration: 96 ...\n",
      "Train Loss = 7.424204719903254\n",
      "Test Loss = 6.3904226042039705\n",
      "We are in iteration: 97 ...\n",
      "Train Loss = 8.20311108330757\n",
      "Test Loss = 7.065703269464049\n",
      "We are in iteration: 98 ...\n",
      "Train Loss = 9.03173489383447\n",
      "Test Loss = 7.819000823536558\n",
      "We are in iteration: 99 ...\n",
      "Train Loss = 9.995748932541925\n",
      "Test Loss = 8.663005451599126\n",
      "We are in iteration: 100 ...\n",
      "Train Loss = 11.054062511369274\n",
      "Test Loss = 9.605427328083659\n"
     ]
    }
   ],
   "source": [
    "best_b0, best_b1, best_b2, best_b3, best_test_loss, best_iter = main(n_iter=100, lr=0.01, step_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6925027509382682 0.2905504174655244 1.352525522576194 3.5240774606967213 0.4164968643411749 10\n"
     ]
    }
   ],
   "source": [
    "print(best_b0, best_b1, best_b2, best_b3, best_test_loss, best_iter)\n",
    "# gamma = 0.95, fare_scaling = p50, with regularization 0.1\n",
    "# --- 1.517388764794251 0.09627509778325313 0.7899406274789974 2.0840185343833264 0.22026837308085773 99\n",
    "\n",
    "# gamma = 0.95, fare_scaling = p50, with regularization 0.2\n",
    "# --- 1.6925027509382682 0.2905504174655244 1.352525522576194 3.5240774606967213 0.4164968643411749 10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "03. Python 3.6 (General DS)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
