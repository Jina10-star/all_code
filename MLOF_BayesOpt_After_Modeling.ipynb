{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# source $VIRTUAL_ENV_DIR/python3/bin/activate\n",
    " \n",
    "# # Install latest mxpkg version (to specify version, use syntax: pip install mxpkg==1.1.7)\n",
    "# pip install dataclasses\n",
    "# pip install matching-ds-tools\n",
    " \n",
    "# deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from queryrunner_client import Client\n",
    "USER_EMAIL = 'thai@uber.com'\n",
    "qclient = Client(user_email=USER_EMAIL)\n",
    "CONSUMER_NAME = 'intelligentdispatch'\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "#num_cores = multiprocessing.cpu_count()  -- 48\n",
    "n_cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from queryrunner_client import Client as QRClient\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdstk\n",
    "from mdstk.data_fetcher.data_fetcher import DataFetcher\n",
    "from mdstk.data_fetcher.cached_data_fetcher import CachedDataFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://artifactory.uber.internal:4587/artifactory/api/pypi/pypi/simple/\n",
      "Requirement already satisfied: bayesian-optimization in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from bayesian-optimization) (1.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from bayesian-optimization) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from bayesian-optimization) (1.16.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.stats.mstats import gmean\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collection\n",
    "\n",
    "QUERY = \"\"\"\n",
    "with dispatch as (\n",
    "select \n",
    "    datestr,\n",
    "    msg.cityid,\n",
    "    msg.ctplangenrequestuuid as plangen_uuid,\n",
    "    msg.ctrequestuuid as scan_uuid,\n",
    "    j as job_uuid,\n",
    "    msg.supplyuuid,\n",
    "    msg.planactiontype\n",
    "from \n",
    "    rawdata_user.kafka_hp_multileg_dispatched_plan_nodedup\n",
    "cross join \n",
    "    unnest(msg.jobuuid) jobs(j)\n",
    "where \n",
    "    datestr = '{datestr}'\n",
    "    and msg.cityid = {city_id}\n",
    "    and msg.vehicleviewid = {vvid} \n",
    "    and msg.tenancy = 'uber/production'\n",
    "    and CARDINALITY(msg.jobuuid) > 0\n",
    "    and substr(msg.ctrequestuuid, 1, length('{digits}')) = '{digits}'\n",
    "),\n",
    "plangen as (\n",
    "select \n",
    "    msg.scanuuid as plangen_uuid, \n",
    "    p.uuid as job_uuid,\n",
    "    j.supplyuuid\n",
    "from \n",
    "    rawdata_user.kafka_hp_multileg_matching_observability_proposals_v2_nodedup\n",
    "cross join \n",
    "    unnest(msg.proposals) as job(j)\n",
    "cross join \n",
    "    unnest(j.jobs) as plan(p)\n",
    "where \n",
    "    datestr = '{datestr}'\n",
    "    and msg.cityid = {city_id}\n",
    "    and msg.flowtype = 'solo_batch'\n",
    "    and msg.tenancy = 'uber/production'\n",
    "    and j.status = 'eligible'\n",
    "),\n",
    "mgv as (\n",
    "select datestr,\n",
    "    msg.city_id,\n",
    "    msg.job_uuid,\n",
    "    msg.client_uuid,\n",
    "    msg.ct_request_uuid as plangen_uuid,\n",
    "    msg.supply_uuid,\n",
    "    msg.supply_plan_uuid as plan_uuid,\n",
    "    msg.unadjusted_eta as eta,\n",
    "    (CASE\n",
    "      WHEN msg.adjustedeta > 1500 THEN 1500.0\n",
    "      WHEN msg.adjustedeta < 0 THEN 0.0\n",
    "      ELSE msg.adjustedeta\n",
    "    END) as adjustedeta,\n",
    "    round(msg.job_surge, 4) as surge_mul,\n",
    "    round(msg.eventual_completion_probability, 4) as eventual_comp_prob,\n",
    "    msg.ranking_metric,\n",
    "    round(1 - msg.solo_cancel_model_driver_accept_prob, 4) as d_proba,\n",
    "    round(1 - msg.solo_cancel_model_rider_accept_prob, 4) as r_proba,\n",
    "    round(1 - msg.spinner_survive_prob_before_next_scan, 4) as s_proba,\n",
    "    msg.preferred_destination_adjustment,\n",
    "    msg.objective_value as of_value,\n",
    "    msg.inconvenience_etd - msg.ranking_metric as trip_length\n",
    "from   \n",
    "    rawdata.kafka_hp_multileg_mgv_log_nodedup\n",
    "where  \n",
    "    datestr = '{datestr}'\n",
    "    and msg.city_id = {city_id}\n",
    "    and msg.tenancy = 'uber/production'\n",
    "    and msg.vehicle_view_id = {vvid} \n",
    "    and msg.flow_type = 'solo_batch'\n",
    "    and msg.job_uuid <> msg.client_uuid\n",
    "    and msg.calculator_type = 'markov_eta_v2'\n",
    "),\n",
    "test as (\n",
    "select \n",
    "    mgv.datestr,\n",
    "    mgv.city_id,\n",
    "    dispatch.scan_uuid,\n",
    "    mgv.plangen_uuid,\n",
    "    mgv.job_uuid,\n",
    "    dispatch.planactiontype,\n",
    "    mgv.supply_uuid,\n",
    "    case when dispatch.supplyuuid = mgv.supply_uuid then 1 else 0 end as is_selected,\n",
    "    mgv.eta,\n",
    "    mgv.adjustedeta,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1), 4) as eta_one,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.05), 4) as eta_one_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.10), 4) as eta_one_ten,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.15), 4) as eta_one_fifteen,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.20), 4) as eta_one_twenty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.25), 4) as eta_one_quarter,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.30), 4) as eta_one_thirty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.35), 4) as eta_one_thirty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.40), 4) as eta_one_forty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.45), 4) as eta_one_forty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.50), 4) as eta_one_fifty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.55), 4) as eta_one_fifty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.60), 4) as eta_one_sixty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.65), 4) as eta_one_sixty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.70), 4) as eta_one_seventy,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.75), 4) as eta_one_seventy_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.80), 4) as eta_one_eighty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.85), 4) as eta_one_eighty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.90), 4) as eta_one_ninety,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.95), 4) as eta_one_ninety_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 2), 4) as eta_square,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 3), 4) as eta_cube,\n",
    "    mgv.surge_mul,\n",
    "    mgv.eventual_comp_prob,\n",
    "    round(1.0 / (1.0 + POWER(mgv.surge_mul, 2)), 4) as network_contention_2,\n",
    "    round(1.0 / (1.0 + POWER(mgv.surge_mul, 3)), 4) as network_contention_3,\n",
    "    round(1.0 / (1.0 + POWER(mgv.surge_mul, 5)), 4) as network_contention_5,\n",
    "    mgv.ranking_metric,\n",
    "    mgv.d_proba,\n",
    "    mgv.r_proba,\n",
    "    mgv.s_proba,\n",
    "    round((1.0 - mgv.d_proba) * (1.0 - mgv.r_proba) * (1.0 - mgv.s_proba) + mgv.eventual_comp_prob * mgv.d_proba, 4) as cr_ratio,\n",
    "    round((1.0 - mgv.d_proba) * (1.0 - mgv.r_proba) + mgv.eventual_comp_prob * mgv.d_proba, 4) as crof_ratio,\n",
    "    mgv.preferred_destination_adjustment,\n",
    "    mgv.of_value,\n",
    "    mgv.trip_length,\n",
    "    fare.est_rider_quoted_final_fare as fare,\n",
    "    fare.est_rider_quoted_final_fare * 1.0 / fare.usd_fx_rate as fare_usd\n",
    "from\n",
    "    mgv\n",
    "join\n",
    "    plangen\n",
    "on \n",
    "    mgv.plangen_uuid = plangen.plangen_uuid\n",
    "    and mgv.job_uuid = plangen.job_uuid\n",
    "    and mgv.supply_uuid = plangen.supplyuuid\n",
    "join\n",
    "    dispatch\n",
    "on\n",
    "    mgv.plangen_uuid = dispatch.plangen_uuid\n",
    "    and mgv.job_uuid = dispatch.job_uuid\n",
    "join\n",
    "    dwh.fact_trip_fare fare \n",
    "on\n",
    "    mgv.job_uuid = fare.trip_uuid\n",
    "    and fare.datestr = '{datestr}'\n",
    "    and fare.city_id = {city_id}\n",
    ")\n",
    "select * from test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Query:\n",
    "    prefix: str\n",
    "    hex_digits: str\n",
    "    city_id: int\n",
    "    vvid: str\n",
    "    datestr: str\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.name = f'{self.prefix}_city{self.city_id}_{self.vvid}_{self.datestr}_segment{self.hex_digits}'\n",
    "        self.qry = QUERY.format(city_id=self.city_id, vvid=self.vvid, digits=self.hex_digits, datestr=self.datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataFetcher(DataFetcher):\n",
    "    def query_many_presto(self, *args, **kwargs):\n",
    "        return super().query_many_presto(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new objective function\n",
    "def clean_df(df):\n",
    "    df = df[df['fare'].notnull()]\n",
    "    df['trip_length'][df['trip_length'] <= 100] = 100\n",
    "    df = df.drop_duplicates(subset=['job_uuid', 'supply_uuid'])\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# def compute_new_of(df):\n",
    "    \n",
    "#     # Baseline (Markov)\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.945,\n",
    "#  'overwrite': 0.0,\n",
    "#  'Average Matched ETA': 487.91,\n",
    "#  'P90 Matched ETA': 1122.0,\n",
    "#  'Driver AR': 0.496,\n",
    "#  'Rider cancel': 0.154,\n",
    "#  'Average trip length': 829.1,\n",
    "#  'Average Matched Fare': 16.0,\n",
    "#  'Total GB': 38381}\n",
    "\n",
    "#     # EFOF\n",
    "#     df['new_of'] = - df['eta_square'] * df['cr_ratio'] * df['fare']\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.985,\n",
    "#  'overwrite': 0.164,\n",
    "#  'Average Matched ETA': 531.9,\n",
    "#  'P90 Matched ETA': 1219.8,\n",
    "#  'Driver AR': 0.493,\n",
    "#  'Rider cancel': 0.171,\n",
    "#  'Average trip length': 835.03,\n",
    "#  'Average Matched Fare': 16.1,\n",
    "#  'Total GB': 39531}\n",
    "\n",
    "#     # CROF\n",
    "#     df['new_of'] = - df['eta_square'] * df['crof_ratio']\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.984,\n",
    "#  'overwrite': 0.134,\n",
    "#  'Average Matched ETA': 530.09,\n",
    "#  'P90 Matched ETA': 1217.0,\n",
    "#  'Driver AR': 0.493,\n",
    "#  'Rider cancel': 0.169,\n",
    "#  'Average trip length': 833.92,\n",
    "#  'Average Matched Fare': 16.08,\n",
    "#  'Total GB': 39573}\n",
    "\n",
    "############################################\n",
    "#             GUB as label                 #\n",
    "#              Unit: USD                   #\n",
    "############################################\n",
    "\n",
    "#     # gamma = 1.00 - with Intercept - MAIN II - Use local currency with a fixed exchange rate (which is ~ 1 at the median value)\n",
    "#     df['new_of'] = - (0.4019 * df['d_proba'] \\\n",
    "#                       - 0.9627 * df['eventual_comp_prob'] \\\n",
    "#                       - 1.3453 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.6210 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       - 0.6435 * df['eta_one_quarter'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       - 1.1098 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "#                       + 4.1085 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "#                       + 0.15\n",
    "#                      )\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.981,\n",
    "#  'overwrite': 0.19,\n",
    "#  'Average Matched ETA': 531.33,\n",
    "#  'P90 Matched ETA': 1212.0,\n",
    "#  'Driver AR': 0.501,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 834.63,\n",
    "#  'Average Matched Fare': 16.12,\n",
    "#  'Total GB': 40213}\n",
    "\n",
    "#     return df\n",
    "\n",
    "def global_new_of(df):\n",
    "\n",
    "    df['global_new_of'] = - (0.4019 * df['d_proba'] \\\n",
    "                      - 0.9627 * df['eventual_comp_prob'] \\\n",
    "                      - 1.3453 * df['eta_one'] * df['cr_ratio'] \\\n",
    "                      + 0.6210 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "                      - 0.6435 * df['eta_one_quarter'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "                      - 1.1098 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "                      + 4.1085 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "                      + 1.3591\n",
    "                     )\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_new_of(\n",
    "        df,\n",
    "        a = 0.4019,\n",
    "        b = -0.9627,\n",
    "        c = -1.3453,\n",
    "        d = 0.6210,\n",
    "        e = -0.6435,\n",
    "        f = -1.1098,\n",
    "        g = 4.1085,\n",
    "        h = 1.3591\n",
    "    ):\n",
    "\n",
    "    df['new_of'] = - (a * df['d_proba'] \\\n",
    "                      + b * df['eventual_comp_prob'] \\\n",
    "                      + c * df['eta_one'] * df['cr_ratio'] \\\n",
    "                      + d * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "                      + e * df['eta_one_quarter'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "                      + f * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "                      + g * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "                      + h\n",
    "             )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local solver\n",
    "def solve_dict(\n",
    "    scan: dict, \n",
    "    cost_col: str, \n",
    "    job_singleton: float = 1500,\n",
    "    infinity: float = 1000000\n",
    "):\n",
    "    job_list = list(set([k[0] for k in scan.keys()]))\n",
    "    job_idx = {j: i for i, j in enumerate(job_list)}\n",
    "    job_count = len(job_list)\n",
    "\n",
    "    supply_list = list(set([k[1] for k in scan.keys()]))\n",
    "    supply_idx = {s: i for i, s in enumerate(supply_list)}\n",
    "    supply_count = len(supply_list)\n",
    "    \n",
    "    utility = np.full((len(job_list), len(supply_list) + len(job_list)), infinity, dtype=np.float32)\n",
    "    for k in scan.keys():\n",
    "        jidx = job_idx[k[0]]\n",
    "        sidx = supply_idx[k[1]]\n",
    "        utility[jidx, sidx] = scan[k][cost_col]\n",
    "    for i in range(len(job_list)):\n",
    "        utility[i, supply_count + i] = job_singleton\n",
    "            \n",
    "    # solve\n",
    "    job_sol, supply_sol = linear_sum_assignment(utility)\n",
    "\n",
    "    result = set()\n",
    "    for jidx, sidx in zip(job_sol, supply_sol):\n",
    "        j = job_list[jidx]\n",
    "        if sidx >= supply_count:\n",
    "            result.add((j,))\n",
    "        else:\n",
    "            s = supply_list[sidx]\n",
    "            result.add((j, s))\n",
    "            \n",
    "    assert len(result) == len(job_list)\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import field\n",
    "\n",
    "@dataclass\n",
    "class ScanMetrics:\n",
    "    total_jobs: int = 0.\n",
    "    total_eta: float = 0.\n",
    "    total_offer: float = 0.\n",
    "    total_ar: float = 0.\n",
    "    total_rc: float = 0.\n",
    "    total_trip: float = 0.\n",
    "    total_gb: float = 0.\n",
    "    total_fare: float = 0.\n",
    "    total_overwrite: int = 0.\n",
    "    total_global_new_of: float = 0.\n",
    "    list_etas: list = field(default_factory = list)\n",
    "    \n",
    "    def __add__(self, o: 'ScanMetrics') -> 'ScanMetrics':\n",
    "        return ScanMetrics(\n",
    "            self.total_jobs + o.total_jobs,\n",
    "            self.total_eta + o.total_eta,\n",
    "            self.total_offer + o.total_offer,\n",
    "            self.total_ar + o.total_ar,\n",
    "            self.total_rc + o.total_rc,\n",
    "            self.total_trip + o.total_trip,\n",
    "            self.total_overwrite + o.total_overwrite,\n",
    "            self.total_gb + o.total_gb,\n",
    "            self.total_fare + o.total_fare,\n",
    "            self.total_global_new_of + o.total_global_new_of,\n",
    "            self.list_etas.expand + o.list_etas\n",
    "        )\n",
    "    def __iadd__(self, o: 'ScanMetrics') -> 'ScanMetrics':\n",
    "        self.total_jobs += o.total_jobs\n",
    "        self.total_eta += o.total_eta\n",
    "        self.total_offer += o.total_offer\n",
    "        self.total_ar += o.total_ar\n",
    "        self.total_rc += o.total_rc\n",
    "        self.total_trip += o.total_trip\n",
    "        self.total_overwrite += o.total_overwrite\n",
    "        self.total_gb += o.total_gb\n",
    "        self.total_fare += o.total_fare\n",
    "        self.total_global_new_of += o.total_global_new_of\n",
    "        self.list_etas += o.list_etas\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Summary\n",
    "def metric_summary_dict(\n",
    "    scan_dict: Dict[str, Dict[str, Any]],\n",
    "    matching: set, \n",
    "    overwrite: int,\n",
    ") -> ScanMetrics:\n",
    "    sm = ScanMetrics()\n",
    "    sm.total_jobs = len(matching)\n",
    "    sm.total_overwrite = overwrite\n",
    "    \n",
    "    for m in matching:\n",
    "        if len(m) == 2:\n",
    "            row = scan_dict[(m[0], m[1])]\n",
    "            sm.total_offer += 1\n",
    "            sm.total_eta += row['eta']\n",
    "            sm.total_ar += 1 - row['d_proba']\n",
    "            sm.total_rc += row['r_proba']\n",
    "            if row['trip_length'] < 7200:\n",
    "                sm.total_trip += row['trip_length']\n",
    "            if row['fare_usd'] > 0:\n",
    "                sm.total_gb += (1 - row['d_proba']) * (1 - row['r_proba']) * row['fare_usd']\n",
    "                sm.total_fare += row['fare_usd']\n",
    "            \n",
    "            sm.total_global_new_of += (1 - row['d_proba']) * (1 - row['r_proba']) * row['global_new_of']\n",
    "                \n",
    "            sm.list_etas.append(row['eta'])\n",
    "\n",
    "    return sm\n",
    "\n",
    "def solve_all_dict(df, solver: Callable[[dict], set]):\n",
    "    total_scans = dict(tuple(df.groupby('scan_uuid')))\n",
    "\n",
    "    sm = ScanMetrics()\n",
    "    for scan_uuid, scan_df in total_scans.items():\n",
    "        scan = (scan_df.set_index(['job_uuid', 'supply_uuid']).to_dict(orient='index'))\n",
    "        matching, overwrite = solver(scan)\n",
    "        sm += metric_summary_dict(scan, matching, overwrite)\n",
    "    \n",
    "    return {'total_jobs': round(sm.total_jobs),\n",
    "            'match_rate': round(sm.total_offer * 1.0 / sm.total_jobs, 3),\n",
    "            'overwrite': round(sm.total_overwrite * 1.0 / sm.total_jobs, 3), # different decisions compared to Markov\n",
    "            'average_matched_eta': round(sm.total_eta * 1.0 / sm.total_offer, 2),\n",
    "            'p90_matched_eta': round(np.percentile(sm.list_etas, 90), 2),\n",
    "            'driver_ar': round(sm.total_ar * 1.0 / sm.total_offer, 3),\n",
    "            'rider_cancel': round(sm.total_rc * 1.0 / sm.total_offer, 3),\n",
    "            'average_trip_length': round(sm.total_trip * 1.0 / sm.total_offer, 2),\n",
    "            'average_matched_fare': round(sm.total_fare * 1.0 / sm.total_offer, 2),\n",
    "            'total_gb': round(sm.total_gb),\n",
    "            'global_new_of': round(sm.total_global_new_of * 1.0 / sm.total_jobs, 3)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_matching_decision(m1,m2):\n",
    "    return m1.difference(m2), m2.difference(m1)\n",
    "\n",
    "def supply_cost_solve_dict(scan, is_markov = False, secondary_singleton = 0.0):\n",
    "    # Markov\n",
    "    primary_matching = solve_dict(scan, 'of_value', job_singleton = 1500)\n",
    "    if is_markov:      \n",
    "        return primary_matching, 0\n",
    "    \n",
    "    # SCA solve\n",
    "    secondary_matching = solve_dict(scan, 'new_of', job_singleton = secondary_singleton)\n",
    "    different_matches = len(different_matching_decision(primary_matching, secondary_matching)[0])\n",
    "    return secondary_matching, different_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21/21 dataframes from cache!\n"
     ]
    }
   ],
   "source": [
    "prefix = 'replay'\n",
    "hex_digits = '36'\n",
    "\n",
    "city_id_vvids = {38: '(3298)', 37: '(5235)', 36: '(570)'}\n",
    "\n",
    "datestrs = [  # 1 week\n",
    "    '2022-09-13',\n",
    "    '2022-09-14',\n",
    "    '2022-09-15',\n",
    "    '2022-09-16',\n",
    "    '2022-09-17',\n",
    "    '2022-09-18',\n",
    "    '2022-09-19'\n",
    "]\n",
    "\n",
    "queries = [\n",
    "    Query(prefix=prefix, hex_digits=hex_digits, city_id=city_id, vvid=vvid, datestr=datestr)\n",
    "    for (city_id, vvid), datestr in itertools.product(city_id_vvids.items(), datestrs)\n",
    "]\n",
    "\n",
    "cache_qry_map = {\n",
    "    q.name: q.qry \n",
    "    for q in queries\n",
    "}\n",
    "\n",
    "cdf = CachedDataFetcher(\n",
    "    data_fetcher=MyDataFetcher(\n",
    "        user_email=USER_EMAIL,\n",
    "        consumer_name=CONSUMER_NAME,\n",
    "    ),\n",
    "    cache_qry_map=cache_qry_map,\n",
    "    datacenter='dca1',\n",
    "    datasource='presto-secure',\n",
    ")\n",
    "\n",
    "# In the first run, set bust_cache to True; after that, set this to False)\n",
    "cdf.fetch(bust_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "scans = pd.concat(cdf.dfs.values(), axis=0, ignore_index=True) \n",
    "df = scans\n",
    "df = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate global_new_of\n",
    "df = global_new_of(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_function(\n",
    "        a = 0.4019,\n",
    "        b = -0.9627,\n",
    "        c = -1.3453,\n",
    "        d = 0.6210,\n",
    "        e = -0.6435,\n",
    "        f = -1.1098,\n",
    "        g = 4.1085,\n",
    "        h = 1.3591,\n",
    "        seed = 96,\n",
    "        training = True,\n",
    "        iter_df = df\n",
    "    ):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    iter_df = compute_new_of(iter_df, a = a, b = b, c = c, d = d, e = e, f = f, g = g, h = h)\n",
    "    \n",
    "    # Solve is based on 'new_of'\n",
    "    matching = solve_all_dict(iter_df, lambda scan: supply_cost_solve_dict(scan, is_markov = False))\n",
    "    \n",
    "    # Evaluation is based on 'global_new_of'\n",
    "    rew = - matching['global_new_of'] - 0.015 * matching['average_matched_eta'] + 25 * matching['match_rate']\n",
    "    \n",
    "    if training:\n",
    "        return rew - 0.005 * sum([i**2 for i in [a, b, c, d, e, f, g, h]])\n",
    "    return rew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounded region of parameter space\n",
    "pbounds = {'a': (0, 1),\n",
    "           'b': (-2, 0),\n",
    "           'c': (-2, 0),\n",
    "           'd': (0, 2),\n",
    "           'e': (-2, 0),\n",
    "           'f': (-2, 0),\n",
    "           'g': (3, 5),\n",
    "           'h': (0, 2)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=optimized_function,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.probe(\n",
    "    params={'a': 0.4019,\n",
    "            'b': -0.9627,\n",
    "            'c': -1.3453,\n",
    "            'd': 0.6210,\n",
    "            'e': -0.6435,\n",
    "            'f': -1.1098,\n",
    "            'g': 4.1085,\n",
    "            'h': 1.3591},\n",
    "    lazy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     a     |     b     |     c     |     d     |     e     |     f     |     g     |     h     |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jaeger_tracing:Tracing sampler started with sampling refresh interval 60 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 32.2    \u001b[0m | \u001b[0m 0.4019  \u001b[0m | \u001b[0m-0.9627  \u001b[0m | \u001b[0m-1.345   \u001b[0m | \u001b[0m 0.621   \u001b[0m | \u001b[0m-0.6435  \u001b[0m | \u001b[0m-1.11    \u001b[0m | \u001b[0m 4.109   \u001b[0m | \u001b[0m 1.359   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 27.56   \u001b[0m | \u001b[0m 0.417   \u001b[0m | \u001b[0m-0.5594  \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m 0.6047  \u001b[0m | \u001b[0m-1.706   \u001b[0m | \u001b[0m-1.815   \u001b[0m | \u001b[0m 3.373   \u001b[0m | \u001b[0m 0.6911  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 32.31   \u001b[0m | \u001b[95m 0.3968  \u001b[0m | \u001b[95m-0.9224  \u001b[0m | \u001b[95m-1.162   \u001b[0m | \u001b[95m 1.37    \u001b[0m | \u001b[95m-1.591   \u001b[0m | \u001b[95m-0.2438  \u001b[0m | \u001b[95m 3.055   \u001b[0m | \u001b[95m 1.341   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 32.18   \u001b[0m | \u001b[0m 0.9087  \u001b[0m | \u001b[0m-0.0963  \u001b[0m | \u001b[0m-0.1637  \u001b[0m | \u001b[0m 0.6454  \u001b[0m | \u001b[0m-0.3824  \u001b[0m | \u001b[0m-0.1678  \u001b[0m | \u001b[0m 3.734   \u001b[0m | \u001b[0m 1.38    \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 32.28   \u001b[0m | \u001b[0m 0.0972  \u001b[0m | \u001b[0m-1.043   \u001b[0m | \u001b[0m-1.267   \u001b[0m | \u001b[0m 1.453   \u001b[0m | \u001b[0m-1.215   \u001b[0m | \u001b[0m-0.2768  \u001b[0m | \u001b[0m 3.169   \u001b[0m | \u001b[0m 1.356   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 32.31   \u001b[0m | \u001b[95m 0.3902  \u001b[0m | \u001b[95m-0.9253  \u001b[0m | \u001b[95m-1.163   \u001b[0m | \u001b[95m 1.372   \u001b[0m | \u001b[95m-1.581   \u001b[0m | \u001b[95m-0.2431  \u001b[0m | \u001b[95m 3.058   \u001b[0m | \u001b[95m 1.342   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 32.31   \u001b[0m | \u001b[0m 0.3806  \u001b[0m | \u001b[0m-0.93    \u001b[0m | \u001b[0m-1.163   \u001b[0m | \u001b[0m 1.376   \u001b[0m | \u001b[0m-1.567   \u001b[0m | \u001b[0m-0.2409  \u001b[0m | \u001b[0m 3.063   \u001b[0m | \u001b[0m 1.345   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 32.31   \u001b[0m | \u001b[95m 0.3921  \u001b[0m | \u001b[95m-0.9195  \u001b[0m | \u001b[95m-1.175   \u001b[0m | \u001b[95m 1.367   \u001b[0m | \u001b[95m-1.596   \u001b[0m | \u001b[95m-0.2606  \u001b[0m | \u001b[95m 3.053   \u001b[0m | \u001b[95m 1.331   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 32.2    \u001b[0m | \u001b[0m 0.397   \u001b[0m | \u001b[0m-1.003   \u001b[0m | \u001b[0m-1.2     \u001b[0m | \u001b[0m 0.6818  \u001b[0m | \u001b[0m-0.5148  \u001b[0m | \u001b[0m-0.9126  \u001b[0m | \u001b[0m 4.143   \u001b[0m | \u001b[0m 1.464   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 32.31   \u001b[0m | \u001b[95m 0.38    \u001b[0m | \u001b[95m-0.9223  \u001b[0m | \u001b[95m-1.192   \u001b[0m | \u001b[95m 1.37    \u001b[0m | \u001b[95m-1.594   \u001b[0m | \u001b[95m-0.2732  \u001b[0m | \u001b[95m 3.05    \u001b[0m | \u001b[95m 1.324   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 32.31   \u001b[0m | \u001b[0m 0.3697  \u001b[0m | \u001b[0m-0.9319  \u001b[0m | \u001b[0m-1.21    \u001b[0m | \u001b[0m 1.386   \u001b[0m | \u001b[0m-1.606   \u001b[0m | \u001b[0m-0.273   \u001b[0m | \u001b[0m 3.028   \u001b[0m | \u001b[0m 1.324   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 32.31   \u001b[0m | \u001b[0m 0.3695  \u001b[0m | \u001b[0m-0.9269  \u001b[0m | \u001b[0m-1.2     \u001b[0m | \u001b[0m 1.369   \u001b[0m | \u001b[0m-1.586   \u001b[0m | \u001b[0m-0.2799  \u001b[0m | \u001b[0m 3.052   \u001b[0m | \u001b[0m 1.307   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 32.31   \u001b[0m | \u001b[0m 0.3705  \u001b[0m | \u001b[0m-0.9203  \u001b[0m | \u001b[0m-1.202   \u001b[0m | \u001b[0m 1.368   \u001b[0m | \u001b[0m-1.589   \u001b[0m | \u001b[0m-0.2835  \u001b[0m | \u001b[0m 3.054   \u001b[0m | \u001b[0m 1.329   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 32.31   \u001b[0m | \u001b[0m 0.3808  \u001b[0m | \u001b[0m-0.9216  \u001b[0m | \u001b[0m-1.192   \u001b[0m | \u001b[0m 1.376   \u001b[0m | \u001b[0m-1.583   \u001b[0m | \u001b[0m-0.2886  \u001b[0m | \u001b[0m 3.047   \u001b[0m | \u001b[0m 1.32    \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 32.31   \u001b[0m | \u001b[0m 0.3584  \u001b[0m | \u001b[0m-0.9232  \u001b[0m | \u001b[0m-1.213   \u001b[0m | \u001b[0m 1.344   \u001b[0m | \u001b[0m-1.6     \u001b[0m | \u001b[0m-0.2649  \u001b[0m | \u001b[0m 3.075   \u001b[0m | \u001b[0m 1.322   \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 32.32   \u001b[0m | \u001b[95m 0.3426  \u001b[0m | \u001b[95m-0.8974  \u001b[0m | \u001b[95m-1.193   \u001b[0m | \u001b[95m 1.367   \u001b[0m | \u001b[95m-1.602   \u001b[0m | \u001b[95m-0.2573  \u001b[0m | \u001b[95m 3.035   \u001b[0m | \u001b[95m 1.299   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 32.17   \u001b[0m | \u001b[0m 0.3871  \u001b[0m | \u001b[0m-1.126   \u001b[0m | \u001b[0m-1.384   \u001b[0m | \u001b[0m 0.4751  \u001b[0m | \u001b[0m-0.3711  \u001b[0m | \u001b[0m-1.245   \u001b[0m | \u001b[0m 4.464   \u001b[0m | \u001b[0m 1.479   \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 32.32   \u001b[0m | \u001b[95m 0.3445  \u001b[0m | \u001b[95m-0.8868  \u001b[0m | \u001b[95m-1.185   \u001b[0m | \u001b[95m 1.366   \u001b[0m | \u001b[95m-1.605   \u001b[0m | \u001b[95m-0.2588  \u001b[0m | \u001b[95m 3.04    \u001b[0m | \u001b[95m 1.304   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 32.31   \u001b[0m | \u001b[0m 0.3481  \u001b[0m | \u001b[0m-0.8801  \u001b[0m | \u001b[0m-1.192   \u001b[0m | \u001b[0m 1.379   \u001b[0m | \u001b[0m-1.602   \u001b[0m | \u001b[0m-0.2585  \u001b[0m | \u001b[0m 3.048   \u001b[0m | \u001b[0m 1.306   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 32.27   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m-1.146   \u001b[0m | \u001b[0m-1.071   \u001b[0m | \u001b[0m 1.33    \u001b[0m | \u001b[0m-1.224   \u001b[0m | \u001b[0m-0.4996  \u001b[0m | \u001b[0m 3.35    \u001b[0m | \u001b[0m 1.455   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 32.24   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m-1.326   \u001b[0m | \u001b[0m-1.375   \u001b[0m | \u001b[0m 1.245   \u001b[0m | \u001b[0m-0.7934  \u001b[0m | \u001b[0m-0.4843  \u001b[0m | \u001b[0m 3.407   \u001b[0m | \u001b[0m 1.479   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 32.18   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.61    \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 32.16   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.908   \u001b[0m | \u001b[0m 0.7098  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 32.23   \u001b[0m | \u001b[0m 0.1087  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.7567  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.9343  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 32.27   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.4209  \u001b[0m | \u001b[0m-0.7174  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.032   \u001b[0m | \u001b[0m 1.458   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 32.25   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05519 \u001b[0m | \u001b[0m-0.3349  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.369   \u001b[0m | \u001b[0m 1.346   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 32.25   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5232  \u001b[0m | \u001b[0m-0.3176  \u001b[0m | \u001b[0m-0.3357  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.808   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 32.31   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m-0.8243  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=25, acq=\"poi\", xi=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSR_Eval(\n",
    "        params,\n",
    "        seed = 96,\n",
    "        iter_df = df\n",
    "    ):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    a, b, c, d, e, f, g, h = params\n",
    "    iter_df = compute_new_of(iter_df, a = a, b = b, c = c, d = d, e = e, f = f, g = g, h = h)\n",
    "    \n",
    "    # Solve is based on 'new_of'\n",
    "    matching = solve_all_dict(iter_df, lambda scan: supply_cost_solve_dict(scan, is_markov = False))\n",
    "    \n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_jobs': 6076,\n",
       " 'match_rate': 0.988,\n",
       " 'overwrite': 0.199,\n",
       " 'average_matched_eta': 539.81,\n",
       " 'p90_matched_eta': 1231.0,\n",
       " 'driver_ar': 0.501,\n",
       " 'rider_cancel': 0.172,\n",
       " 'average_trip_length': 835.6,\n",
       " 'average_matched_fare': 16.13,\n",
       " 'total_gb': 40498,\n",
       " 'global_new_of': -15.718}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = LSR_Eval(\n",
    "        params = [0.4019, -0.9627, -1.3453, 0.6210, -0.6435, -1.1098, 4.1085, 1.3591],\n",
    "        seed = 96,\n",
    "        iter_df = df\n",
    "    )\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_jobs': 6076,\n",
       " 'match_rate': 0.989,\n",
       " 'overwrite': 0.208,\n",
       " 'average_matched_eta': 541.72,\n",
       " 'p90_matched_eta': 1233.0,\n",
       " 'driver_ar': 0.503,\n",
       " 'rider_cancel': 0.172,\n",
       " 'average_trip_length': 835.62,\n",
       " 'average_matched_fare': 16.14,\n",
       " 'total_gb': 40696,\n",
       " 'global_new_of': -15.805}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = LSR_Eval(\n",
    "    params = list(optimizer.max[\"params\"].values()),\n",
    "    seed = 96,\n",
    "    iter_df = df\n",
    "    )\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3444705740718891,\n",
       " -0.886766111974594,\n",
       " -1.1853201082277138,\n",
       " 1.3662973896250004,\n",
       " -1.6049984362797407,\n",
       " -0.25883503674061675,\n",
       " 3.0404645312380407,\n",
       " 1.3040092284736122]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(optimizer.max[\"params\"].values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02. Python 3.6 (General DS)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
