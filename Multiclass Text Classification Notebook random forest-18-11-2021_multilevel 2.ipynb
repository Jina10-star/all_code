{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5c46fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jghosh2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jghosh2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import sklearn.feature_extraction\n",
    "#import itertools, string, operator, re, unicodedata, nltk\n",
    "#from nltk.corpus import wordnet\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "'''Features'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "'''Classifiers'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91ebf164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('Taxml_Integers_Verified_17-11.csv',lineterminator='\\n',header=0,index_col=None,usecols=['item_name','description','establishment_type','cat_name_primary','cat_name_secondary'],dtype={'item_name': str, 'description': str,'establishment_type': str, 'cat_name_primary':str,'cat_name_secondary':str})\n",
    "#df = pd.read_excel('Taxml_Integers_Verified_17-11.xlsx',header=1,usecols=['item_name','description','establishment_type','cat_name_primary','cat_name_secondary'])\n",
    "df = pd.read_csv('taxml_data_17_11.csv', encoding='utf8',engine='python',usecols=['item_name','description','establishment_type','CAT_Name_combined','cat_name_primary','cat_name_secondary','cat_multilevel'])\n",
    "#df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7723f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_stopwords=['grocery']\n",
    "stpwrd = nltk.corpus.stopwords.words('english')\n",
    "#stpwrd.extend(new_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47f025c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stpwrd]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "    final_text=\" \".join([w for w in lemma_words])\n",
    "    return final_text\n",
    "def cat_name_sorted(text):\n",
    "    text=sorted(text.split(','))\n",
    "    text=','.join([x for x in text])\n",
    "    return text\n",
    "def cat_name_without_temp(text):\n",
    "    if ',TEMP_HEATED' in text:\n",
    "        text=re.sub(',TEMP_HEATED','', text)\n",
    "    if ',TEMP_UNHEATED' in text:\n",
    "        text=re.sub(',TEMP_UNHEATED','', text)\n",
    "    if ',TEMP_COLD' in text:\n",
    "        text=re.sub(',TEMP_COLD','', text)\n",
    "    if 'TEMP_HEATED' in text:\n",
    "        text=re.sub('TEMP_HEATED','', text)\n",
    "    if 'TEMP_UNHEATED' in text:\n",
    "        text=re.sub('TEMP_UNHEATED','', text)\n",
    "    if 'TEMP_COLD' in text:\n",
    "        text=re.sub('TEMP_COLD','', text)\n",
    "    else:\n",
    "        pass\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eeef8c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169952, 7)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8aa56fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1=df.sample(n=2000,random_state=42)\n",
    "df1=df.sample(frac=1, random_state=42)\n",
    "#df1['CAT_Name']=df1['CAT_Name'].progress_apply(lambda x: cat_name_sorted(x))\n",
    "#df1['CAT_Name']=df1['CAT_Name'].progress_apply(lambda x: cat_name_without_temp(x))\n",
    "df1=df1.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df1 = df1.dropna(subset=['cat_multilevel'])\n",
    "df1=df1.drop_duplicates(subset=['item_name','description','establishment_type','cat_multilevel'],ignore_index=True,keep=False)\n",
    "df1['input_str'] = df1[['item_name', 'description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "df1['cleanText']=df1['input_str'].map(lambda s:preprocess(s)) \n",
    "df1=df1.drop_duplicates(subset=['cat_multilevel','cleanText'],ignore_index=True,keep='first')\n",
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "97f235e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cat_multilevel_count'] = df1.groupby('cat_multilevel')['cat_multilevel'].transform('count')\n",
    "df2=df1[df1['cat_multilevel_count']<2].reset_index()\n",
    "df3=df1[df1['cat_multilevel_count']>2].reset_index()\n",
    "X=df3[['item_name','description','establishment_type','cleanText','cat_multilevel']]\n",
    "Y=df3['cat_multilevel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4165d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    Y,\n",
    "                                                    test_size = .20, \n",
    "                                                    random_state = 42,\n",
    "                                                    stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2e1192f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final=pd.concat([X_train['cleanText'], df2['cleanText']])\n",
    "y_train_final=pd.concat([y_train, df2['cat_multilevel']])\n",
    "X_train_final=X_train_final.values\n",
    "y_train_final=y_train_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0282fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[]\n",
    "for i in y_train_final:\n",
    "    v=i.split(',')\n",
    "    c.append(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "096a92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=[]\n",
    "for i in y_test:\n",
    "    v=i.split(',')\n",
    "    d.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a27817cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "rf = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', RandomForestClassifier()),\n",
    "              ])\n",
    "\n",
    "n_classes = 2\n",
    "multi_target_forest = MultiOutputClassifier(rf, n_jobs=-1)\n",
    "multi_target_forest.fit(X_train_final, np.array(c))\n",
    "y_pred=multi_target_forest.predict(X_test['cleanText'])\n",
    "#rf.fit(X_train_final, y_train_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bd49477d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681797092483762"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_target_forest.score(X_train_final, np.array(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "667a9bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_series_pred = pd.DataFrame(y_pred,columns=['c', 'a'])\n",
    "new_series_pred['pred']=new_series_pred['c']+','+new_series_pred['a']\n",
    "new_series_test= pd.DataFrame(np.array(d),columns=['c', 'a'])\n",
    "new_series_test['test']=new_series_test['c']+','+new_series_test['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8589976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_series=pd.concat([new_series_pred, new_series_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e458296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_series.to_csv('res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "391fb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_series\n",
    "misclassifications = new_series.loc[new_series['test']!=new_series['pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9c2dbe06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6411, 6)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassifications.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4494e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications.to_csv('mis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2c4244f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7521073389529038\n",
      "0.1303058013315739\n",
      "0.17027339787807286\n",
      "0.14353636961732968\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(new_series['pred'],new_series['test']))\n",
    "print(precision_score(new_series['pred'],new_series['test'],average='macro'))\n",
    "print(recall_score(new_series['pred'],new_series['test'],average='macro'))\n",
    "print(f1_score(new_series['pred'],new_series['test'],average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d43134df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.77971149011873\n",
      "0.605444931270198\n",
      "0.7025870291816179\n",
      "0.6316093970912848\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test['cleanText'])\n",
    "print(f'accuracy {accuracy_score(y_pred,y_test)}')\n",
    "print(precision_score(y_pred,y_test,average='macro'))\n",
    "print(recall_score(y_pred,y_test,average='macro'))\n",
    "print(f1_score(y_pred,y_test,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf36283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5696, 6)\n",
      "(25857, 6)\n"
     ]
    }
   ],
   "source": [
    "result=pd.DataFrame()\n",
    "result=X_test\n",
    "result['original_cat']=y_test\n",
    "result['pred']=y_pred\n",
    "misclassifications = result.loc[result['original_cat']!=result['pred']]\n",
    "print(misclassifications.shape)\n",
    "print(result.shape)\n",
    "misclassifications.to_excel('misclassifications_sample.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bc7fd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.ExcelWriter('misclassifications_sample.xlsx') as writer:  \n",
    "    for i,label in enumerate(misclassifications['original_cat']):\n",
    "        df = misclassifications.loc[misclassifications['original_cat'] == label]\n",
    "        df.to_excel(writer, sheet_name='{}'.format(label[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9123a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(rf, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5bcd1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, x_val, y_train, y_val = train_test_split(df3['input_str'],\n",
    "                                                    df3['CAT_Name'],\n",
    "                                                    test_size = .4, \n",
    "                                                    random_state = 42,\n",
    "                                                    stratify=df3['CAT_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b2a533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8273388250763817\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af6593",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('misclassifications_check.xlsx') as writer:  \n",
    "    for i,label in enumerate(misclassifications):\n",
    "        df = misclassifications.loc[result['CAT_Name'] == label]\n",
    "        df.to_excel(writer, sheet_name='Sheet_name_{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "168520bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cleanText\n",
      "1 original_cat\n",
      "2 pred\n"
     ]
    }
   ],
   "source": [
    " for i,label in enumerate(misclassifications):\n",
    "        print(i,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f3dd6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanText</th>\n",
       "      <th>original_cat</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56934</th>\n",
       "      <td>celsius pear</td>\n",
       "      <td>CAT_ENERGY_DRINK,CONTAINER_BOTTLED</td>\n",
       "      <td>CAT_JUICE_NON_CARBONATED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>real kidney bean</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_SHELF_STABLE_POTATOES</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117757</th>\n",
       "      <td>david jumbo dill pickle sunflower seed</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_SNACK_NUTS</td>\n",
       "      <td>CAT_SEEDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41013</th>\n",
       "      <td>coca cola zero liter</td>\n",
       "      <td>CAT_ALCOHOL</td>\n",
       "      <td>CAT_SOFT_DRINK,CONTAINER_BOTTLED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55272</th>\n",
       "      <td>mdh meat masala mdh meat masala</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_SEASONING</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87673</th>\n",
       "      <td>devacurl leave miracle curl plumper devacurl b...</td>\n",
       "      <td>CAT_TPP_SHAMPOOS</td>\n",
       "      <td>CAT_TPP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>julio blanco liquor bottle abv</td>\n",
       "      <td>CAT_ALCOHOL</td>\n",
       "      <td>CAT_LIQUOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95590</th>\n",
       "      <td>planet oregon fiz sparkling rose flower</td>\n",
       "      <td>CAT_SPARKLING_WINE</td>\n",
       "      <td>CAT_TPP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49560</th>\n",
       "      <td>patchology perfect ten</td>\n",
       "      <td>CAT_TPP_BODY_LOTION</td>\n",
       "      <td>CAT_TPP_SKIN_CARE_PRODUCTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63689</th>\n",
       "      <td>roll</td>\n",
       "      <td>CAT_BAKERY_ITEM</td>\n",
       "      <td>CAT_PREPARED_FOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5716 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                cleanText  \\\n",
       "56934                                        celsius pear   \n",
       "7532                                     real kidney bean   \n",
       "117757             david jumbo dill pickle sunflower seed   \n",
       "41013                                coca cola zero liter   \n",
       "55272                     mdh meat masala mdh meat masala   \n",
       "...                                                   ...   \n",
       "87673   devacurl leave miracle curl plumper devacurl b...   \n",
       "3977                       julio blanco liquor bottle abv   \n",
       "95590             planet oregon fiz sparkling rose flower   \n",
       "49560                              patchology perfect ten   \n",
       "63689                                                roll   \n",
       "\n",
       "                                      original_cat  \\\n",
       "56934           CAT_ENERGY_DRINK,CONTAINER_BOTTLED   \n",
       "7532    CAT_PREPACKAGED_FOOD_SHELF_STABLE_POTATOES   \n",
       "117757             CAT_PREPACKAGED_FOOD_SNACK_NUTS   \n",
       "41013                                  CAT_ALCOHOL   \n",
       "55272               CAT_PREPACKAGED_FOOD_SEASONING   \n",
       "...                                            ...   \n",
       "87673                             CAT_TPP_SHAMPOOS   \n",
       "3977                                   CAT_ALCOHOL   \n",
       "95590                           CAT_SPARKLING_WINE   \n",
       "49560                          CAT_TPP_BODY_LOTION   \n",
       "63689                              CAT_BAKERY_ITEM   \n",
       "\n",
       "                                    pred  \n",
       "56934           CAT_JUICE_NON_CARBONATED  \n",
       "7532                CAT_PREPACKAGED_FOOD  \n",
       "117757                         CAT_SEEDS  \n",
       "41013   CAT_SOFT_DRINK,CONTAINER_BOTTLED  \n",
       "55272               CAT_PREPACKAGED_FOOD  \n",
       "...                                  ...  \n",
       "87673                            CAT_TPP  \n",
       "3977                          CAT_LIQUOR  \n",
       "95590                            CAT_TPP  \n",
       "49560         CAT_TPP_SKIN_CARE_PRODUCTS  \n",
       "63689                  CAT_PREPARED_FOOD  \n",
       "\n",
       "[5716 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f4880230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dict = {'Random Forest': Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('rf', RandomForestClassifier()),\n",
    "              ]),\n",
    "             \n",
    "             'naive bayas': Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ]),\n",
    "              'logistic': Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('lg', LogisticRegression()),\n",
    "              ])\n",
    "             }\n",
    "            \n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in tqdm(model_dict.items()):   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train_final, y_train_final)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a46fa145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426eb277f816427e81d812376da13439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-c3a12fa8024a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_score_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-123-386b86827f34>\u001b[0m in \u001b[0;36mmodel_score_df\u001b[0;34m(model_dict)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mac_score_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(model_score_df(model_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b0014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a462b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################redundent code###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f0687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features (tf-idf weights) for the processed text\n",
    "\n",
    "#texts = df1['input_str'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),max_df = .95)\n",
    "LE = LabelEncoder()\n",
    "#tfidf\n",
    "tfv = TfidfVectorizer(strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',ngram_range=(1,2), use_idf=1,smooth_idf=1,sublinear_tf=1,max_df = .95,stop_words = 'english')\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train) #features\n",
    "X_test_tfidf= tfidf_vectorizer.fit_transform(X_test) #features\n",
    "\n",
    "tfv.fit(list(X_train) + list(X_test))\n",
    "xtrain_tfv =  tfv.transform(X_train) \n",
    "xvalid_tfv = tfv.transform(X_test)\n",
    "\n",
    "#countvec\n",
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "X_train_ctv = ctv.fit_transform(X_train) #features\n",
    "X_test_ctv= ctv.fit_transform(X_test) #features\n",
    "\n",
    "\n",
    "\n",
    "y_train_final=LE.fit_transform(y_train)\n",
    "y_test_final=LE.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341fc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X_train_final = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_final = lsa.fit_transform(X_test_tfidf)\n",
    "\n",
    "X_train_final_ctv= lsa.fit_transform(X_train_ctv)\n",
    "X_test_final_ctv= lsa.fit_transform(X_test_ctv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "randomforestmodel=RandomForestClassifier(random_state=3)\n",
    "#tfidf\n",
    "#randomforestmodel.fit(xtrain_tfv, y_train_final)\n",
    "#y_pred = randomforestmodel.predict(xvalid_tfv)\n",
    "#countvec\n",
    "#randomforestmodel.fit(X_train_final_ctv, y_train_final)\n",
    "#y_pred = randomforestmodel.predict(X_test_final_ctv)\n",
    "#svd\n",
    "randomforestmodel.fit(X_train_final, y_train_final)\n",
    "y_pred = randomforestmodel.predict(X_test_final)\n",
    "\n",
    "ac_score_list.append(accuracy_score(y_test_final, y_pred))\n",
    "p_score_list.append(precision_score(y_test_final, y_pred, average='macro'))\n",
    "r_score_list.append(recall_score(y_test_final, y_pred, average='macro'))\n",
    "f1_score_list.append(f1_score(y_test_final, y_pred, average='macro'))\n",
    "model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e053b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Preliminary model evaluation using default parameters\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Creating a dict of the models\n",
    "model_dict = {'Random Forest': RandomForestClassifier(random_state=3)}\n",
    "            \n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in tqdm(model_dict.items()):   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train_final, y_train_final)\n",
    "        y_pred = v.predict(X_test_final)\n",
    "        ac_score_list.append(accuracy_score(y_test_final, y_pred))\n",
    "        p_score_list.append(precision_score(y_test_final, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test_final, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test_final, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df,v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698eaacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict=model_score_df(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6255123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15b26c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56f703ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 27.282s\n",
      "Best score: 0.592\n",
      "Best parameters set:\n",
      "\tclf__bootstrap: True\n",
      "\tclf__max_depth: 100\n",
      "\tclf__max_features: 'sqrt'\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__min_samples_split: 2\n",
      "\tclf__n_estimators: 400\n",
      "\tclf__random_state: 3\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#clf = RandomForestClassifier()\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "rf=Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', RandomForestClassifier()),\n",
    "              ])\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigramslf__\n",
    "     \"clf__bootstrap\":[True, False],\n",
    "     \"clf__max_depth\":[10, 50, 100,500, None],\n",
    "     \"clf__max_features\":['auto', 'sqrt'],\n",
    "     \"clf__min_samples_leaf\":[1,2,4],\n",
    "     \"clf__min_samples_split\":[2,5,10],\n",
    "     \"clf__n_estimators\":[400,600,800],\n",
    "     \"clf__random_state\":[3]\n",
    "\n",
    "}\n",
    "\n",
    "RandomizedSearch = RandomizedSearchCV(rf,\n",
    "                          parameters, \n",
    "                          cv=5,\n",
    "                          verbose=1, \n",
    "                          n_jobs=-1)\n",
    "\n",
    "t0 = time()\n",
    "rf_best_model = RandomizedSearch.fit(X_train_final, y_train_final)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "#print()\n",
    "print(\"Best score: %0.3f\" % rf_best_model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = rf_best_model.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75fb718c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                             ('tfidf', TfidfTransformer()),\n",
       "                                             ('clf',\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'clf__bootstrap': [True, False],\n",
       "                                        'clf__max_depth': [10, 50, 100, None],\n",
       "                                        'clf__max_features': ['auto', 'sqrt'],\n",
       "                                        'clf__min_samples_leaf': [1, 2, 4],\n",
       "                                        'clf__min_samples_split': [2, 5, 10],\n",
       "                                        'clf__n_estimators': [800, 1400, 2000],\n",
       "                                        'clf__random_state': [3],\n",
       "                                        'vect__max_df': (0.5, 0.75, 1.0),\n",
       "                                        'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7413f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_model = RandomForestClassifier(bootstrap = False,\n",
    "                                       max_depth = 50,\n",
    "                                       max_features = 'auto',\n",
    "                                       min_samples_leaf = 1,\n",
    "                                       n_estimators = 1400,\n",
    "                                       random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], []\n",
    "rf_best_model.fit(X_train, y_train)\n",
    "y_pred = rf_best_model.predict(X_test)\n",
    "ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "model_comparison_df = pd.DataFrame([ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "model_comparison_df.columns = ['accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7509dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee69e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e74678",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './output/finalized_model.sav'\n",
    "joblib.dump(model, filename)\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
