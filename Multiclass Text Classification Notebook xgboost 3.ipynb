{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5c46fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jghosh2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jghosh2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import sklearn.feature_extraction\n",
    "import itertools, string, operator, re, unicodedata, nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "'''Features'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.preprocessing import label_binarize\n",
    "'''Classifiers'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ebf164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Taxml_Integers_Verified.csv', index_col=None, header=0,dtype={'item_name': str, 'description': str,'establishment_type': str, 'CAT_Name':str},usecols=['item_name','description','establishment_type','CAT_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f025c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=WordNetLemmatizer()\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    #print(tag,word)\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "def clean_text(text):\n",
    "\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ' '.join(word for word in list(set(text.split())) if word not in STOPWORDS)# remove stopwors from text\n",
    "    #text =  \" \".join([le.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text) if w not in string.punctuation])\n",
    "    text =  \" \".join([le.lemmatize(w) for w in nltk.word_tokenize(text) if w not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "def cat_name_sorted(text):\n",
    "    text=sorted(text.split(','))\n",
    "    text=','.join([x for x in text])\n",
    "    return text\n",
    "def cat_name_without_temp(text):\n",
    "    if ',TEMP_HEATED' in text:\n",
    "        text=re.sub(',TEMP_HEATED','', text)\n",
    "    if ',TEMP_UNHEATED' in text:\n",
    "        text=re.sub(',TEMP_UNHEATED','', text)\n",
    "    if ',TEMP_COLD' in text:\n",
    "        text=re.sub(',TEMP_COLD','', text)\n",
    "    if 'TEMP_HEATED' in text:\n",
    "        text=re.sub('TEMP_HEATED','', text)\n",
    "    if 'TEMP_UNHEATED' in text:\n",
    "        text=re.sub('TEMP_UNHEATED','', text)\n",
    "    if 'TEMP_COLD' in text:\n",
    "        text=re.sub('TEMP_COLD','', text)\n",
    "    else:\n",
    "        pass\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeef8c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175570, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa56fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2323923947bb4e5ba775ee563d0540ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ea5161cebd4efcaa1a836e555a6544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = list(set(stopwords.words('english')))\n",
    "STOPWORDS.append('n')\n",
    "STOPWORDS.append('grocery')\n",
    "#df1=df.sample(n=2000,random_state=42)\n",
    "df1=df.sample(frac=1, random_state=42)\n",
    "df1['CAT_Name']=df1['CAT_Name'].progress_apply(lambda x: cat_name_sorted(x))\n",
    "df1['CAT_Name']=df1['CAT_Name'].progress_apply(lambda x: cat_name_without_temp(x))\n",
    "df1=df1.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df1 = df1.dropna(subset=['CAT_Name'])\n",
    "df1=df1.drop_duplicates(subset=['item_name','description','establishment_type','CAT_Name'],ignore_index=True,keep=False)\n",
    "df1=df1.drop_duplicates(subset=['item_name','description','establishment_type'],ignore_index=True,keep=False)\n",
    "df1['input_str'] = df1[['item_name', 'description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "df1['input_str'] = df1['input_str'].apply(clean_text)\n",
    "df1['input_str'] = df1['input_str'].str.replace('\\d+', '')\n",
    "df1=df1.drop_duplicates(subset=['CAT_Name','input_str'],ignore_index=True,keep='first')\n",
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f11fcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151456, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7482774c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>description</th>\n",
       "      <th>establishment_type</th>\n",
       "      <th>CAT_Name</th>\n",
       "      <th>input_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iles Formula Spa Pack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_TPP</td>\n",
       "      <td>iles formula spa pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StoliÂ® Gluten Free Vodka.750ml Bottle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_LIQUOR</td>\n",
       "      <td>gluten stoli bottle vodkaml free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian Standard Gold (1L), (1L) Wine &amp; Bubbly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_SPARKLING_WINE</td>\n",
       "      <td>standard bubbly l  russian abv gold wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bell's Two Hearted Ale IPA, 12pk-12oz can beer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_BEER</td>\n",
       "      <td>beer bell pkoz ale abv two hearted ipa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barbancourt 8yr Rhum</td>\n",
       "      <td>\\N</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_LIQUOR</td>\n",
       "      <td>yr barbancourt rhum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151451</th>\n",
       "      <td>Donjulio 1942 Anejo, 750 ml tequila (40% ABV)</td>\n",
       "      <td>\\N</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_LIQUOR</td>\n",
       "      <td>ml  tequila  anejo abv donjulio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151452</th>\n",
       "      <td>Mishka Beef Cake Bubble</td>\n",
       "      <td>Our classic Mishka cakes fit in the palm of yo...</td>\n",
       "      <td>PET</td>\n",
       "      <td>CAT_PET_FOOD</td>\n",
       "      <td>bubble mishka shape signature hand palm cake c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151453</th>\n",
       "      <td>Oberto Beef Jerky</td>\n",
       "      <td>3.25 oz Original</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_PREPARED_FOOD</td>\n",
       "      <td>oberto jerky original  beef oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151454</th>\n",
       "      <td>Rastafri Malibu Afro Kinky Braid Hair - 14 in</td>\n",
       "      <td>\\N</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_TPP</td>\n",
       "      <td>braid rastafri hair kinky  malibu afro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151455</th>\n",
       "      <td>Organic Teriyaki Soy-Free Sauce</td>\n",
       "      <td>This delicious Kobe-inspired teriyaki sauce is...</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_CONDIMENTS</td>\n",
       "      <td>certified sweet great pineapple usda barbeque ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151456 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                item_name  \\\n",
       "0                                   Iles Formula Spa Pack   \n",
       "1                   StoliÂ® Gluten Free Vodka.750ml Bottle   \n",
       "2       Russian Standard Gold (1L), (1L) Wine & Bubbly...   \n",
       "3       Bell's Two Hearted Ale IPA, 12pk-12oz can beer...   \n",
       "4                                    Barbancourt 8yr Rhum   \n",
       "...                                                   ...   \n",
       "151451      Donjulio 1942 Anejo, 750 ml tequila (40% ABV)   \n",
       "151452                            Mishka Beef Cake Bubble   \n",
       "151453                                  Oberto Beef Jerky   \n",
       "151454      Rastafri Malibu Afro Kinky Braid Hair - 14 in   \n",
       "151455                    Organic Teriyaki Soy-Free Sauce   \n",
       "\n",
       "                                              description establishment_type  \\\n",
       "0                                                     NaN            GROCERY   \n",
       "1                                                     NaN            GROCERY   \n",
       "2                                                     NaN            GROCERY   \n",
       "3                                                     NaN            GROCERY   \n",
       "4                                                      \\N            GROCERY   \n",
       "...                                                   ...                ...   \n",
       "151451                                                 \\N            GROCERY   \n",
       "151452  Our classic Mishka cakes fit in the palm of yo...                PET   \n",
       "151453                                   3.25 oz Original            GROCERY   \n",
       "151454                                                 \\N            GROCERY   \n",
       "151455  This delicious Kobe-inspired teriyaki sauce is...            GROCERY   \n",
       "\n",
       "                               CAT_Name  \\\n",
       "0                               CAT_TPP   \n",
       "1                            CAT_LIQUOR   \n",
       "2                    CAT_SPARKLING_WINE   \n",
       "3                              CAT_BEER   \n",
       "4                            CAT_LIQUOR   \n",
       "...                                 ...   \n",
       "151451                       CAT_LIQUOR   \n",
       "151452                     CAT_PET_FOOD   \n",
       "151453                CAT_PREPARED_FOOD   \n",
       "151454                          CAT_TPP   \n",
       "151455  CAT_PREPACKAGED_FOOD_CONDIMENTS   \n",
       "\n",
       "                                                input_str  \n",
       "0                                   iles formula spa pack  \n",
       "1                        gluten stoli bottle vodkaml free  \n",
       "2                standard bubbly l  russian abv gold wine  \n",
       "3                  beer bell pkoz ale abv two hearted ipa  \n",
       "4                                     yr barbancourt rhum  \n",
       "...                                                   ...  \n",
       "151451                   ml  tequila  anejo abv donjulio   \n",
       "151452  bubble mishka shape signature hand palm cake c...  \n",
       "151453                     oberto jerky original  beef oz  \n",
       "151454             braid rastafri hair kinky  malibu afro  \n",
       "151455  certified sweet great pineapple usda barbeque ...  \n",
       "\n",
       "[151456 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e622afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('final_df11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e750cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cat_count'] = df1.groupby('CAT_Name')['CAT_Name'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37056837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1[df1['cat_count']==1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "877ea5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df1[df1['cat_count']>1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4165d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(df3['input_str'],\n",
    "                                                    df3['CAT_Name'],\n",
    "                                                    test_size = .20, \n",
    "                                                    random_state = 42,\n",
    "                                                    stratify=df3['CAT_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2956c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6269ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final=pd.concat([X_train, df2['input_str']])\n",
    "y_train_final=pd.concat([y_train, df2['CAT_Name']])\n",
    "X_train_final=X_train_final.values\n",
    "y_train_final=y_train_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27817cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy 0.7086827335754374\n",
      "0.5305261851321219\n",
      "0.5954867163176474\n",
      "0.5486279692306606\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "xgb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', XGBClassifier()),\n",
    "              ])\n",
    "xgb.fit(X_train_final, y_train_final)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print(f'accuracy {accuracy_score(y_pred,y_test)}')\n",
    "print(precision_score(y_pred,y_test,average='macro'))\n",
    "print(recall_score(y_pred,y_test,average='macro'))\n",
    "print(f1_score(y_pred,y_test,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cff3b787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046686002226973\n",
      "0.704864008931533\n",
      "0.6341608455538031\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d7bf519c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5533, 3)\n",
      "(30165, 3)\n"
     ]
    }
   ],
   "source": [
    "result=pd.DataFrame()\n",
    "result['input_str']=X_test\n",
    "result['original_cat']=y_test\n",
    "result['pred']=y_pred\n",
    "misclassifications = result.loc[result['original_cat']!=result['pred']]\n",
    "print(misclassifications.shape)\n",
    "print(result.shape)\n",
    "misclassifications.to_csv('misclassifications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5e283790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(rf, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2e2a948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8996353389690038\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1a52064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, x_val, y_train, y_val = train_test_split(df3['input_str'],\n",
    "                                                    df3['CAT_Name'],\n",
    "                                                    test_size = .4, \n",
    "                                                    random_state = 42,\n",
    "                                                    stratify=df3['CAT_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f4880230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dict = {'Random Forest': Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('rf', RandomForestClassifier()),\n",
    "              ]),\n",
    "             \n",
    "             'naive bayas': Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ]),\n",
    "              'logistic': Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('lg', LogisticRegression()),\n",
    "              ])\n",
    "             }\n",
    "            \n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in tqdm(model_dict.items()):   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train_final, y_train_final)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a46fa145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426eb277f816427e81d812376da13439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-c3a12fa8024a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_score_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-123-386b86827f34>\u001b[0m in \u001b[0;36mmodel_score_df\u001b[0;34m(model_dict)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mac_score_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(model_score_df(model_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b0014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a462b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f0687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features (tf-idf weights) for the processed text\n",
    "\n",
    "#texts = df1['input_str'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),max_df = .95)\n",
    "LE = LabelEncoder()\n",
    "#tfidf\n",
    "tfv = TfidfVectorizer(strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',ngram_range=(1,2), use_idf=1,smooth_idf=1,sublinear_tf=1,max_df = .95,stop_words = 'english')\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train) #features\n",
    "X_test_tfidf= tfidf_vectorizer.fit_transform(X_test) #features\n",
    "\n",
    "tfv.fit(list(X_train) + list(X_test))\n",
    "xtrain_tfv =  tfv.transform(X_train) \n",
    "xvalid_tfv = tfv.transform(X_test)\n",
    "\n",
    "#countvec\n",
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "X_train_ctv = ctv.fit_transform(X_train) #features\n",
    "X_test_ctv= ctv.fit_transform(X_test) #features\n",
    "\n",
    "\n",
    "\n",
    "y_train_final=LE.fit_transform(y_train)\n",
    "y_test_final=LE.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341fc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X_train_final = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_final = lsa.fit_transform(X_test_tfidf)\n",
    "\n",
    "X_train_final_ctv= lsa.fit_transform(X_train_ctv)\n",
    "X_test_final_ctv= lsa.fit_transform(X_test_ctv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "randomforestmodel=RandomForestClassifier(random_state=3)\n",
    "#tfidf\n",
    "#randomforestmodel.fit(xtrain_tfv, y_train_final)\n",
    "#y_pred = randomforestmodel.predict(xvalid_tfv)\n",
    "#countvec\n",
    "#randomforestmodel.fit(X_train_final_ctv, y_train_final)\n",
    "#y_pred = randomforestmodel.predict(X_test_final_ctv)\n",
    "#svd\n",
    "randomforestmodel.fit(X_train_final, y_train_final)\n",
    "y_pred = randomforestmodel.predict(X_test_final)\n",
    "\n",
    "ac_score_list.append(accuracy_score(y_test_final, y_pred))\n",
    "p_score_list.append(precision_score(y_test_final, y_pred, average='macro'))\n",
    "r_score_list.append(recall_score(y_test_final, y_pred, average='macro'))\n",
    "f1_score_list.append(f1_score(y_test_final, y_pred, average='macro'))\n",
    "model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e053b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Preliminary model evaluation using default parameters\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Creating a dict of the models\n",
    "model_dict = {'Random Forest': RandomForestClassifier(random_state=3)}\n",
    "            \n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in tqdm(model_dict.items()):   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train_final, y_train_final)\n",
    "        y_pred = v.predict(X_test_final)\n",
    "        ac_score_list.append(accuracy_score(y_test_final, y_pred))\n",
    "        p_score_list.append(precision_score(y_test_final, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test_final, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test_final, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df,v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698eaacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict=model_score_df(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6255123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15b26c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56f703ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 27.282s\n",
      "Best score: 0.592\n",
      "Best parameters set:\n",
      "\tclf__bootstrap: True\n",
      "\tclf__max_depth: 100\n",
      "\tclf__max_features: 'sqrt'\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__min_samples_split: 2\n",
      "\tclf__n_estimators: 400\n",
      "\tclf__random_state: 3\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#clf = RandomForestClassifier()\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "rf=Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', RandomForestClassifier()),\n",
    "              ])\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigramslf__\n",
    "     \"clf__bootstrap\":[True, False],\n",
    "     \"clf__max_depth\":[10, 50, 100,500, None],\n",
    "     \"clf__max_features\":['auto', 'sqrt'],\n",
    "     \"clf__min_samples_leaf\":[1,2,4],\n",
    "     \"clf__min_samples_split\":[2,5,10],\n",
    "     \"clf__n_estimators\":[400,600,800],\n",
    "     \"clf__random_state\":[3]\n",
    "\n",
    "}\n",
    "\n",
    "RandomizedSearch = RandomizedSearchCV(rf,\n",
    "                          parameters, \n",
    "                          cv=5,\n",
    "                          verbose=1, \n",
    "                          n_jobs=-1)\n",
    "\n",
    "t0 = time()\n",
    "rf_best_model = RandomizedSearch.fit(X_train_final, y_train_final)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "#print()\n",
    "print(\"Best score: %0.3f\" % rf_best_model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = rf_best_model.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75fb718c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                             ('tfidf', TfidfTransformer()),\n",
       "                                             ('clf',\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'clf__bootstrap': [True, False],\n",
       "                                        'clf__max_depth': [10, 50, 100, None],\n",
       "                                        'clf__max_features': ['auto', 'sqrt'],\n",
       "                                        'clf__min_samples_leaf': [1, 2, 4],\n",
       "                                        'clf__min_samples_split': [2, 5, 10],\n",
       "                                        'clf__n_estimators': [800, 1400, 2000],\n",
       "                                        'clf__random_state': [3],\n",
       "                                        'vect__max_df': (0.5, 0.75, 1.0),\n",
       "                                        'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7413f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_model = RandomForestClassifier(bootstrap = False,\n",
    "                                       max_depth = 50,\n",
    "                                       max_features = 'auto',\n",
    "                                       min_samples_leaf = 1,\n",
    "                                       n_estimators = 1400,\n",
    "                                       random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], []\n",
    "rf_best_model.fit(X_train, y_train)\n",
    "y_pred = rf_best_model.predict(X_test)\n",
    "ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "model_comparison_df = pd.DataFrame([ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "model_comparison_df.columns = ['accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7509dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee69e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e74678",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './output/finalized_model.sav'\n",
    "joblib.dump(model, filename)\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
