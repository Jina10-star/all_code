{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from queryrunner_client import Client as QRClient\n",
    "#from batch_utils.batch_querier import BatchQuerier\n",
    "from mdstk.data_fetcher.data_fetcher import DataFetcher\n",
    "from mdstk.data_fetcher.cached_data_fetcher import CachedDataFetcher\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "#from queryrunner_client import Client\n",
    "#qclient = Client(user_email='mehrdad@uber.com')\n",
    "\n",
    "import os\n",
    "import pulp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "#num_cores = multiprocessing.cpu_count()\n",
    "n_cores = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_EMAIL = 'mehrdadb@uber.com'\n",
    "CONSUMER_NAME = 'intelligentdispatch'\n",
    "\n",
    "QUERY = \"\"\"\n",
    "with dispatch as (\n",
    "    select \n",
    "        datestr,\n",
    "        msg.cityid,\n",
    "        msg.ctplangenrequestuuid as plangen_uuid,\n",
    "        msg.ctrequestuuid as scan_uuid,\n",
    "        msg.jobuuid[1] as job_uuid,\n",
    "        msg.supplyuuid,\n",
    "        msg.planactiontype\n",
    "    from rawdata_user.kafka_hp_multileg_dispatched_plan_nodedup\n",
    "    where datestr = '{datestr}'\n",
    "    and msg.cityid = {city_id}\n",
    "    and msg.vehicleviewid in {vvid} \n",
    "    and msg.tenancy = 'uber/production'\n",
    "    and CARDINALITY(msg.jobuuid) > 0\n",
    "    and substr(msg.ctrequestuuid, 1, length('{digits}')) = '{digits}'\n",
    "),\n",
    "plangen as (\n",
    "    select \n",
    "        msg.jobs[1].uuid as job_uuid,\n",
    "        msg.supplyuuid,\n",
    "        msg.scanuuid as plangen_uuid,\n",
    "        msg.waypoints[1].latitude as pickup_latitude\n",
    "    from rawdata_user.kafka_hp_plangenerator_matching_plans_log_nodedup\n",
    "    where datestr = '{datestr}'\n",
    "    and msg.cityid = {city_id}\n",
    "    and msg.tenancy = 'uber/production'\n",
    "    and CARDINALITY(msg.jobs) > 0\n",
    "    and msg.planstatus = 'eligible'\n",
    "),\n",
    "mgv as (\n",
    "    select datestr,\n",
    "           msg.city_id,\n",
    "           msg.job_uuid,\n",
    "           msg.client_uuid,\n",
    "           msg.ct_request_uuid as plangen_uuid,\n",
    "           msg.supply_uuid,\n",
    "           msg.supply_plan_uuid as plan_uuid,\n",
    "           msg.unadjusted_eta as eta,\n",
    "           msg.fd_eta,\n",
    "           msg.adjustedeta,\n",
    "           msg.ranking_metric,\n",
    "           round(1 - msg.solo_cancel_model_driver_accept_prob, 4) as d_proba,\n",
    "           round(1 - msg.solo_cancel_model_rider_accept_prob, 4) as r_proba,\n",
    "           round(1 - msg.spinner_survive_prob_before_next_scan, 4) as s_proba,\n",
    "           msg.preferred_destination_adjustment,\n",
    "           msg.objective_value as of_value,\n",
    "           msg.inconvenience_etd - msg.ranking_metric as trip_length,\n",
    "           msg.pickup_latitude as pickup_latitude,\n",
    "           msg.pickup_longitude as pickup_longitude,\n",
    "           msg.supply_latitude as supply_latitude,\n",
    "           msg.supply_longitude as supply_longitude\n",
    "    from   rawdata.kafka_hp_multileg_mgv_log_nodedup\n",
    "    where  datestr = '{datestr}'\n",
    "    and    msg.city_id = {city_id}\n",
    "    and    msg.tenancy = 'uber/production'\n",
    "    and    msg.vehicle_view_id in {vvid} \n",
    "    and    msg.flow_type = 'solo_batch'\n",
    "    and    msg.job_uuid <> msg.client_uuid\n",
    "),\n",
    "test as (\n",
    "    select \n",
    "        mgv.datestr,\n",
    "        mgv.city_id,\n",
    "        plangen.pickup_latitude as plangen_pickup_lat,\n",
    "        dispatch.scan_uuid,\n",
    "        mgv.plangen_uuid,\n",
    "        mgv.job_uuid,\n",
    "        dispatch.planactiontype,\n",
    "        mgv.supply_uuid,\n",
    "        case when dispatch.supplyuuid = mgv.supply_uuid then 1 else 0 end as is_selected,\n",
    "        mgv.eta,\n",
    "        mgv.adjustedeta,\n",
    "        mgv.fd_eta,\n",
    "        mgv.ranking_metric,\n",
    "        mgv.d_proba,\n",
    "        mgv.r_proba,\n",
    "        mgv.s_proba,\n",
    "        mgv.preferred_destination_adjustment,\n",
    "        mgv.of_value,\n",
    "        mgv.trip_length,\n",
    "        ftf.est_rider_quoted_final_fare as upfront_fare,\n",
    "        ftf.est_rider_rsp_multiplier,\n",
    "        ft.surge_multiplier,\n",
    "        case when fst.trip_uuid is null then 0 else 1 end as is_scheduled_trip,\n",
    "        fst.upfront_fare as fst_upfront_fare,\n",
    "        fst.reservation_variant,\n",
    "        mgv.pickup_latitude as mgv_pickup_lat,\n",
    "        mgv.pickup_longitude as mgv_pickup_lng,\n",
    "        mgv.supply_latitude as mgv_supply_lat,\n",
    "        mgv.supply_longitude as mgv_supply_lng\n",
    "    from mgv\n",
    "    join plangen\n",
    "    on mgv.plangen_uuid = plangen.plangen_uuid\n",
    "    and mgv.job_uuid = plangen.job_uuid\n",
    "    and mgv.supply_uuid = plangen.supplyuuid\n",
    "    join dispatch\n",
    "    on mgv.plangen_uuid = dispatch.plangen_uuid\n",
    "    and mgv.job_uuid = dispatch.job_uuid\n",
    "    join dwh.fact_trip_fare ftf\n",
    "    on mgv.job_uuid = ftf.trip_uuid\n",
    "    and ftf.datestr = mgv.datestr\n",
    "    and ftf.datestr = '{datestr}'\n",
    "    join dwh.fact_trip ft\n",
    "    on mgv.job_uuid = ft.uuid\n",
    "    and mgv.datestr = ft.datestr\n",
    "    and ft.datestr = '{datestr}'\n",
    "    left join rider.fact_scheduled_trip fst\n",
    "    on mgv.job_uuid = fst.trip_uuid\n",
    "    and mgv.datestr = fst.datestr\n",
    "    and fst.datestr = '{datestr}'\n",
    ")\n",
    "select * from test\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class Query:\n",
    "    prefix: str\n",
    "    hex_digits: str\n",
    "    city_id: int\n",
    "    vvid: str\n",
    "    datestr: str\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.name = f'{self.prefix}_city{self.city_id}_{self.vvid}_{self.datestr}_segment{self.hex_digits}'\n",
    "        self.qry = QUERY.format(city_id=self.city_id, vvid=self.vvid, digits=self.hex_digits, datestr=self.datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for VVIDs: https://querybuilder-ea.uberinternal.com/r/rEQz18SJz/run/DoTpgoE81/edit\n",
    "prefix = 'replay'\n",
    "hex_digits = '35'\n",
    "\n",
    "# 6, 1, 21, 15, 26,\n",
    "#    235, 35, 93, 50, 30\n",
    "\n",
    "city_name = {\n",
    "    1: 'SF',\n",
    "    3: 'Paris',\n",
    "    12: 'LA',\n",
    "    52: 'Lisbon',\n",
    "    458: 'Sao Paulo',\n",
    "    90: 'Mexico City',\n",
    "    146: 'Bogota',\n",
    "    803: 'Goiania',\n",
    "    218: 'Tijuana',\n",
    "    1379: 'Cabro Frio',\n",
    "    799: 'Recife',\n",
    "}\n",
    "\n",
    "city_id_vvids = {\n",
    "    1: '(8)', #SF\n",
    "#     3: '(235)', # Paris\n",
    "#     6: '(116)',\n",
    "    12: '(125)', # Los Angeles\n",
    "#     21: '(184)',\n",
    "#     15: '(1783)',\n",
    "#     26: '(347)',\n",
    "#     235: '(685)',\n",
    "#     35: '(442)',\n",
    "#     93: '(353)',\n",
    "#     50: '(425)',\n",
    "#     52: '(120)', # Lisbon\n",
    "#     30: '(350)',\n",
    "#     458: '(3825)', # Sao Paulo\n",
    "#     493: '(5433)', # Belo Horizonte\n",
    "#     90: '(651)',\n",
    "#     146: '(1934)',\n",
    "#     803: '(10369)',\n",
    "#     218: '(837)',\n",
    "#     1379: '(10002430)',\n",
    "#     799: '(11047)',\n",
    "\n",
    "}\n",
    "datestrs = [  # 1 week\n",
    "#     '2021-09-21',\n",
    "#     '2021-09-22',\n",
    "#     '2021-09-23',\n",
    "#     '2021-09-24',\n",
    "#     '2021-09-25',\n",
    "#     '2021-09-26',\n",
    "    '2021-09-27',    \n",
    "]\n",
    "\n",
    "queries = [\n",
    "    Query(prefix=prefix, hex_digits=hex_digits, city_id=city_id, vvid=vvid, datestr=datestr)\n",
    "    for (city_id, vvid), datestr in itertools.product(city_id_vvids.items(), datestrs)\n",
    "]\n",
    "\n",
    "cache_qry_map = {\n",
    "    q.name: q.qry \n",
    "    for q in queries\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2/2 dataframes from cache!\n"
     ]
    }
   ],
   "source": [
    "class MyDataFetcher(DataFetcher):\n",
    "    def query_many_presto(self, *args, **kwargs):\n",
    "        return super().query_many_presto(*args, **kwargs)#, timeout=2000)\n",
    "    \n",
    "cdf = CachedDataFetcher(\n",
    "    data_fetcher=MyDataFetcher(\n",
    "        user_email=USER_EMAIL,\n",
    "        consumer_name=CONSUMER_NAME,\n",
    "    ),\n",
    "    cache_qry_map=cache_qry_map,\n",
    "    #datacenter='dca1',\n",
    "    datasource='presto-secure',\n",
    ")\n",
    "\n",
    "cdf.fetch(bust_cache=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39132, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scans = pd.concat(cdf.dfs.values(), axis=0, ignore_index=True).query(\"of_value > 1\")\n",
    "scans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datestr</th>\n",
       "      <th>city_id</th>\n",
       "      <th>plangen_pickup_lat</th>\n",
       "      <th>scan_uuid</th>\n",
       "      <th>plangen_uuid</th>\n",
       "      <th>job_uuid</th>\n",
       "      <th>planactiontype</th>\n",
       "      <th>supply_uuid</th>\n",
       "      <th>is_selected</th>\n",
       "      <th>eta</th>\n",
       "      <th>...</th>\n",
       "      <th>upfront_fare</th>\n",
       "      <th>est_rider_rsp_multiplier</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>is_scheduled_trip</th>\n",
       "      <th>fst_upfront_fare</th>\n",
       "      <th>reservation_variant</th>\n",
       "      <th>mgv_pickup_lat</th>\n",
       "      <th>mgv_pickup_lng</th>\n",
       "      <th>mgv_supply_lat</th>\n",
       "      <th>mgv_supply_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>1</td>\n",
       "      <td>37.794110</td>\n",
       "      <td>353d6eef-601f-4c30-9275-e39c863b53b9</td>\n",
       "      <td>aebaaafb-3c34-4afb-bbad-9222a53540ec</td>\n",
       "      <td>d8e6439d-4b62-4387-8a9c-136699df1754</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>fc099e06-4f97-43c0-bd7e-bc1876650ab8</td>\n",
       "      <td>0</td>\n",
       "      <td>818.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.82</td>\n",
       "      <td>0.965210</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.785175</td>\n",
       "      <td>-122.40537</td>\n",
       "      <td>37.781803</td>\n",
       "      <td>-122.401458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>1</td>\n",
       "      <td>37.784150</td>\n",
       "      <td>35830cae-a0ea-4618-a9f8-42103035e55b</td>\n",
       "      <td>4040b712-d02f-4824-aa64-16acb88c4610</td>\n",
       "      <td>8533c894-8085-4bdf-8617-a1551ae27064</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>ddea8314-8cc3-4840-8fbe-c8d082cbae8b</td>\n",
       "      <td>0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.17</td>\n",
       "      <td>1.074415</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.784150</td>\n",
       "      <td>-122.40456</td>\n",
       "      <td>37.779030</td>\n",
       "      <td>-122.401484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>1</td>\n",
       "      <td>37.776104</td>\n",
       "      <td>353d6eef-601f-4c30-9275-e39c863b53b9</td>\n",
       "      <td>aebaaafb-3c34-4afb-bbad-9222a53540ec</td>\n",
       "      <td>d8e6439d-4b62-4387-8a9c-136699df1754</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>c59fb151-d271-4860-9024-1b44d6589378</td>\n",
       "      <td>0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.82</td>\n",
       "      <td>0.965210</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.785175</td>\n",
       "      <td>-122.40537</td>\n",
       "      <td>37.788347</td>\n",
       "      <td>-122.416866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>1</td>\n",
       "      <td>37.776104</td>\n",
       "      <td>353d6eef-601f-4c30-9275-e39c863b53b9</td>\n",
       "      <td>aebaaafb-3c34-4afb-bbad-9222a53540ec</td>\n",
       "      <td>d8e6439d-4b62-4387-8a9c-136699df1754</td>\n",
       "      <td>OFFER</td>\n",
       "      <td>7793e7fb-f6c8-4cae-98bd-69f189cd4060</td>\n",
       "      <td>0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.82</td>\n",
       "      <td>0.965210</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.785175</td>\n",
       "      <td>-122.40537</td>\n",
       "      <td>37.776562</td>\n",
       "      <td>-122.394405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>1</td>\n",
       "      <td>37.406757</td>\n",
       "      <td>351aac3b-2c8e-4323-adf0-146b0bff57da</td>\n",
       "      <td>217eb3f5-ec1d-49cf-b975-57dcb2dc7ef5</td>\n",
       "      <td>9e5de763-34e0-43fb-9e7c-28e98bd0d1dd</td>\n",
       "      <td>KEEP_ALIVE</td>\n",
       "      <td>98d603d9-a479-415b-9c0d-bd328edd6803</td>\n",
       "      <td>0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.406757</td>\n",
       "      <td>-121.97379</td>\n",
       "      <td>37.352440</td>\n",
       "      <td>-121.973464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      datestr  city_id  plangen_pickup_lat  \\\n",
       "0  2021-09-27        1           37.794110   \n",
       "2  2021-09-27        1           37.784150   \n",
       "4  2021-09-27        1           37.776104   \n",
       "5  2021-09-27        1           37.776104   \n",
       "8  2021-09-27        1           37.406757   \n",
       "\n",
       "                              scan_uuid                          plangen_uuid  \\\n",
       "0  353d6eef-601f-4c30-9275-e39c863b53b9  aebaaafb-3c34-4afb-bbad-9222a53540ec   \n",
       "2  35830cae-a0ea-4618-a9f8-42103035e55b  4040b712-d02f-4824-aa64-16acb88c4610   \n",
       "4  353d6eef-601f-4c30-9275-e39c863b53b9  aebaaafb-3c34-4afb-bbad-9222a53540ec   \n",
       "5  353d6eef-601f-4c30-9275-e39c863b53b9  aebaaafb-3c34-4afb-bbad-9222a53540ec   \n",
       "8  351aac3b-2c8e-4323-adf0-146b0bff57da  217eb3f5-ec1d-49cf-b975-57dcb2dc7ef5   \n",
       "\n",
       "                               job_uuid planactiontype  \\\n",
       "0  d8e6439d-4b62-4387-8a9c-136699df1754          OFFER   \n",
       "2  8533c894-8085-4bdf-8617-a1551ae27064          OFFER   \n",
       "4  d8e6439d-4b62-4387-8a9c-136699df1754          OFFER   \n",
       "5  d8e6439d-4b62-4387-8a9c-136699df1754          OFFER   \n",
       "8  9e5de763-34e0-43fb-9e7c-28e98bd0d1dd     KEEP_ALIVE   \n",
       "\n",
       "                            supply_uuid  is_selected    eta  ...  \\\n",
       "0  fc099e06-4f97-43c0-bd7e-bc1876650ab8            0  818.0  ...   \n",
       "2  ddea8314-8cc3-4840-8fbe-c8d082cbae8b            0  523.0  ...   \n",
       "4  c59fb151-d271-4860-9024-1b44d6589378            0  733.0  ...   \n",
       "5  7793e7fb-f6c8-4cae-98bd-69f189cd4060            0  708.0  ...   \n",
       "8  98d603d9-a479-415b-9c0d-bd328edd6803            0  785.0  ...   \n",
       "\n",
       "   upfront_fare  est_rider_rsp_multiplier  surge_multiplier  \\\n",
       "0         15.82                  0.965210               1.3   \n",
       "2         18.17                  1.074415               2.0   \n",
       "4         15.82                  0.965210               1.3   \n",
       "5         15.82                  0.965210               1.3   \n",
       "8         56.93                       NaN               4.9   \n",
       "\n",
       "   is_scheduled_trip  fst_upfront_fare  reservation_variant  mgv_pickup_lat  \\\n",
       "0                  0               NaN                  NaN       37.785175   \n",
       "2                  0               NaN                  NaN       37.784150   \n",
       "4                  0               NaN                  NaN       37.785175   \n",
       "5                  0               NaN                  NaN       37.785175   \n",
       "8                  0               NaN                  NaN       37.406757   \n",
       "\n",
       "   mgv_pickup_lng  mgv_supply_lat  mgv_supply_lng  \n",
       "0      -122.40537       37.781803     -122.401458  \n",
       "2      -122.40456       37.779030     -122.401484  \n",
       "4      -122.40537       37.788347     -122.416866  \n",
       "5      -122.40537       37.776562     -122.394405  \n",
       "8      -121.97379       37.352440     -121.973464  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import osmnx as ox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point, LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('tl_2017_06075_roads.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('shapefiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiona.ogrext:Failed to auto identify EPSG: 7\n"
     ]
    }
   ],
   "source": [
    "# geo_df = gpd.read_file('shapefiles/tl_2017_06075_roads.shp')\n",
    "geo_df = gpd.read_file('stanford_shapefile/zk060kc5726.shp')\n",
    "### geo_df = gpd.read_file('bay_area_shapefile/geo_export_8129597e-2c44-4cec-b815-c997d3a423d1.shp')\n",
    "### geo_df = gpd.read_file('bay_area_shapefile_2/bayarea_zipcodes.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "from flipr_client.clients.remote_client import RemoteClient\n",
    "from batch_utils import helpers\n",
    "\n",
    "flipr = RemoteClient(\n",
    "    host='localhost',\n",
    "    port=14570,\n",
    "    application_identifier='autolaszlo'\n",
    ")\n",
    "radars = helpers.get_radars(1, flipr)\n",
    "print(len(radars['radars']))\n",
    "radar_set = set()\n",
    "for radar in radars['radars']:\n",
    "    if radar['radarFlow'] == 'uberx':\n",
    "        radar_set.add((radar['center']['latitude'], radar['center']['longitude'], radar['maxRadius']))\n",
    "#         print(radar['maxRadius'])\n",
    "#         print(radar['center']['latitude'], radar['center']['longitude'])\n",
    "print(len(radar_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['replay_city1_(8)_2021-09-27_segment35', 'replay_city12_(125)_2021-09-27_segment35'])\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-28-a2d6b19fd363>, line 176)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-a2d6b19fd363>\"\u001b[0;36m, line \u001b[0;32m176\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# geo_df = geo_df.to_crs(epsg=3857)\n",
    "# # Initialize our plot\n",
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# # Plot our SF GeoDataFrame\n",
    "# geo_df.plot(ax=ax, alpha = .1)\n",
    "# # Add in a background using contextily\n",
    "# ## ctx.add_basemap(ax)\n",
    "# ctx.add_basemap(ax, source = ctx.sources.OSM_A)\n",
    "\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "\n",
    "only_sf = False\n",
    "show_radars = False\n",
    "\n",
    "blue_color = 'b'# \"#390099\"#\"#3a86ff\"\n",
    "red_color = \"#d81159\"\n",
    "\n",
    "print(cdf.dfs.keys())\n",
    "prune_of = 1500\n",
    "for scans_key in cdf.dfs.keys():\n",
    "    city_id = int(scans_key.split('_')[1][4:])\n",
    "    datestr = scans_key.split('_')[3]\n",
    "#     if city_id not in [1, 3, 12, 52, 458]:\n",
    "    if city_id not in [1]:\n",
    "        continue\n",
    "    scans = cdf.dfs[scans_key]\n",
    "#     number_of_clusters = get_number_of_components_in_all_scans(scans)\n",
    "    df = scans\n",
    "    markov_df = df[df['of_value']>1]\n",
    "#     markov_df = compute_new_of(markov_df, c_d = 1)\n",
    "    total_scans = list(set(markov_df['scan_uuid']))\n",
    "    job_count_list = []\n",
    "    cluster_count_list = []\n",
    "    #d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "    #df = pd.DataFrame(data=d)\n",
    "#     OG figure is scan[19]\n",
    "    for scan_count, scan_uuid in enumerate(total_scans[5:30]):\n",
    "#     for scan_count, scan_uuid in enumerate(total_scans[19:20]):\n",
    "#     for scan_count, scan_uuid in enumerate(total_scans[19:35]):\n",
    "        scan = markov_df[markov_df['scan_uuid'] == scan_uuid]\n",
    "        plan_count = scan.shape[0]\n",
    "        pickup_lats = list(scan['mgv_pickup_lat'])\n",
    "        pickup_lngs = list(scan['mgv_pickup_lng'])\n",
    "        supply_lats = list(scan['mgv_supply_lat'])\n",
    "        supply_lngs = list(scan['mgv_supply_lng'])\n",
    "        of_column = 'of_value'\n",
    "        of_values = list(scan[of_column])\n",
    "#         drivers = scan[['mgv_supply_lat', 'mgv_supply_lng']].copy()\n",
    "#         riders = scan[['mgv_pickup_lat', 'mgv_pickup_lng']].copy()\n",
    "        driver_points = []\n",
    "        rider_points = []\n",
    "        graph_edges = []\n",
    "        unique_drivers = set()\n",
    "        unique_riders = set()\n",
    "        for j in range(plan_count):\n",
    "            if of_values[j] > prune_of:\n",
    "                continue\n",
    "            pickup = pickup_lats[j]\n",
    "            unique_riders.add(list(scan['job_uuid'])[j])\n",
    "            unique_drivers.add(list(scan['supply_uuid'])[j])\n",
    "            supply_point = Point(float(list(scan['mgv_supply_lng'])[j]), float(list(scan['mgv_supply_lat'])[j]))\n",
    "            job_point = Point(float(list(scan['mgv_pickup_lng'])[j]), float(list(scan['mgv_pickup_lat'])[j]))\n",
    "            driver_points.append(supply_point)\n",
    "            rider_points.append(job_point)\n",
    "            graph_edges.append(LineString([supply_point, job_point]))\n",
    "        \n",
    "#         print(scan_count, len(set(list(scan['job_uuid']))), len(graph_edges))\n",
    "#         continue\n",
    "#         if len(unique_riders) < len(unique_drivers):\n",
    "#             continue\n",
    "#         print(scan_count, len(unique_riders), len(unique_drivers))\n",
    "#         continue\n",
    "#         print(unique_riders)\n",
    "#         print(rider_points)\n",
    "\n",
    "        geo_df = geo_df.to_crs(epsg=3857)\n",
    "        # Initialize our plot\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        # Plot our SF GeoDataFrame\n",
    "        sf_alpha = 0.05 if only_sf else 0.01\n",
    "        geo_df.plot(ax=ax, alpha = sf_alpha)\n",
    "        # Add in a background using contextily\n",
    "        # ctx.add_basemap(ax)\n",
    "        if only_sf:\n",
    "            ctx.add_basemap(ax, source = ctx.sources.OSM_A)\n",
    "\n",
    "            \n",
    "        riders = pd.DataFrame()\n",
    "        drivers = pd.DataFrame()\n",
    "        edges = pd.DataFrame()\n",
    "        radars = pd.DataFrame()\n",
    "\n",
    "        drivers['geometry'] = driver_points\n",
    "        # Convert Pandas DataFrame to a GeoDataFrame\n",
    "        drivers_geo_df = gpd.GeoDataFrame(drivers, geometry='geometry')\n",
    "        # Initialize crs to 4326 because that's the format of our geomtry\n",
    "        drivers_geo_df.crs = \"EPSG:4326\"\n",
    "        # Change the crs to match our SF GeoDataFrame\n",
    "        drivers_geo_df = drivers_geo_df.to_crs(epsg = 3857)\n",
    "        \n",
    "        riders['geometry'] = rider_points\n",
    "        # Convert Pandas DataFrame to a GeoDataFrame\n",
    "        riders_geo_df = gpd.GeoDataFrame(riders, geometry='geometry')\n",
    "        # Initialize crs to 4326 because that's the format of our geomtry\n",
    "        riders_geo_df.crs = \"EPSG:4326\"\n",
    "        # Change the crs to match our SF GeoDataFrame\n",
    "        riders_geo_df = riders_geo_df.to_crs(epsg = 3857)\n",
    "\n",
    "        edges['geometry'] = graph_edges\n",
    "        edges_geo_df = gpd.GeoDataFrame(edges, geometry='geometry')\n",
    "        edges_geo_df.crs = \"EPSG:4326\"\n",
    "        edges_geo_df = edges_geo_df.to_crs(epsg = 3857)\n",
    "        \n",
    "        # Plot our drivers locations\n",
    "        drivers_geo_df.plot(ax=ax, color=red_color, marker = '.', markersize=50, edgecolor = 'black', legend = True)\n",
    "        # Add in a background using contextily\n",
    "##         ctx.add_basemap(ax)\n",
    "\n",
    "        edges_geo_df.plot(ax=ax, color=blue_color, linewidth=0.4)\n",
    "\n",
    "        # Plot our riders locations\n",
    "        riders_geo_df.plot(ax=ax, color='gray', marker = '.', markersize=250, edgecolor = 'black', legend = True)\n",
    "        # Add in a background using contextily\n",
    "##         ctx.add_basemap(ax)\n",
    "        #important it seems\n",
    "        ctx.add_basemap(ax, source = ctx.sources.OSM_A)\n",
    "#         print(drivers_geo_df)\n",
    "    \n",
    "        \n",
    "        if show_radars:\n",
    "            radars_points = []\n",
    "            radars_sizes = []\n",
    "            for lat, lng, radius in radar_set:\n",
    "                radars_points.append(Point(lng, lat))\n",
    "                radars_sizes.append(radius*0.9)\n",
    "    #             drawObject = Circle((lng, lat), radius, color='r', alpha=0.1)\n",
    "    #             ax.add_patch(drawObject)\n",
    "            radars['geometry'] = radars_points\n",
    "            # Convert Pandas DataFrame to a GeoDataFrame\n",
    "            radars_geo_df = gpd.GeoDataFrame(radars, geometry='geometry')\n",
    "            # Initialize crs to 4326 because that's the format of our geomtry\n",
    "            radars_geo_df.crs = \"EPSG:4326\"\n",
    "            # Change the crs to match our SF GeoDataFrame\n",
    "            radars_geo_df = radars_geo_df.to_crs(epsg = 3857)\n",
    "            radars_geo_df['sizes'] = radars_sizes\n",
    "            radars_geo_df.plot(ax=ax, color=red_color, marker = 'o', markersize=radars_sizes, edgecolor = 'red', legend = True, alpha=0.2)\n",
    "\n",
    "#         plt.plot((4.50*1e6, -1.360*1e7))\n",
    "#         ctx.add_basemap(ax)\n",
    "        ctx.add_basemap(ax, source = ctx.sources.OSM_A)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        if not only_sf:\n",
    "            miny = 4.47*1e6\n",
    "            maxy = 4.56*1e6\n",
    "            minx = -1.364*1e7\n",
    "            maxx = -1.356*1e7\n",
    "        # # ax.set(xlim=(minx, maxx), ylim=(miny, maxy))\n",
    "            ax.set_xlim(minx, maxx)\n",
    "            ax.set_ylim(miny, maxy)\n",
    "\n",
    "        title = 'automated_new_'\n",
    "        title += \"SF_City\" if only_sf else \"BayArea\"\n",
    "        if show_radars:\n",
    "            title += '_show_radars'\n",
    "        ax.set_axis_off()\n",
    "        fig.tight_layout()\n",
    "        plt.savefig('new_bayarea_pics2/%s_%s_%s.png' % (title, scans_key, scan_count), dpi=300)\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "#         break\n",
    "    break\n",
    "\n",
    "# Turn off axis\n",
    "# ax.set_axis_off()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if only_sf:\n",
    "#     miny = 4.54*1e6\n",
    "#     maxy = 4.555*1e6\n",
    "#     minx = -1.364*1e7\n",
    "#     maxx = -1.362*1e7\n",
    "\n",
    "if not only_sf:\n",
    "    miny = 4.47*1e6\n",
    "    maxy = 4.56*1e6\n",
    "    minx = -1.364*1e7\n",
    "    maxx = -1.356*1e7\n",
    "# # ax.set(xlim=(minx, maxx), ylim=(miny, maxy))\n",
    "    ax.set_xlim(minx, maxx)\n",
    "    ax.set_ylim(miny, maxy)\n",
    "\n",
    "title = 'New_'\n",
    "title += \"SF_City\" if only_sf else \"BayArea\"\n",
    "if show_radars:\n",
    "    title += '_show_radars'\n",
    "fig.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('%s_%s_%s.png' % (title, scans_key, scan_count), dpi=300)\n",
    "# plt.cla()\n",
    "# plt.clf()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (General DS)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
