{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for Quick Start Example on MaLearn EngDocs\n",
    "\n",
    "https://engdocs.uberinternal.com/malearn/rst/user_guide/quick-start.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build operators and workflow service fat jars.\n",
    "# ./buckw build //data/michelangelo/operators/jarfatjar:bin_main\n",
    "# ./buckw build //data/michelangelo/workflow:bin_main\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config('spark.jars', '../../../../../buck-out/gen/data/michelangelo/operators/jarfatjar/bin_main/bin_main.jar') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Setup (not needed in DSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append system path\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "# Tunnel Muttley for production WFO GRPC\n",
    "# os.system('ssh -MfN -L 5435:localhost:5435 adhoc20-dca1')\n",
    "# Or start WFO service locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MaLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malearn\n",
    "from malearn import MaLearnConfig\n",
    "\n",
    "config = MaLearnConfig()\n",
    "config.running_mode = 'local'\n",
    "config.workspace_override_root_dir = '/tmp/michelangelo'  # Only for local.\n",
    "config.workflow_service_port = 9877  # 9876 for OSS, 5435 for muttley\n",
    "malearn.init(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "Load Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malearn.datasets import load_iris\n",
    "df = load_iris()\n",
    "# Show DataFrame\n",
    "df.value.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Split data into train data set and test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malearn.model_selection import TrainTestSplit\n",
    "splitter = TrainTestSplit(test_ratio=0.2)\n",
    "train_df, test_df = splitter.split(df)\n",
    "# Show count\n",
    "train_df.value.count(), test_df.value.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Define Decision Tree parameters using Params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malearn import Params\n",
    "p = Params()\n",
    "p.max_depth = 5\n",
    "p.max_bins = 32\n",
    "params = p.to_constant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Spark ML Pipeline using Custom Python Operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malearn import Params, python_op\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "@python_op\n",
    "def create_pipeline(train_df: DataFrame, params: Params) -> Pipeline:\n",
    "    from pyspark.ml.classification import DecisionTreeClassifier\n",
    "    from pyspark.ml.feature import IndexToString, StringIndexer, VectorAssembler\n",
    "    from pyspark.ml import Pipeline\n",
    "\n",
    "    label_string_indexer = StringIndexer(inputCol='target', outputCol='indexedLabel').fit(train_df)\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm'],\n",
    "        outputCol='features')\n",
    "    dt = DecisionTreeClassifier(\n",
    "        labelCol='indexedLabel',\n",
    "        featuresCol='features',\n",
    "        predictionCol='indexedPrediction',\n",
    "        maxDepth=p.max_depth,\n",
    "        maxBins=p.max_bins)\n",
    "    label_index_to_string = IndexToString(\n",
    "        inputCol='indexedPrediction',\n",
    "        outputCol='prediction',\n",
    "        labels=label_string_indexer.labels)\n",
    "    return Pipeline(stages=[label_string_indexer, assembler, dt, label_index_to_string])\n",
    "\n",
    "pipeline = create_pipeline(train_df, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Make prediction on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_df = pipeline_model.predict(test_df)\n",
    "predicted_test_df.value.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data\n",
    "Save data to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = predicted_test_df.drop(['features', 'rawPrediction', 'indexedLabel', 'probability', 'indexedPrediction'])\n",
    "final_df.to_csv('/tmp/michelangelo/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
