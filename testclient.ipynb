{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc940b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/jghosh2/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import http.client\n",
    "import base64\n",
    "import time\n",
    "import json\n",
    "import traceback\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "nltk.download('popular')\n",
    "import os\n",
    "#from flask import jsonify # <- `jsonify` instead of `json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ed01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############L1 traige inputs#############\n",
    "id1=1\n",
    "label1='prod'\n",
    "projectid1=\"taxml_classification\"\n",
    "item1='Hot Pockets'\n",
    "description1='Choose between Pepperoni and Ham & Cheddar'\n",
    "establishment_type1='CONVENIENCE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91c2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_1={\"id\": id1,\"label\": label1,\"projectid\": projectid1,\"item\": item1,\"description\": description1,\"establishment_type\":establishment_type1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deee4113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"version\":\"1.0\",\"access_token\":\"eyJhbGciOiJFUzI1NiIsImVudiI6InByb2QiLCJraWQiOiJnX0hsUlpnWGRzMlNFcUVFUGVzZmdiUDBaRWxIV2tiaFJ5SUd4alRKMWNrIiwidHlwIjoiSldUIiwidmVyIjoiMS4wIn0.eyJhdWQiOiJpYWNvZS11cHNlcnZpY2UudWJlcmludGVybmFsLmNvbSIsImNsaWVudF9pZCI6IjNZS25pekJha3R1dUxQcjN5bk53aU40ZDN4a0trTmVZNXhvVWZjV00iLCJleHAiOjE2NzM1NzU5MTcsImlhdCI6MTY3MzUwMzYxNywiaXNzIjoic3BpZmZlOi8vdXNzby51cGtpLmNhIiwianRpIjoiNjMzMTQ0OGUtNzQyZS00NGU0LTlmYTEtNzRhYTk3MDM1YjEzIiwicGxjeSI6IktUc2FEMjRsdHgyczVWY2FCa0tpMndyRnAxeHFsWm4xWFRIeHdvUTlTZFNGNGRQcWVHdkxZQW5Cc0Y2VlFPZlNJUHFGNW1rS1M4c0hzY3VRb2x1d3J3ZGhGTk1iVHNXcmFUL1MzM1RUVGxzdWhRanBzWHk5SWgvMzRRYVJvRGJpdXVGSUtMcXFOb1BDcnhOR1VzNkpGZG5leXZZWFBQdkxPRHBkQnUwcmZISG01NFpGNm9uUzY3a0ViZWRsY09aa1l0bEFZL1I1ZDJvPSIsInBsY3lfa2V5Ijoia2V5LXVzc28tcGxjeS0xMTA5MTgucGVtIiwic3ViIjoic3BpZmZlOi8vdXNzby51cGtpLmNhL3NlcnZpY2Uvc3ZjLXVwc2VydmljZS1pYWNvZSIsInR5cGUiOiJhY2Nlc3MifQ.FNaEq_U2UBmMF_vbGqofqptzEIGdPk_NbPL4JEtsSSLdQ0hfUSFTqZymQAmjzOec75oZEsX2x-EVXIXcCZUfeQ\",\"issued_at\":1673503917,\"expires_in\":37108,\"refresh_token\":\"ZTczNTBmNjgtOWMzNi00OTYyLTljZmQtZmRmMDhhODA4ZTI4LBy3Uyqutmbd9FBg4EFI6BlTvN6VfMCNxpgJ1f13gwIrkTH-ZFn4KEJoi3wt5bJ2-v4vCNKwQvI8LpmXj2zojA\",\"refresh_expires_in\":2320799,\"token_type\":\"bearer\"}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'Authorization': 'Basic M1lLbml6QmFrdHV1TFByM3luTndpTjRkM3hrS2tOZVk1eG9VZmNXTTozd3FpR2hQS3RDR3JIaGV2S3A5MXVNbGk5Qll2ZkVsUkdHNUlHZ29h',\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    #'audience': 'inca-staging.uberinternal.com',\n",
    "    'audience': 'iacoe-upservice.uberinternal.com',\n",
    "}\n",
    "\n",
    "response = requests.post('https://usso.uberinternal.com/oauth2/token', headers=headers, data=data)\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88cb4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f5fcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJhbGciOiJFUzI1NiIsImVudiI6InByb2QiLCJraWQiOiJnX0hsUlpnWGRzMlNFcUVFUGVzZmdiUDBaRWxIV2tiaFJ5SUd4alRKMWNrIiwidHlwIjoiSldUIiwidmVyIjoiMS4wIn0.eyJhdWQiOiJpYWNvZS11cHNlcnZpY2UudWJlcmludGVybmFsLmNvbSIsImNsaWVudF9pZCI6IjNZS25pekJha3R1dUxQcjN5bk53aU40ZDN4a0trTmVZNXhvVWZjV00iLCJleHAiOjE2NzM1NzU5MTcsImlhdCI6MTY3MzUwMzYxNywiaXNzIjoic3BpZmZlOi8vdXNzby51cGtpLmNhIiwianRpIjoiNjMzMTQ0OGUtNzQyZS00NGU0LTlmYTEtNzRhYTk3MDM1YjEzIiwicGxjeSI6IktUc2FEMjRsdHgyczVWY2FCa0tpMndyRnAxeHFsWm4xWFRIeHdvUTlTZFNGNGRQcWVHdkxZQW5Cc0Y2VlFPZlNJUHFGNW1rS1M4c0hzY3VRb2x1d3J3ZGhGTk1iVHNXcmFUL1MzM1RUVGxzdWhRanBzWHk5SWgvMzRRYVJvRGJpdXVGSUtMcXFOb1BDcnhOR1VzNkpGZG5leXZZWFBQdkxPRHBkQnUwcmZISG01NFpGNm9uUzY3a0ViZWRsY09aa1l0bEFZL1I1ZDJvPSIsInBsY3lfa2V5Ijoia2V5LXVzc28tcGxjeS0xMTA5MTgucGVtIiwic3ViIjoic3BpZmZlOi8vdXNzby51cGtpLmNhL3NlcnZpY2Uvc3ZjLXVwc2VydmljZS1pYWNvZSIsInR5cGUiOiJhY2Nlc3MifQ.FNaEq_U2UBmMF_vbGqofqptzEIGdPk_NbPL4JEtsSSLdQ0hfUSFTqZymQAmjzOec75oZEsX2x-EVXIXcCZUfeQ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995ed923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZTczNTBmNjgtOWMzNi00OTYyLTljZmQtZmRmMDhhODA4ZTI4LBy3Uyqutmbd9FBg4EFI6BlTvN6VfMCNxpgJ1f13gwIrkTH-ZFn4KEJoi3wt5bJ2-v4vCNKwQvI8LpmXj2zojA'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['refresh_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96f995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(item,description,establishment_type):\n",
    "\n",
    "    message=item + \" \" +description+ \" \"+establishment_type\n",
    "    sw =nltk.corpus.stopwords.words('english')   \n",
    "   # new_stopwords=['ml','oz','pk','grocery','lb']\n",
    "   # sw.extend(new_stopwords) \n",
    "    # 1. Init Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #lowering and removing punctuation\n",
    "    message = re.sub(r'[^\\w\\s]',' ', message.lower())\n",
    "    #removing the numerical values and working only with text values\n",
    "    message = re.sub('[^a-zA-Z]', \" \", message )\n",
    "    #removing the stopwords\n",
    "    message = ' '.join([word for word in message.split() if word not in sw and len(word)>1])\n",
    "    #lemmatizing the text\n",
    "    message =  \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(message) if w not in string.punctuation])\n",
    "    #print(\"message is : \",message)\n",
    "    return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43fe7f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import http.client\n",
    "def classify_taxml_michelangelo(id1,label,projectid,item,description,establishment_type):\n",
    "    # preprocessing\n",
    "    message =preprocess_text(item, description,establishment_type)\n",
    "    #     message = [message]\n",
    "    print(message)\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection(\"iacoe-upservice.uberinternal.com\")\n",
    "        \n",
    "        payload = json.dumps({\"id\":id1,\"label\": label,\"projectid\": projectid,\"ticketinput\":message})\n",
    "        print(payload)\n",
    "        my_token=json_data['access_token']\n",
    "        #my_token=json_data['refresh_token']\n",
    "        #print(my_token)\n",
    "        headers = {\n",
    "          'Content-Type': 'application/json',\n",
    "          'RPC-Service': 'iacoe-upservice',\n",
    "          'RPC-Procedure': 'uber.finance.iacoe.iacoeupservice.IacoeUpservice::Predictionmodel',\n",
    "          'RPC-Encoding': 'json',\n",
    "          'Context-TTL-MS': '1000',\n",
    "          'Authorization':  'Bearer {}'.format(my_token)\n",
    "        }\n",
    "        #print(headers)\n",
    "        conn.request(\"POST\", \"/api\", payload, headers)\n",
    "        res = conn.getresponse()\n",
    "        data = res.read()\n",
    "        data=data.decode(\"utf-8\")\n",
    "        #print(data)\n",
    "        result = json.loads(data)\n",
    "        print(result)\n",
    "        final_result={}\n",
    "        if 'topPrediction' in result: \n",
    "            if label=='prod':\n",
    "                output= result['topPrediction'].replace('[', '').replace(']', '').replace('\"','')\n",
    "                final_result['cat_name']= output.split(':')[0]\n",
    "                final_result['integer']= output.split(':')[1]\n",
    "                final_result['conf_score']= result['confScore']\n",
    "            final_result=[200,final_result]\n",
    "        else:\n",
    "            final_result=[400,result]\n",
    "\n",
    "    except:\n",
    "        tb = traceback.format_exc()\n",
    "        return [\"\\n\" + tb]\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1fed74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxml_classifier_michelangelo(request):\n",
    "    try:\n",
    "        #logger.info(f'[{os.getpid()}] Received Request for {sys._getframe().f_code.co_name} with {request.data}')\n",
    "        # fetch input data and store it\n",
    "        #print(request)\n",
    "        id1=request['id']\n",
    "        label = request['label']\n",
    "        projectid = request['projectid']\n",
    "        item = request['item']\n",
    "        description = request['description']\n",
    "        establishment_type = request['establishment_type']\n",
    "        # pass items list for prediction/classification\n",
    "        final_result = classify_l1triage_michelangelo(id1,label,projectid,item,description,establishment_type)\n",
    "        #print(final_result)\n",
    "        if final_result[0] != 200:\n",
    "           # logger.error(CLASSIFICATION_EXCEPTION,exc_info=result)\n",
    "            return {\"Error\": final_result[1]}\n",
    "\n",
    "        success = {\"success\": final_result[1]}\n",
    "        #logger.info(f'[{os.getpid()}] Request successfully completed with {success}'+\"\\n\")\n",
    "        return success\n",
    "        \n",
    "    except:\n",
    "        tb = traceback.format_exc()\n",
    "        print(\"exception\" +tb)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc8304d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot pocket choose pepperoni ham cheddar convenience\n",
      "{\"id\": 1, \"label\": \"prod\", \"projectid\": \"taxml_classification\", \"ticketinput\": \"hot pocket choose pepperoni ham cheddar convenience\"}\n",
      "{'topPrediction': '[\"CAT_PREPACKAGED_FOOD,TEMP_COLD:106,3\"]', 'confScore': '0.64'}\n",
      "{'success': {'cat_name': 'CAT_PREPACKAGED_FOOD,TEMP_COLD', 'integer': '106,3', 'conf_score': '0.64'}}\n"
     ]
    }
   ],
   "source": [
    "print(l1_triage_classifier_michelangelo(payload_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d562699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda activate py365\n",
    "#export USSH_TOKEN=$(usso -ussh iacoe-upservice.uberinternal.com -print 2>&1 | tail -n 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543133d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
