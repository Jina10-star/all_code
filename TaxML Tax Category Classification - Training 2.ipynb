{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa18879",
   "metadata": {},
   "source": [
    "# <h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import Requirements\" data-toc-modified-id=\"Import-Requirements-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Requirements</a></span></li><li><span><a href=\"#Prepare Training Data\" data-toc-modified-id=\"Prepare-Training-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prepare Training Data</a></span><ul class=\"toc-item\"></ul></li><li><span><a href=\"#Model Training\" data-toc-modified-id=\"Model Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Training</a></span></li><li><span><a href=\"#Model Saving\" data-toc-modified-id=\"Model Saving-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model Saving</a></span><ul class=\"toc-item\"></ul></li><li><span><a href=\"#Validation and Results\" data-toc-modified-id=\"Validation and Results-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Validation and Results</a></span><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe6d0d",
   "metadata": {},
   "source": [
    "<a id='Import Requirements'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971b37a",
   "metadata": {},
   "source": [
    "# Import Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca994c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4342ccbd",
   "metadata": {},
   "source": [
    "<a id='Prepare Training Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4230c",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0d0ec",
   "metadata": {},
   "source": [
    "Input data for training consists of both historical data and CICD data( Production run data for which manual agent validation has been done for the ML prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322e3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(message):\n",
    "\n",
    "    #stopwords\n",
    "    stpwrd = nltk.corpus.stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    message=message.lower()\n",
    "    message = re.sub(r'-',' ', message)\n",
    "    #removing the numerical values and working only with text values\n",
    "    message = re.sub('[^a-zA-Z]', \" \", message)\n",
    "    #lowering and removing punctuation\n",
    "    message = re.sub(r'[^\\w\\s]',' ',message)\n",
    "    #removing the stopwords\n",
    "    message = ' '.join([word for word in message.split() if word not in stpwrd])\n",
    "    #lemmatizing the text\n",
    "    message =  \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(message) if w not in string.punctuation])\n",
    "    #removing hyperlinks\n",
    "    message = re.sub(r'http\\S+', ' ', message)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff2ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inca1=pd.read_csv('../data/retrain_data/INDIRECTTX-1954-03-15.csv', usecols = ['entity_uuid','product_name','product_description','establishment_type','CAT NAME,CAT_TEMP','Integers'])\n",
    "data_inca2=pd.read_csv('../data/retrain_data/INDIRECTTX-1954-02-15.csv', usecols = ['entity_uuid','product_name','product_description','establishment_type','CAT NAME,CAT_TEMP','Integers'])\n",
    "data_inca3=pd.read_csv('../data/retrain_data/2023-05-22 - Albertsons Liquor in Illinois - Menu Items & Existing Tax Categories.csv', usecols = ['entity_uuid','product_name','product_description','establishment_type','CAT NAME,CAT_TEMP','Integers'])\n",
    "data_inca4=pd.read_csv('../data/retrain_data/INDIRECTTX-1954 - 2023-06-09.csv', usecols = ['entity_uuid','product_name','product_description','establishment_type','CAT NAME,CAT_TEMP','Integers'])\n",
    "data_inca=pd.concat([data_inca1,data_inca2,data_inca3,data_inca4])\n",
    "data_inca['target_new']=data_inca['CAT NAME,CAT_TEMP']+\":\"+ data_inca['Integers']\n",
    "data_inca.drop(['CAT NAME,CAT_TEMP', 'Integers'],inplace=True,axis=1)\n",
    "data_inca=data_inca.rename(columns={'product_name': 'Item', 'product_description': 'Description','entity_uuid':'UniqueUUID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9a09841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35207 entries, 0 to 21127\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   UniqueUUID          35207 non-null  object\n",
      " 1   Item                35207 non-null  object\n",
      " 2   Description         33530 non-null  object\n",
      " 3   establishment_type  35207 non-null  object\n",
      " 4   target_new          35207 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_inca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967ce9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read input from historical data into dataframe\n",
    "data_df = pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/historical_data_24_11_22.csv', encoding='utf8',engine='python',usecols=['UniqueUUID','Item','Description','establishment_type','target_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9dc93c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583371, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 39928 entries, 11374 to 583282\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   UniqueUUID          39928 non-null  object\n",
      " 1   Item                39928 non-null  object\n",
      " 2   Description         31371 non-null  object\n",
      " 3   establishment_type  39928 non-null  object\n",
      " 4   target_new          39928 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "(21971, 7)\n"
     ]
    }
   ],
   "source": [
    "#read input from cicd data into dataframe\n",
    "data_cicd=pd.read_csv('../data/retrain_data/TaxML-CICD - Prod_Data_latest.csv', usecols = ['UniqueUUID','Item','Description','establishment_type','Confidence Score','Agent Corrected CAT Name', 'Agent Corrected Integer','CAT NAME_ ValidationScore [0-100]','Integer_ValidationScore[0-100]'])\n",
    "print(data_cicd.shape)\n",
    "#misclassified data                                        \n",
    "data_cicd_misclassification=data_cicd[(data_cicd['CAT NAME_ ValidationScore [0-100]']==0)| (data_cicd['Integer_ValidationScore[0-100]']==0)]\n",
    "data_cicd_latest=data_cicd_misclassification[['UniqueUUID','Item','Description','establishment_type','Agent Corrected CAT Name', 'Agent Corrected Integer']]\n",
    "data_cicd_latest['target_new']=data_cicd_latest['Agent Corrected CAT Name'] + \":\" + data_cicd_latest['Agent Corrected Integer']\n",
    "data_cicd_latest.drop(['Agent Corrected CAT Name', 'Agent Corrected Integer'],inplace=True,axis=1)\n",
    "print(data_cicd_latest.info())\n",
    "data_cicd_final = pd.concat([data_inca, data_cicd_latest], join=\"outer\")\n",
    "final_data=pd.concat([data_df, data_cicd_final], join=\"outer\")\n",
    "final_data.to_csv('training_data.csv',index=False)\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "data_cicd_final['combined_text'] = data_cicd_final[['Item','Description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "data_cicd_final['processed_text']= data_cicd_final['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "\n",
    "data_cicd_final = data_cicd_final.reset_index(drop=True)\n",
    "# prepare the target column by combining 'Agent Corrected CAT Name' and 'Agent Corrected Integer'\n",
    "\n",
    "data_cicd_final=data_cicd_final.drop_duplicates(subset=['processed_text','target_new'],keep='first')\n",
    "print(data_cicd_final.shape)\n",
    "\n",
    "#remove rows having empty target column\n",
    "data_cicd_final.dropna(subset=['target_new'],inplace=True)\n",
    "\n",
    "\n",
    "X_cicd= data_cicd_final[['Item','Description','establishment_type','processed_text']]\n",
    "y_cicd= data_cicd_final['target_new']\n",
    "\n",
    "# split the cicd data into train and test \n",
    "X_train_cicd, X_test_cicd, y_train_cicd, y_test_cicd = train_test_split(X_cicd, y_cicd,shuffle=True, test_size = .01, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3211e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 396190 entries, 0 to 396189\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   UniqueUUID          396190 non-null  object\n",
      " 1   Item                396187 non-null  object\n",
      " 2   Description         271012 non-null  object\n",
      " 3   establishment_type  396190 non-null  object\n",
      " 4   target_new          396190 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 15.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0739b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergedStuff_cicd= data_df.set_index('UniqueUUID').join(data_cicd_latest.set_index('UniqueUUID'))\n",
    "#final_data=pd.concat([data_df, data_cicd_final], join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa585e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueUUID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Description</th>\n",
       "      <th>establishment_type</th>\n",
       "      <th>target_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n</td>\n",
       "      <td>Captain Morgan White Rum.1.75L Bottle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_LIQUOR:535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n</td>\n",
       "      <td>D’USSÉ® VSOP Cognac.375ml Bottle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_LIQUOR:535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n</td>\n",
       "      <td>Jim Beam Honey Bourbon Whiskey.750ml Bottle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_LIQUOR:535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n</td>\n",
       "      <td>Ardbeg Scotch Uigeadail. 750ml Bottle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_LIQUOR:535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n</td>\n",
       "      <td>Jameson Irish Whiskey.1.75L Bottle Size</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_LIQUOR:535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583278</th>\n",
       "      <td>e64e6ef6-a179-5c09-babe-565f6d743b80:f3589175-...</td>\n",
       "      <td>Planters · Cocktail Peanuts (12 oz)</td>\n",
       "      <td>12 oz</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_SNACK_NUTS:747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583279</th>\n",
       "      <td>e64e6ef6-a179-5c09-babe-565f6d743b80:6d218339-...</td>\n",
       "      <td>Café Bustelo · Espresso Ground Coffee (6 oz)</td>\n",
       "      <td>6 oz</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_INSTANT_COFFEE:733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583280</th>\n",
       "      <td>e64e6ef6-a179-5c09-babe-565f6d743b80:1fd4c419-...</td>\n",
       "      <td>Old El Paso · Vegetarian Refried Beans (16 oz)</td>\n",
       "      <td>16 oz</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD_CANNED_BEANS:719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583281</th>\n",
       "      <td>e64e6ef6-a179-5c09-babe-565f6d743b80:d6980d8d-...</td>\n",
       "      <td>The Greek Gods · Greek Style Nonfat Plain Yogu...</td>\n",
       "      <td>24 oz</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_PREPACKAGED_FOOD,CAT_SNACK,TEMP_COLD:106,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583282</th>\n",
       "      <td>e64e6ef6-a179-5c09-babe-565f6d743b80:6ac06b04-...</td>\n",
       "      <td>Vita Coco · Coconut Water (16.9 fl oz)</td>\n",
       "      <td>16.9 fl oz</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>CAT_JUICE,TRAIT_PCT_100,TEMP_COLD:110,51,3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450197 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               UniqueUUID  \\\n",
       "0                                                      \\n   \n",
       "1                                                      \\n   \n",
       "2                                                      \\n   \n",
       "3                                                      \\n   \n",
       "4                                                      \\n   \n",
       "...                                                   ...   \n",
       "583278  e64e6ef6-a179-5c09-babe-565f6d743b80:f3589175-...   \n",
       "583279  e64e6ef6-a179-5c09-babe-565f6d743b80:6d218339-...   \n",
       "583280  e64e6ef6-a179-5c09-babe-565f6d743b80:1fd4c419-...   \n",
       "583281  e64e6ef6-a179-5c09-babe-565f6d743b80:d6980d8d-...   \n",
       "583282  e64e6ef6-a179-5c09-babe-565f6d743b80:6ac06b04-...   \n",
       "\n",
       "                                                     Item Description  \\\n",
       "0                   Captain Morgan White Rum.1.75L Bottle         NaN   \n",
       "1                        D’USSÉ® VSOP Cognac.375ml Bottle         NaN   \n",
       "2             Jim Beam Honey Bourbon Whiskey.750ml Bottle         NaN   \n",
       "3                   Ardbeg Scotch Uigeadail. 750ml Bottle         NaN   \n",
       "4                 Jameson Irish Whiskey.1.75L Bottle Size         NaN   \n",
       "...                                                   ...         ...   \n",
       "583278                Planters · Cocktail Peanuts (12 oz)       12 oz   \n",
       "583279       Café Bustelo · Espresso Ground Coffee (6 oz)        6 oz   \n",
       "583280     Old El Paso · Vegetarian Refried Beans (16 oz)       16 oz   \n",
       "583281  The Greek Gods · Greek Style Nonfat Plain Yogu...       24 oz   \n",
       "583282             Vita Coco · Coconut Water (16.9 fl oz)  16.9 fl oz   \n",
       "\n",
       "       establishment_type                                         target_new  \n",
       "0                 GROCERY                                     CAT_LIQUOR:535  \n",
       "1                 GROCERY                                     CAT_LIQUOR:535  \n",
       "2                 GROCERY                                     CAT_LIQUOR:535  \n",
       "3                 GROCERY                                     CAT_LIQUOR:535  \n",
       "4                 GROCERY                                     CAT_LIQUOR:535  \n",
       "...                   ...                                                ...  \n",
       "583278            GROCERY                CAT_PREPACKAGED_FOOD_SNACK_NUTS:747  \n",
       "583279            GROCERY            CAT_PREPACKAGED_FOOD_INSTANT_COFFEE:733  \n",
       "583280            GROCERY              CAT_PREPACKAGED_FOOD_CANNED_BEANS:719  \n",
       "583281            GROCERY  CAT_PREPACKAGED_FOOD,CAT_SNACK,TEMP_COLD:106,1...  \n",
       "583282            GROCERY         CAT_JUICE,TRAIT_PCT_100,TEMP_COLD:110,51,3  \n",
       "\n",
       "[450197 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af554b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396190, 7)\n"
     ]
    }
   ],
   "source": [
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "data_df['combined_text'] = data_df[['Item','Description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "data_df['processed_text']= data_df['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0002a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343116, 7)\n",
      "(274492, 4)\n"
     ]
    }
   ],
   "source": [
    "data_df=data_df.drop_duplicates(subset=['processed_text','target_new'],keep='first')\n",
    "print(data_df.shape)\n",
    "#remove rows having empty target column\n",
    "data_df.dropna(subset=['target_new'],inplace=True)\n",
    "\n",
    "X= data_df[['Item','Description','establishment_type','processed_text']]\n",
    "y= data_df['target_new']\n",
    "\n",
    "# split the cicd data into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,shuffle=True, test_size = .20, random_state = 42)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a27ed",
   "metadata": {},
   "source": [
    "We will append the CICD data to the historical data to create the final train and test data.\n",
    "Train set has 80% of all historical data and 90% of all cicd data.\n",
    "Test set consists of 20% of historic data and 10% of all cicd data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dceeea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train.append(X_train_cicd)\n",
    "X_test_final = X_test.append(X_test_cicd)\n",
    "y_train_final = y_train.append(y_train_cicd)\n",
    "y_test_final = y_test.append(y_test_cicd)\n",
    "\n",
    "#X_train_final = X_train\n",
    "#X_test_final = X_test\n",
    "#y_train_final = y_train\n",
    "#y_test_final = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123f453",
   "metadata": {},
   "source": [
    "<a id='Model Training'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd540e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 296243\n",
      "Test data size: 68844\n"
     ]
    }
   ],
   "source": [
    "print('Training data size: {}'.format(len(X_train_final)))\n",
    "print('Test data size: {}'.format(len(X_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2e6c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels in train data: 206\n",
      "Number of unique labels in test data: 197\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique labels in train data: {}'.format(len(y_train_final.unique().tolist())))\n",
    "print('Number of unique labels in test data: {}'.format(len(y_test_final.unique().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f664ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_new</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CAT_LIQUOR:535</th>\n",
       "      <td>37090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_PREPARED_FOOD,TEMP_HEATED:101,1</th>\n",
       "      <td>32171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_TPP:531</th>\n",
       "      <td>31809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_WINE:534</th>\n",
       "      <td>22136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_BEER:533</th>\n",
       "      <td>17534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_TPP_CAMPING_EQUIPMENT:779</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_POSTAGE:527</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_PRESCRIPTION_DRUGS:520</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_OIL:778</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT_NEWSPAPERS:538</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     count\n",
       "target_new                                \n",
       "CAT_LIQUOR:535                       37090\n",
       "CAT_PREPARED_FOOD,TEMP_HEATED:101,1  32171\n",
       "CAT_TPP:531                          31809\n",
       "CAT_WINE:534                         22136\n",
       "CAT_BEER:533                         17534\n",
       "...                                    ...\n",
       "CAT_TPP_CAMPING_EQUIPMENT:779            4\n",
       "CAT_POSTAGE:527                          2\n",
       "CAT_PRESCRIPTION_DRUGS:520               2\n",
       "CAT_OIL:778                              1\n",
       "CAT_NEWSPAPERS:538                       1\n",
       "\n",
       "[204 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_count = data_df.groupby(['target_new'],sort=False).agg({'target_new':'count'})\n",
    "category_count.rename(columns={'target_new':'count'},inplace=True)\n",
    "category_count.sort_values('count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edc1a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_count.to_csv('category_count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6d97a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75af4ab",
   "metadata": {},
   "source": [
    "The Model Pipeline consists of 1. CountVectorizer, 2. Tfidf-Transformer 3. MultinomialNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a6991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = CountVectorizer(strip_accents='ascii',token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', stop_words='english', max_df=0.85)\n",
    "#X = vectorizer.fit_transform(X_train_final['processed_text'].values)\n",
    "#features = vectorizer.get_feature_names()\n",
    "#len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f12ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t_start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69bdc710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a result dataframe to store final results\n",
    "result=X_test_final\n",
    "\n",
    "#create the model pipeline\n",
    "rf = Pipeline([('vect', CountVectorizer(strip_accents='ascii',max_df=0.85)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            #('mnb', MultinomialNB(alpha= 0.05,fit_prior= False))])\n",
    "            #('clf', RandomForestClassifier())])\n",
    "            ('svc',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f66314de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/utils/validation.py:179: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(joblib_version) < '0.12':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.85,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents='ascii',\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('svc',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform model training\n",
    "rf.fit(X_train_final['processed_text'].values, y_train_final.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39d8c5eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3172894089.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/dk/dcz1bsq51ydb6f7j_7n8pxpr0000gn/T/ipykernel_24678/3172894089.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print(\"Total model training time: {}\".format(time_minutes))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "t_end=time.time()\n",
    "interval=t_end-t_start\n",
    "time_minutes=time.strftime(\"%H:%M:%S\", time.gmtime(interval)\n",
    "print(\"Total model training time: {}\".format(time_minutes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8d3ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "result=X_test_final\n",
    "y_pred = rf.predict(X_test_final['processed_text'].values)\n",
    "\n",
    "result['original_cat']= y_test_final.values\n",
    "result['predicted_cat'] = y_pred\n",
    "#result['prediction_cat_confscore'] = np.round_(np.max(rf.predict_proba(X_test_final['processed_text']), axis=1), decimals=2)\n",
    "result['prediction_cat_confscore'] = np.round_(1/(1+(np.max(rf.decision_function(X_test_final['processed_text'].values), axis=1))),decimals=2)\n",
    "\n",
    "#\n",
    "output = {'accuracy': accuracy_score(y_pred,y_test_final),'precision_score':precision_score(y_pred,y_test_final,average='weighted'),'recall_score':recall_score(y_pred,y_test_final,average='weighted')\n",
    ",'f1_score':f1_score(y_pred,y_test_final,average='weighted')}\n",
    "\n",
    "result['confusion_matrix'] = str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e34bb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"{'accuracy': 0.7910638545116495, 'precision_score': 0.8015364216905002, 'recall_score': 0.7910638545116495, 'f1_score': 0.7948336169385961}\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['confusion_matrix'] [5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array([\"{'accuracy': 0.7481380408209677, 'precision_score': 0.8104281909828657, 'recall_score': 0.7481380408209677, 'f1_score': 0.772676580987015}\"],\n",
    "      #dtype=object)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f3209",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d68dbf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   45.5s finished\n",
      "/Users/jghosh2/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/utils/validation.py:179: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(joblib_version) < '0.12':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7174939692303207\n",
      "Best Params:  {'mnb__alpha': 0.05}\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "  'mnb__alpha': [0.01,0.05,0.1,0.2,0.3],\n",
    "}\n",
    "clf = GridSearchCV(rf, grid_params,n_jobs=-1,verbose=1)\n",
    "clf.fit(X_train_final['processed_text'].values, y_train_final.values)\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(\"Best Params: \", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aace8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'svc__C':np.arange(0.01,100,10)}\n",
    "linearSVC = GridSearchCV(rf,param_grid,cv=2,return_train_score=True)\n",
    "linearSVC.fit(X_train_final['processed_text'].values, y_train_final.values)\n",
    "print(linearSVC.best_params_)\n",
    "#linearSVC.coef_\n",
    "#linearSVC.intercept_\n",
    "\n",
    "bestlinearSVC = linearSVC.best_estimator_\n",
    "bestlinearSVC.fit(X_train,y_train)\n",
    "bestlinearSVC.coef_ = bestlinearSVC.named_steps['SVC'].coef_\n",
    "bestlinearSVC.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = metrics.classification_report(y_test_final, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4944c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display=pd.DataFrame(classification_report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.to_csv('classification_report.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa3c79",
   "metadata": {},
   "source": [
    "<a id='Model Saving'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dab90b",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54abd6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/model/latest/finalized_model.sav\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import datetime\n",
    "# save the model to disk\n",
    "filename_primary= 'finalized_model.sav'\n",
    "model_dir_taxml='/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/model/latest'\n",
    "# save the model to disk\n",
    "filename_primary= 'finalized_model.sav'\n",
    "model_path = os.path.join(model_dir_taxml, filename_primary) \n",
    "print(model_path)\n",
    "pickle.dump(rf, open(model_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0273b",
   "metadata": {},
   "source": [
    "<a id='Validation and Results'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4c028",
   "metadata": {},
   "source": [
    "# Validation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c98d4f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8697386942476278\n"
     ]
    }
   ],
   "source": [
    "#accuracy score of the model\n",
    "import joblib\n",
    "x=joblib.load(model_path)\n",
    "accuracy = x.score(X_train_final['processed_text'].values, y_train_final)\n",
    "print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c11bfb",
   "metadata": {},
   "source": [
    "# Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39fa7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "x=joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "330118b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg=X_train_final['processed_text'][:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5ebfdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reg=X_test_final['processed_text'][:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cce29678",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg=pd.concat([X_train_reg,X_test_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "831fbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reg=y_train_final[:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9c8923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reg=y_test_final[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5ba0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reg=pd.concat([y_train_reg,y_test_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e00d6c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.84842\n"
     ]
    }
   ],
   "source": [
    "#accuracy score of the model of regression\n",
    "accuracy = x.score(X_reg, y_reg)\n",
    "print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "830d6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df=pd.DataFrame()\n",
    "accuracy_df['Accuracy']=[accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "354d5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df.to_csv('old_accuracy.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4aa179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_accuracy=pd.read_csv('./old_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79fd8335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to update model\n"
     ]
    }
   ],
   "source": [
    "if old_accuracy['Accuracy'].item()>accuracy:\n",
    "    print('No need to update model')\n",
    "else:\n",
    "     print('Need to update model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e978a",
   "metadata": {},
   "source": [
    "# Saving the train and test data for reference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d91cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_end = int(len(data_df)*train_size)\n",
    "df_train = data_df[:train_end]\n",
    "df_test = data_df[train_end:]\n",
    "train_size_cicd=0.02\n",
    "train_end_cicd = int(len(data_cicd_final)*train_size_cicd)\n",
    "df2_train = data_cicd_final[:train_end_cicd]\n",
    "df2_test = data_cicd_final[train_end_cicd:]\n",
    "df2_train = df2_train[['Item','Description','establishment_type','combined_text','processed_text','target_new']]\n",
    "df2_test = df2_test[['Item','Description','establishment_type','combined_text','processed_text','target_new']]\n",
    "X_train_save = df_train.append(df2_train)\n",
    "X_test_save = df_test.append(df2_test)\n",
    "X_train_save['label'] = 'train'\n",
    "X_test_save['label'] = 'test'\n",
    "X_data = X_train_save.append(X_test_save)\n",
    "X_data.to_csv('df_traintestdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "461a685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the misclassifications\n",
    "misclassifications= result.loc[result['original_cat']!=result['predicted_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f7d7d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16781"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(misclassifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3581dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications.to_csv('misclassifications.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c21a4",
   "metadata": {},
   "source": [
    "# model tagging on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c919063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "x=joblib.load('finalized_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6e09d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(475000, 14)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dk/dcz1bsq51ydb6f7j_7n8pxpr0000gn/T/ipykernel_20228/2422938505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cat_int'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction_cat_confscore'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'combined_text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'processed_text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/after/2023-07-14 - Walmart Canada_after_tagging_7.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py365/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "#read input from historical data into dataframe\n",
    "df_1= pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/before/2023-07-14 - Walmart Canada_7.csv',encoding='latin-1',engine='python')\n",
    "#choose sample data from entire data\n",
    "df_1 = df_1.sample(frac=1, random_state=42)\n",
    "#fill blanks with ''\n",
    "df_1 = df_1.fillna('')\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "df_1['combined_text'] = df_1[['product_name','product_description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "df_1['processed_text'] = df_1['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "print(df_1.shape)\n",
    "df_1 = df_1.reset_index(drop=True)\n",
    "y_pred = x.predict(df_1['processed_text'].values)\n",
    "df_1['target'] = y_pred\n",
    "df_1[['cat_name','cat_int']] = df_1['target'].str.split(':', expand=True)\n",
    "df_1['prediction_cat_confscore'] = np.round_(1/(1+(np.max(x.decision_function(df_1['processed_text'].values), axis=1))),decimals=2)\n",
    "#df_1['prediction_cat_confscore'] =np.round_(np.max(x.predict_proba(df_1['processed_text']), axis=1), decimals=2)\n",
    "df_1.drop(['combined_text','processed_text','target'], inplace=True, axis=1)\n",
    "df_1.to_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/after/2023-07-14 - Walmart Canada_after_tagging_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f94799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(475000, 14)\n"
     ]
    }
   ],
   "source": [
    "#read input from historical data into dataframe\n",
    "df_1= pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/before/2023-07-14 - Walmart Canada_8.csv',encoding='latin-1',engine='python')\n",
    "#choose sample data from entire data\n",
    "df_1 = df_1.sample(frac=1, random_state=42)\n",
    "#fill blanks with ''\n",
    "df_1 = df_1.fillna('')\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "df_1['combined_text'] = df_1[['product_name','product_description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "df_1['processed_text'] = df_1['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "print(df_1.shape)\n",
    "df_1 = df_1.reset_index(drop=True)\n",
    "y_pred = x.predict(df_1['processed_text'].values)\n",
    "df_1['target'] = y_pred\n",
    "df_1[['cat_name','cat_int']] = df_1['target'].str.split(':', expand=True)\n",
    "#df_1['prediction_cat_confscore'] =np.round_(np.max(x.predict_proba(df_1['processed_text']), axis=1), decimals=2)\n",
    "df_1['prediction_cat_confscore'] = np.round_(1/(1+(np.max(x.decision_function(df_1['processed_text'].values), axis=1))),decimals=2)\n",
    "df_1.drop(['combined_text','processed_text','target'], inplace=True, axis=1)\n",
    "df_1.to_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/after/2023-07-14 - Walmart Canada_after_tagging_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a121f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318749, 14)\n"
     ]
    }
   ],
   "source": [
    "#read input from historical data into dataframe\n",
    "df_1= pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/before/2023-07-14 - Walmart Canada_9.csv',encoding='latin-1',engine='python')\n",
    "#choose sample data from entire data\n",
    "df_1 = df_1.sample(frac=1, random_state=42)\n",
    "#fill blanks with ''\n",
    "df_1 = df_1.fillna('')\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "df_1['combined_text'] = df_1[['product_name','product_description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "df_1['processed_text'] = df_1['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "print(df_1.shape)\n",
    "df_1 = df_1.reset_index(drop=True)\n",
    "y_pred = x.predict(df_1['processed_text'].values)\n",
    "df_1['target'] = y_pred\n",
    "df_1[['cat_name','cat_int']] = df_1['target'].str.split(':', expand=True)\n",
    "#df_1['prediction_cat_confscore'] =np.round_(np.max(x.predict_proba(df_1['processed_text']), axis=1), decimals=2)\n",
    "df_1['prediction_cat_confscore'] = np.round_(1/(1+(np.max(x.decision_function(df_1['processed_text'].values), axis=1))),decimals=2)\n",
    "df_1.drop(['combined_text','processed_text','target'], inplace=True, axis=1)\n",
    "df_1.to_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/after/2023-07-14 - Walmart Canada_after_tagging_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "028e7a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(475000, 14)\n"
     ]
    }
   ],
   "source": [
    "#read input from historical data into dataframe\n",
    "df_1= pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/before/2023-07-14 - Walmart Canada_6.csv',encoding='latin-1',engine='python')\n",
    "#choose sample data from entire data\n",
    "df_1 = df_1.sample(frac=1, random_state=42)\n",
    "#fill blanks with ''\n",
    "df_1 = df_1.fillna('')\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "df_1['combined_text'] = df_1[['product_name','product_description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "df_1['processed_text'] = df_1['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "print(df_1.shape)\n",
    "df_1 = df_1.reset_index(drop=True)\n",
    "y_pred = x.predict(df_1['processed_text'].values)\n",
    "df_1['target'] = y_pred\n",
    "df_1[['cat_name','cat_int']] = df_1['target'].str.split(':', expand=True)\n",
    "df_1['prediction_cat_confscore'] =np.round_(np.max(x.predict_proba(df_1['processed_text']), axis=1), decimals=2)\n",
    "df_1.drop(['combined_text','processed_text','target'], inplace=True, axis=1)\n",
    "df_1.to_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/after/2023-07-14 - Walmart Canada_after_tagging_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d2b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132281, 9)\n",
      "(132281, 12)\n"
     ]
    }
   ],
   "source": [
    "#read input from historical data into dataframe\n",
    "df_2= pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/before/2023-01-16 - Weekly New GroCo Menu Items.csv', encoding='utf8',engine='python')\n",
    "#choose sample data from entire data\n",
    "df_2 = df_2.sample(frac=1, random_state=42)\n",
    "#fill blanks with ''\n",
    "df_2 = df_2.fillna('')\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "df_2['combined_text'] = df_2[['item_name','description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "df_2['processed_text'] = df_2['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "print(df_2.shape)\n",
    "df_2 = df_2.reset_index(drop=True)\n",
    "y_pred = x.predict(df_2['processed_text'].values)\n",
    "df_2['target'] = y_pred\n",
    "df_2[['cat_name','cat_int']] = df_2['target'].str.split(':', expand=True)\n",
    "df_2.drop('target', inplace=True, axis=1)\n",
    "df_2['prediction_cat_confscore'] =np.round_(np.max(x.predict_proba(df_2['processed_text']), axis=1), decimals=2)\n",
    "df_2.to_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/after/2023-01-16 - Weekly New GroCo Menu Items_after_tagging.csv')\n",
    "print(df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b380a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3198, 25)\n",
      "(3198, 26)\n"
     ]
    }
   ],
   "source": [
    "#read input from historical data into dataframe\n",
    "df_3= pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/before/INDIRECTTX-2456 - Uber Eats Market (Jersey City) - INCA Tax Tagging - INCA Products.csv', encoding='latin-1',engine='python')\n",
    "#choose sample data from entire data\n",
    "df_3 = df_3.sample(frac=1, random_state=42)\n",
    "#fill blanks with ''\n",
    "df_3 = df_3.fillna('')\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "df_3['combined_text'] = df_3[['product_name','product_description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "df_3['processed_text'] = df_3['combined_text'].map(lambda s:preprocess_text(s)) \n",
    "print(df_3.shape)\n",
    "df_3 = df_3.reset_index(drop=True)\n",
    "y_pred = x.predict(df_3['processed_text'].values)\n",
    "df_3['target'] = y_pred\n",
    "df_3[['cat_name','cat_int']] = df_3['target'].str.split(':', expand=True)\n",
    "df_3.drop('target', inplace=True, axis=1)\n",
    "df_3['prediction_cat_confscore'] =np.round_(np.max(x.predict_proba(df_3['processed_text']), axis=1), decimals=2)\n",
    "df_3.drop('processed_text', inplace=True, axis=1)\n",
    "df_3.drop('combined_text', inplace=True, axis=1)\n",
    "df_3.to_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/ml_tagged_data/after/INDIRECTTX-2456 - Uber Eats Market (Jersey City) - INCA Tax Tagging - INCA Products_after_tagging.csv')\n",
    "print(df_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2bcd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read input from historical data into dataframe\n",
    "df_3= pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/bf.csv', encoding='latin-1',engine='python')\n",
    "#choose sample data from entire data\n",
    "df_3 = df_3.sample(frac=1, random_state=42)\n",
    "#fill blanks with ''\n",
    "df_3 = df_3.fillna('')\n",
    "# combine the columns Item, Description and establishment_type into one column 'combined_text'\n",
    "df_3['combined_text'] = df_3[['Item','Description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "# apply data preprocessing steps on the prepared column\n",
    "df_3['processed_text'] = df_3['combined_text'].map(lambda s:preprocess_text(s)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97455808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2415 entries, 410 to 860\n",
      "Data columns (total 21 columns):\n",
      " #   Column                               Non-Null Count  Dtype \n",
      "---  ------                               --------------  ----- \n",
      " 0   Unnamed: 0                           2415 non-null   int64 \n",
      " 1   CICD Run Date                        2415 non-null   object\n",
      " 2   Date (BOT Sent Details to COE Team)  2415 non-null   object\n",
      " 3   UniqueUUID                           2415 non-null   object\n",
      " 4   store_uuid                           2415 non-null   object\n",
      " 5   item_uuid                            2415 non-null   object\n",
      " 6   Item                                 2415 non-null   object\n",
      " 7   Description                          2415 non-null   object\n",
      " 8   establishment_type                   2415 non-null   object\n",
      " 9   ML CAT Name                          2415 non-null   object\n",
      " 10  ML Integer                           2415 non-null   object\n",
      " 11  ML Confidence Score                  2415 non-null   object\n",
      " 12  Agent CAT Name                       2415 non-null   object\n",
      " 13  Agent Integer                        2415 non-null   object\n",
      " 14  Accuracy                             2415 non-null   bool  \n",
      " 15  New ML Prediction                    2415 non-null   object\n",
      " 16  New ML Integer                       2415 non-null   object\n",
      " 17  New Accuracy                         2415 non-null   object\n",
      " 18  Module                               2415 non-null   object\n",
      " 19  combined_text                        2415 non-null   object\n",
      " 20  processed_text                       2415 non-null   object\n",
      "dtypes: bool(1), int64(1), object(19)\n",
      "memory usage: 398.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d629df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2415, 21)\n",
      "(2415, 19)\n"
     ]
    }
   ],
   "source": [
    "print(df_3.shape)\n",
    "df_3 = df_3.reset_index(drop=True)\n",
    "y_pred = x.predict(df_3['processed_text'].values)\n",
    "df_3['target'] = y_pred\n",
    "df_3[['ML CAT Name','ML Integer']] = df_3['target'].str.split(':', expand=True)\n",
    "df_3.drop('target', inplace=True, axis=1)\n",
    "df_3['ML Confidence Score'] =np.round_(np.max(x.predict_proba(df_3['processed_text']), axis=1), decimals=2)\n",
    "df_3.drop('processed_text', inplace=True, axis=1)\n",
    "df_3.drop('combined_text', inplace=True, axis=1)\n",
    "df_3.to_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/bf.csv')\n",
    "print(df_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fba8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
