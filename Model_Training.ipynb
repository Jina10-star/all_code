{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T00:17:13.530224Z",
     "start_time": "2022-12-06T00:17:13.514487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data preparation: split the dataset as training/testing, and extract the data based on feature list\n",
    "import pandas\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "base_features = ['city_id', 'day_of_week',\n",
    "       'hour_of_day', 'demand_surge',\n",
    "       'eta', 'rounded_eta', 'fd_eta', 'eyeball_eta',\n",
    "       'forward_dispatched', 'starpower', \n",
    "#         'request_location_latitude', 'request_location_longitude', \n",
    "#         'supply_location_latitude', 'supply_location_longitude', \n",
    "#         'dropoff_location_latitude', 'dropoff_location_longitude', \n",
    "        'days_since_signup',\n",
    "       'days_since_first_trip', 'trip_distance_haversine', 'is_commute',\n",
    "       'is_fifo',\n",
    "       'driver_surge_multiplier', 'est_rider_fare_distance_miles',\n",
    "       'fare_distance_miles', 'fare_duration_minutes', 'trip_distance_miles',\n",
    "       'trip_duration_seconds']\n",
    "\n",
    "NRT_features = ['request_average_demand_surge',\n",
    "       'supply_average_demand_surge', 'request_average_eta',\n",
    "       'supply_average_eta', 'request_average_rounded_eta',\n",
    "       'supply_average_rounded_eta', 'request_average_eyeball_eta',\n",
    "       'supply_average_eyeball_eta', 'request_average_trip_distance_haversine',\n",
    "       'supply_average_trip_distance_haversine', 'request_average_fd_eta',\n",
    "       'supply_average_fd_eta', 'request_average_forward_dispatched',\n",
    "       'supply_average_forward_dispatched',\n",
    "       'request_average_driver_surge_multiplier',\n",
    "       'supply_average_driver_surge_multiplier',\n",
    "       'request_average_est_rider_fare_distance_miles',\n",
    "       'supply_average_est_rider_fare_distance_miles',\n",
    "       'request_average_fare_distance_miles',\n",
    "       'supply_average_fare_distance_miles',\n",
    "       'request_average_fare_duration_minutes',\n",
    "       'supply_average_fare_duration_minutes',\n",
    "       'request_average_trip_distance_miles',\n",
    "       'supply_average_trip_distance_miles',\n",
    "       'request_average_trip_duration_seconds',\n",
    "       'supply_average_trip_duration_seconds',\n",
    "#         'request_average_cancel_rate', 'supply_average_cancel_rate'\n",
    "               ]\n",
    "\n",
    "NRT_30_features = ['request_average_demand_surge_30', \n",
    "                   'request_average_driver_surge_multiplier_30', \n",
    "                   'request_average_est_rider_fare_distance_miles_30', \n",
    "                   'request_average_eta_30', \n",
    "                   'request_average_eyeball_eta_30', \n",
    "                   'request_average_fare_distance_miles_30', \n",
    "                   'request_average_fare_duration_minutes_30', \n",
    "                   'request_average_fd_eta_30', \n",
    "                   'request_average_forward_dispatched_30', \n",
    "                   'request_average_rating_30', \n",
    "                   'request_average_rounded_eta_30', \n",
    "                   'request_average_supply_surge_30', \n",
    "                   'request_average_surge_diff_30', \n",
    "                   'request_average_trip_distance_haversine_30', \n",
    "                   'request_average_trip_distance_miles_30', \n",
    "                   'request_average_trip_duration_seconds_30', \n",
    "                   'supply_average_demand_surge_30', \n",
    "                   'supply_average_driver_surge_multiplier_30', \n",
    "                   'supply_average_est_rider_fare_distance_miles_30', \n",
    "                   'supply_average_eta_30', \n",
    "                   'supply_average_eyeball_eta_30', \n",
    "                   'supply_average_fare_distance_miles_30', \n",
    "                   'supply_average_fare_duration_minutes_30', \n",
    "                   'supply_average_fd_eta_30', \n",
    "                   'supply_average_forward_dispatched_30', \n",
    "                   'supply_average_rating_30', \n",
    "                   'supply_average_rounded_eta_30', \n",
    "                   'supply_average_supply_surge_30', \n",
    "                   'supply_average_surge_diff_30', \n",
    "                   'supply_average_trip_distance_haversine_30', \n",
    "                   'supply_average_trip_distance_miles_30', \n",
    "                   'supply_average_trip_duration_seconds_30'\n",
    "                  ]\n",
    "\n",
    "def SplitByDate(raw:pandas.DataFrame, split_date:str):\n",
    "    '''Split the data by split_date.\n",
    "    The data with split_date is included in testing set.\n",
    "    The trainsing and testing sets are returned as tuple.\n",
    "    '''\n",
    "    training_set = raw[raw['datestr']<split_date]\n",
    "    testing_set = raw[raw['datestr']>=split_date]\n",
    "    \n",
    "    return (training_set, testing_set)\n",
    "\n",
    "def DataPreparation(raw:pandas.DataFrame, split_date, features):\n",
    "    '''Prepare the data as training/testing data with defined features.\n",
    "    Return training and testing data as tuple.\n",
    "    '''\n",
    "    \n",
    "    # Fill all null values as zero\n",
    "    raw = raw.fillna(0)\n",
    "    \n",
    "    training_set, testing_set = SplitByDate(raw, split_date)\n",
    "    \n",
    "    training_x = training_set[features]\n",
    "    testing_x = testing_set[features]\n",
    "    \n",
    "    training_y = training_set['canceled']\n",
    "    testing_y = testing_set['canceled']\n",
    "    \n",
    "    return (training_x, training_y, testing_x, testing_y)\n",
    "\n",
    "def TemporalDataPreparation(raw:pandas.DataFrame, start_date:str, end_date:str, training_size:int, testing_size:int, step:int, features:list):\n",
    "    '''Prepare the data as training/tesing data with defined features, based on sliding window,\n",
    "    training_size, testing_size, step are in days.\n",
    "    Return a list of training and testing data.\n",
    "    '''\n",
    "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    result = []\n",
    "    \n",
    "    #initialize cursor, and cursor is the start date of each training set\n",
    "    cursor = start\n",
    "    \n",
    "    #initialize the split date, testing set date\n",
    "    split = cursor + timedelta(days=training_size)\n",
    "    end_test = split + timedelta(days=testing_size)\n",
    "    \n",
    "    while (end_test <= end):\n",
    "        #Split the training/testing data\n",
    "        filtered = raw[(raw['datestr']>=cursor.strftime('%Y-%m-%d')) & (raw['datestr']<end_test.strftime('%Y-%m-%d'))]\n",
    "        training_x, training_y, testing_x, testing_y = DataPreparation(filtered, split.strftime('%Y-%m-%d'), features)\n",
    "        result.append(\n",
    "            {\n",
    "                'training_x': training_x,\n",
    "                'training_y': training_y,\n",
    "                'testing_x': testing_x,\n",
    "                'testing_y': testing_y\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        #Move to next, update cursor, split, end_test\n",
    "        cursor = cursor + timedelta(days=step)\n",
    "        split = cursor + timedelta(days=training_size)\n",
    "        end_test = split + timedelta(days=testing_size)\n",
    "    return result\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T01:13:13.417172Z",
     "start_time": "2022-12-06T01:11:39.340948Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "raw = pandas.read_csv('Sample-1-1/report-trip-hexter-NRT-1-1-2022-0701-0715.csv', header=0)\n",
    "print(raw.shape)\n",
    "\n",
    "base_training_x, base_training_y, base_testing_x, base_testing_y = DataPreparation(raw, '2022-07-10', base_features)\n",
    "training_x, training_y, testing_x, testing_y = DataPreparation(raw, '2022-07-10', base_features + NRT_30_features)\n",
    "\n",
    "print(training_x.columns)\n",
    "\n",
    "print('Training baseline model')\n",
    "base_model = RandomForestClassifier(n_estimators=4, max_depth=12, random_state=919, n_jobs=4)\n",
    "base_model.fit(base_training_x, base_training_y)\n",
    "\n",
    "base_predict_y = base_model.predict(base_testing_x)\n",
    "base_training_predict_y = base_model.predict(base_training_x)\n",
    "\n",
    "print('Training NRT model')\n",
    "NRT_model = RandomForestClassifier(n_estimators=10, max_depth=15, random_state=919, n_jobs=4)\n",
    "NRT_model.fit(training_x, training_y)\n",
    "\n",
    "predict_y = NRT_model.predict(testing_x)\n",
    "training_predict_y = NRT_model.predict(training_x)\n",
    "\n",
    "\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T01:13:29.401589Z",
     "start_time": "2022-12-06T01:13:26.917591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "\n",
    "base_training_roc_auc = roc_auc_score(base_training_y, base_training_predict_y)\n",
    "base_training_f1 = f1_score(base_training_y, base_training_predict_y)\n",
    "\n",
    "base_roc_auc = roc_auc_score(base_testing_y, base_predict_y)\n",
    "base_f1 = f1_score(base_testing_y, base_predict_y)\n",
    "\n",
    "print('Baseline AUC: %s, baseline F1: %s. Training: %s, %s.' % (base_roc_auc, base_f1, base_training_roc_auc, base_training_f1))\n",
    "\n",
    "\n",
    "training_roc_auc = roc_auc_score(training_y, training_predict_y)\n",
    "training_f1 = f1_score(training_y, training_predict_y)\n",
    "\n",
    "roc_auc = roc_auc_score(testing_y, predict_y)\n",
    "f1 = f1_score(testing_y, predict_y)\n",
    "\n",
    "print('NRT AUC: %s, NRT F1: %s. Training: %s, %s.' % (roc_auc, f1, training_roc_auc, training_f1))\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T01:21:13.065004Z",
     "start_time": "2022-12-06T01:21:12.529089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "# NRT = ['NRT_' + x for x in NRT_features]\n",
    "NRT = ['NRT_'+x+'_30' for x in NRT_30_features]\n",
    "\n",
    "n_base_features = len(base_features)\n",
    "n_features = len(base_features+NRT_features)\n",
    "print(n_base_features, n_features)\n",
    "\n",
    "\n",
    "\n",
    "#NRT model\n",
    "importances = NRT_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in NRT_model.estimators_], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(importances)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=importances, y=base_features+NRT, error_x=dict(type='data', array=std), orientation='h'\n",
    "))\n",
    "fig.update_layout(barmode='group', yaxis={'categoryorder':'total ascending'}, height=1000, width=900)\n",
    "\n",
    "fig.update_yaxes(type='category', nticks=n_features)\n",
    "fig.update_layout(xaxis_title='Feature importance')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T00:59:57.180229Z",
     "start_time": "2022-12-06T00:56:51.901797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training and testing with sliding windows\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "\n",
    "raw = pandas.read_csv('Sample-1-1/report-trip-hexter-NRT-1-1-2022-0701-0715.csv', header=0)\n",
    "print(raw.shape)\n",
    "\n",
    "# Split the dataset with sliding windows\n",
    "base_set = TemporalDataPreparation(raw, start_date='2022-07-01', end_date='2022-07-15', training_size=7, testing_size=3, step=1, features=base_features+NRT_30_features)\n",
    "metrics = []\n",
    "\n",
    "training_metrics = []\n",
    "\n",
    "print('Start training')\n",
    "for item in base_set:\n",
    "    training_x = item['training_x']\n",
    "    training_y = item['training_y']\n",
    "    testing_x = item['testing_x']\n",
    "    testing_y = item['testing_y']\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=10, max_depth=15, random_state=919, n_jobs=4)\n",
    "    model.fit(training_x, training_y)\n",
    "\n",
    "    predict_y = model.predict(testing_x)\n",
    "\n",
    "    predict_training_y = model.predict(training_x)\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    training_roc_auc = roc_auc_score(training_y, predict_training_y)\n",
    "    training_f1 = f1_score(training_y, predict_training_y)\n",
    "    \n",
    "    # Calculate testing metrics\n",
    "    roc_auc = roc_auc_score(testing_y, predict_y)\n",
    "    f1 = f1_score(testing_y, predict_y)\n",
    "    \n",
    "    training_metrics.append(\n",
    "        {\n",
    "            'AUC': training_roc_auc,\n",
    "            'F1': training_f1\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    metrics.append(\n",
    "        {\n",
    "            'AUC': roc_auc,\n",
    "            'F1': f1\n",
    "        }\n",
    "    )\n",
    "    \n",
    "print(training_metrics)\n",
    "print('***')\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T01:07:15.094694Z",
     "start_time": "2022-12-06T01:07:15.037967Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the metrics\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "x_labels = [1,2,3,4,5]\n",
    "\n",
    "# SF dataset\n",
    "baseline_metrics = [{'AUC': 0.6620574080564671, 'F1': 0.5319849576470521}, {'AUC': 0.6615395663862847, 'F1': 0.5405177991804042}, {'AUC': 0.6603894860062521, 'F1': 0.5468657279286574}, {'AUC': 0.6433148587965223, 'F1': 0.5027744253939144}, {'AUC': 0.6305539685908852, 'F1': 0.47292936656289397}]\n",
    "# NRT_metrics = [{'AUC': 0.6650541650941918, 'F1': 0.5353107466489516}, {'AUC': 0.6678927807503241, 'F1': 0.5520939842094722}, {'AUC': 0.6661744957705457, 'F1': 0.5538367010654788}, {'AUC': 0.6493805667753964, 'F1': 0.5123467193388118}, {'AUC': 0.6400926422522591, 'F1': 0.4874351251781536}]\n",
    "\n",
    "# 30\n",
    "NRT_metrics = [{'AUC': 0.6631622713219711, 'F1': 0.5335935449264445}, {'AUC': 0.6651563831020831, 'F1': 0.5492524808210929}, {'AUC': 0.6622734655894722, 'F1': 0.5499634575775696}, {'AUC': 0.647061616889139, 'F1': 0.509317229397077}, {'AUC': 0.6345009481324229, 'F1': 0.47731614296803804}]\n",
    "\n",
    "\n",
    "training_baseline_metrics = [{'AUC': 0.6987256684922597, 'F1': 0.6028353730071503}, {'AUC': 0.6963268647320288, 'F1': 0.5930674970507902}, {'AUC': 0.6899193740878362, 'F1': 0.5799469646154118}, {'AUC': 0.6848123986619821, 'F1': 0.5738008058542632}, {'AUC': 0.6847363951546127, 'F1': 0.57355100047029}]\n",
    "training_NRT_metrics = [{'AUC': 0.7275042299546662, 'F1': 0.644549352505522}, {'AUC': 0.7248268938238777, 'F1': 0.6365058108252813}, {'AUC': 0.7183830605724439, 'F1': 0.6242910667654262}, {'AUC': 0.7156956735040735, 'F1': 0.6211565836531951}, {'AUC': 0.7125724755342857, 'F1': 0.6156996604803265}]\n",
    "\n",
    "\n",
    "training_baseline_metrics = pandas.DataFrame(training_baseline_metrics)\n",
    "training_NRT_metrics = pandas.DataFrame(training_NRT_metrics)\n",
    "baseline_metrics = pandas.DataFrame(baseline_metrics)\n",
    "NRT_metrics = pandas.DataFrame(NRT_metrics)\n",
    "\n",
    "print(training_baseline_metrics)\n",
    "print(training_NRT_metrics)\n",
    "print(round(baseline_metrics.describe(),4))\n",
    "print(round(NRT_metrics.describe(), 4))\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Baseline', x=['AUC', 'F1'], y=[baseline_metrics['AUC'].mean(), baseline_metrics['F1'].mean()], width=0.2),\n",
    "    go.Bar(name='NRT', x=['AUC', 'F1'], y=[NRT_metrics['AUC'].mean(), NRT_metrics['F1'].mean()], width=0.2)\n",
    "]\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Training scores\n",
    "# fig.add_trace(go.Scatter(x=x_labels, y=training_baseline_metrics['AUC'], mode='lines', name='Training Baseline-AUC', line=dict(color='green')))\n",
    "# fig.add_trace(go.Scatter(x=x_labels, y=training_baseline_metrics['F1'], mode='lines+markers', name='Training Baseline-F1', line=dict(color='green')))\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=x_labels, y=training_NRT_metrics['AUC'], mode='lines', name='Training NRT-AUC', line=dict(color='orange')))\n",
    "# fig.add_trace(go.Scatter(x=x_labels, y=training_NRT_metrics['F1'], mode='lines+markers', name='Training NRT-F1', line=dict(color='orange')))\n",
    "\n",
    "\n",
    "# Testing scores\n",
    "fig.add_trace(go.Scatter(x=x_labels, y=baseline_metrics['AUC'], mode='lines', name='Baseline-AUC', line=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x=x_labels, y=baseline_metrics['F1'], mode='lines+markers', name='Baseline-F1', line=dict(color='red')))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_labels, y=NRT_metrics['AUC'], mode='lines', name='NRT-AUC', line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=x_labels, y=NRT_metrics['F1'], mode='lines+markers', name='NRT-F1', line=dict(color='blue')))\n",
    "\n",
    "fig.update_layout(\n",
    "xaxis = dict(tickmode='linear', dtick = 1, tick0 = 1))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Sliding window\",\n",
    "    yaxis_title=\"Scores\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T07:11:04.609664Z",
     "start_time": "2022-12-06T01:30:17.476244Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter tuning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "raw = pandas.read_csv('Sample-1-1/report-trip-hexter-NRT-1-1-2022-0701-0715.csv', header=0)\n",
    "print(raw.shape)\n",
    "\n",
    "# Baseline model\n",
    "# training_x, training_y, testing_x, testing_y = DataPreparation(raw, '2022-07-10', base_features)\n",
    "\n",
    "# NRT model\n",
    "training_x, training_y, testing_x, testing_y = DataPreparation(raw, '2022-07-10', base_features + NRT_features + NRT_30_features)\n",
    "\n",
    "metrics = []\n",
    "\n",
    "\n",
    "# i is number of trees, d is the max depth\n",
    "for i in range(2, 30,2):\n",
    "    for d in range(2, 30):\n",
    "        print(i, d)\n",
    "        model = RandomForestClassifier(n_estimators=i, max_depth=d, random_state=919, n_jobs=4)\n",
    "        model.fit(training_x, training_y)\n",
    "\n",
    "        predict_y = model.predict(testing_x)\n",
    "        predict_training_y = model.predict(training_x)\n",
    "        \n",
    "        training_roc_auc = roc_auc_score(training_y, predict_training_y)\n",
    "        training_f1 = f1_score(training_y, predict_training_y)\n",
    "\n",
    "        roc_auc = roc_auc_score(testing_y, predict_y)\n",
    "        f1 = f1_score(testing_y, predict_y)\n",
    "\n",
    "        metrics.append({\n",
    "            'parameter': str(i)+' - '+str(d),\n",
    "            'Training_AUC': training_roc_auc,\n",
    "            'Training_F1': training_f1,\n",
    "            'Testing_AUC': roc_auc,\n",
    "            'Testing_F1': f1\n",
    "        })\n",
    "\n",
    "metrics = pandas.DataFrame(metrics)\n",
    "print(metrics)\n",
    "print('Done')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T22:06:46.283465Z",
     "start_time": "2022-12-05T22:06:46.248286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the parameter tunning results\n",
    "import pandas\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "metrics.to_csv('ParamTunning-NRT-1-1.csv', header=True, index=False)\n",
    "# metrics = pandas.read_csv('ParamTunning-NRT-1-1.csv', header=0)\n",
    "x_label = str(metrics['parameter'])\n",
    "print(metrics)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=metrics['parameter'], y=metrics['Training_AUC'], mode='lines', name='Training_AUC'))\n",
    "fig.add_trace(go.Scatter(x=metrics['parameter'], y=metrics['Training_F1'], mode='lines', name='Training_F1'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=metrics['parameter'], y=metrics['Testing_AUC'], mode='lines', name='Testing_AUC'))\n",
    "fig.add_trace(go.Scatter(x=metrics['parameter'], y=metrics['Testing_F1'], mode='lines', name='Testing_F1'))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Parameter pairs (#trees - max depth)\",\n",
    "    yaxis_title=\"Scores\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01. Python 3.7 (General DS)",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
