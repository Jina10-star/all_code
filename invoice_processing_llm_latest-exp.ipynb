{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9bbbd27",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0886be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##docquery\n",
    "#pip install typing-inspect==0.8.0 typing_extensions==4.5.0\n",
    "#pip uninstall numpy --yes\n",
    "#pip install numpy==1.21\n",
    "#pip install transformers==4.23\n",
    "#pip install #pip --upgrade\n",
    "#pip install pyopenssl --upgrade\n",
    "#pip show OpenSSL\n",
    "#pip install docquery\n",
    "#pip install protobuf==3.20.1\n",
    "#pip install Pillow\n",
    "#pip install tesseract\n",
    "#pip install poppler-utils \n",
    "#pip install pdf2image\n",
    "#pip install requests==2.27.1\n",
    "\n",
    "##chatgpt\n",
    "#!pip install langchain\n",
    "#!pip install openai\n",
    "#!pip install PyPDF2\n",
    "#!pip install faiss-cpu\n",
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42555072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "document-question-answering is already registered. Overwriting pipeline for task document-question-answering...\n"
     ]
    }
   ],
   "source": [
    "#common packages \n",
    "from PyPDF2 import PdfReader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "\n",
    "#chatgpt packages\n",
    "import openai\n",
    "import ast\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key=\"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\"\n",
    "#roberta packages\n",
    "from docquery import document, pipeline\n",
    "from docquery.ocr_reader import get_ocr_reader\n",
    "from PyPDF2 import PdfReader\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "#docquery-impira/layoutlm-document-qa\n",
    "from docquery import document, pipeline\n",
    "from docquery.ocr_reader import get_ocr_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9e639",
   "metadata": {},
   "source": [
    "# variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b13cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_entities=\"\"\"{\n",
    "\t\"vendor\": \"Amazon\",\n",
    "\t\"seller\": \"ETRADE MARKETING PRIVATE LIMITED\",\n",
    "\t\"order number\": \"404-9513165-0870751\",\n",
    "\t\"order date\": \"10.08.2023\",\n",
    "\t\"shipping address\": \"sarbajit das sarbajit das 4, 1 Floor, B-Wing. Sai Sainik, Gokuldham,kanyapada MUMBAI, MAHARASHTRA, 400063 IN\",\n",
    "\t\"invoice number\": \"DEL5-1348108\",\n",
    "\t\"invoice date\": \"10.08.2023\",\n",
    "\t\"total amount\": 236.00,\n",
    "\t\"tax amount\": 25.29,\n",
    "\t\"payment mode\": \"AmazonCredit\"\n",
    "}\"\"\"\n",
    "amazon_text=\"\"\"amazon.in\\nTax Invoice/Bill of Supply/Cash Memo\\n(Original for Recipient)\\n*\\nSold By:\\nETRADE MARKETING PRIVATE LIMITED\\nRect/Killa Nos. 38//8/2 min, 192//22/1,196//2/1/1,\\n37//15/1, 15/2,, Adjacent to Starex School, Village\\n- Binola, National Highway -8, Tehsil - Manesar\\nGurgaon, Haryana, 122413\\nIN\\nBilling Address:\\nsarbajit das\\n4, 1 Floor, B-Wing. Sai Sainik,\\nGokuldham,kanyapada\\nMUMBAI, MAHARASHTRA, 400063\\nIN\\nState/UT Code: 27\\nPAN NO: AADCV4254H\\nGST Registration No: 06AADCV4254H1ZC\\nShipping Address :\\nsarbajit das\\nsarbajit das\\n4, 1 Floor, B-Wing. Sai Sainik,\\nGokuldham,kanyapada\\nMUMBAI, MAHARASHTRA, 400063\\nIN\\nState/UT Code: 27\\nPlace of supply: MAHARASHTRA\\nPlace of delivery: MAHARASHTRA\\nInvoice Number: DEL5-1348108\\nInvoice Details ： HR-DEL5-1317922175-2324\\nInvoice Date: 10.08.2023\\nOrder Number: 404-9513165-0870751\\nOrder Date: 10.08.2023\\nQty\\n1\\nSI.\\nUnit\\nNet Tax Tax Tax Total\\nDescription\\nNo\\nPrice Amount Rate Type Amount Amount\\nKuber Industries Laundry Bag for Clothes, Toys With Handles, 45L\\n(Red & Blue)-HS43KUBMART25869 | B09GVLVJT9 (B09GVLVJT9) 175.00 1 175.00 12%|IGST 21.00 196.00\\nHSN:56031100\\nShipping Charges\\n35.71 35.71 12% IGST 4.29 40.00\\nTOTAL:\\n25.29 236.00\\nAmount in Words:\\nTwo Hundred Thirty-six only\\nFor ETRADE MARKETING PRIVATE LIMITED:\\nJa cu ada\\nAuthorized Signatory\\nWhether tax is payable under reverse charge - No\\nPayment Transaction ID:\\nKZb1Ffiu804xVEYH2xht\\nDate & Time: 10/08/2023, 00:23:59\\nhrs\\nInvoice Value:\\n236.00\\nMode of Payment:\\nAmazonCredit\\n*ASSPL-Amazon Seller Services Pvt. Ltd., ARIPL-Amazon Retail India Pvt. Ltd. (only where Amazon Retail India Pvt. Ltd. fulfillment center is co-located)\\nCustomers desirous of availing input GST credit are requested to create a Business account and purchase on Amazon.in/business from Business eligible offers\\nPlease note that this invoice is not a demand for payment\\nPage 1 of 1\\n\"\"\"\n",
    "flipkart_entities=\"\"\"{\n",
    "    \"vendor\": \"Flipkart\",\n",
    "    \"seller\": \"MAHADEV INDUSTRIES\",\n",
    "    \"order number\": \"OD124997541842689000\",\n",
    "    \"order date\": \"21-05-2022\",\n",
    "    \"shipping address\": \"Jina Ghosh,rb 77,rabindranagar,starting from netaji subhash sarani ..end ing with trinomul van toto stand, Madhyamgram - 700132, IN-WB\",\n",
    "    \"invoice number\": \"FAD5K12300015119\", \n",
    "    \"tax amount\": 10.24,\n",
    "    \"total amount\": 215,\n",
    "    \"invoice date\": \"21-05-2022\"\n",
    "}\"\"\"\n",
    "flipkart_text=\"\"\"Sold By\\nTax Invoice Order Id: OD124997541842689000 Invoice No: FAD5K12300015119 GSTIN: 06GQOPK9183C1ZE\\nOrder Date: 21-05-2022, 01:31 PM\\nInvoice Date: 21-05-2022, 01:32 PM PAN: GQOPK9183C\\nShipping ADDRESS\\nBilling Address\\nMAHADEV INDUSTRIES,\\nJina Ghosh,\\nJina Ghosh,\\nSEC 11 NEAR DEVIPURI ROAD MOTHER LAP SCHOOL\\nrb 77,\\nrb 77,\\nPLOT NO A-510 OPP.,, PANIPAT - 132103\\nrabindranagar,\\nrabindranagar,\\nGST: 06GQOPK9183C1ZE\\nstarting from netaji subhash sarani ..end starting from netaji subhash sarani ..ending with\\ning with trinomul van toto stand,\\ntrinomul van toto stand,\\nMadhyamgram - 700132, IN-WB\\nMadhyamgram - 700132, IN-WB\\nProduct\\nDescription\\nQty\\nGross\\nAmount\\nDiscount\\nTaxable\\nValue\\nIGST\\nTotal\\nDakshya Industries Cotton Home Use Apron -\\nFree Size DNtHGJPmaV APRON02 | Black Box\\nCooking 1 A | IMEI/SrNo: [[]]\\nHSN: 57023210 | IGST: 5%\\n1\\n215.00\\n-0.00\\n204.76\\n10.24\\n215.00\\nShipping and Handling\\nCharges\\n1\\n0.00\\n0\\n0.00\\n0.00\\n0.00\\nTOTAL QTY: 1\\nTOTAL PRICE: 215.00\\nAll values are in INR\\nSeller Registered Address: MAHADEV INDUSTRIES,\\nMAHADEV INDUSTRIES, NEW ANAJ MANDI shop no 205 ground floor PANIPAT, PANIPAT - 132103.\\nDeclaration\\nThe goods sold are intended for end user consumption and not for resale.\\nSANJEEV\\nE. & O.E.\\nOrdered Through\\nFlipkart\\nMAHADEV INDUSTRIES\\nAuthorized Signature\\n\"\"\"\n",
    "big_basket_entities=\"\"\"{\n",
    "        \"vendor\": \"big basket\",\n",
    "        \"order id\": \"MKOO-184072690-190521\",   \n",
    "        \"address\": \"Sarbajit Das, 48 pratapgarh ,2nd floor garfa main road Jadavpur, Kolkata, West-Bengal - 700075\",\n",
    "        \"reference number\": \"MKOI-183642813-190521\",\n",
    "        \"invoice date\": \"21 May 2021\",\n",
    "        \"total amount\": 1852.20,\n",
    "        \"cin\": \"U74130KA2010PTC052192\",\n",
    "        \"payment mode\": \"VISA\"\n",
    "}\"\"\"\n",
    "big_basket_text=\"\"\"R\\nI\\nBill to/Ship to:\\nSarbajit Das,\\n48 pratapgarh , 2nd floor\\ngarfa main road\\nb'\\nbig\\nbasket\\nJadavpur, Kolkata, West-Bengal - 700075\\nstate code: 19\\nReference\\nnumber\\nMKOI-183642813-190521\\nInnovative Retail Concepts Pvt Ltd\\nHolding No. 855, Kheyadaha No. 2 Gram\\nPanchayat,\\nPO Uchhepota, Beside Meghnath Saha\\nCollege,\\nSouth 24 Parganas, Kolkata - 700150\\nWest Bengal (19)\\nTel.: 1860 123 1000\\nGSTIN 19AACCI2053A1Z4\\nCIN U74130KA2010PTC052192\\nFSSAI Lic. No: 12820017000232\\nGST Invoice\\nNo\\nWB201-0002463091\\nOrder ID\\nMKOO-184072690-190521\\nDate of Issue\\nMangoes\\nFri 21 May 2021\\nof Invoice\\nSlot\\nFri 21 May 2021 between 12:00 PM and 05:00 PM\\nNow available in\\n7 varieties\\nat best prices.\\nCheck out today.\\nFinal Total\\nRs. 1852.20\\nPayment By\\nVISA\\nSource\\nBigbasket\\nNo of Items\\n18\\nSI Item\\nNo Description\\nHSN\\nCode/\\nSAC\\nQuantity,\\nalong\\nwith\\nunits\\nUnit\\nPrice\\nTotal\\nCGST SGST Value,\\nUnit\\nGross Discount, Delivery Taxable\\nRate Rate\\nfor\\nTax\\nValue*\\nif any*\\nCharge Value (%) (%) supply\\nValue\\nAmount Amount\\ngoods\\nof\\n4.00\\n29.50 25.00 128.00\\n10.00\\n0.00\\n100.0\\n9.0 9.0 9.0 9.0 118.00\\n1.00\\n27.00 22.88\\n30.00\\n3.00\\n0.00\\n22.88\\n27.00\\n9.0\\n2.06\\n9.0\\n2.06\\n1.00\\n130.00 123.80 185.00\\n55.00\\n0.00\\n123.8\\n2.5 3.1 2.5 3.1 130.00\\n1 Bisk Farm 19053290\\nBiscuits Rich\\nMarie, Light &\\nCrunchy,\\nTeatime\\nSnack 300 g\\nPouch\\n2 Sunfeast 19053290\\nMom's Magic\\n- Rich Cashew\\n& Almond\\nCookies 197 g\\n3 BB Royal\\n07139090\\nMasoor Dal 1\\nkg Pouch\\n4 UNIBIC\\n19053290\\nCookies -\\nChoco Chip\\n75 g Pouch\\n5 Parle Hide & 18069090\\nSeek\\nChocolate\\n100 g Pouch\\n6 UNIBIC\\n19053290\\nCookies -\\nFruit & Nut 75\\ng Pouch\\n7 Fresho Garlic 07032000\\nOrganically\\n1.00\\n30.00 25.42\\n30.00\\n0.00\\n25.42\\n30.00\\n9.0\\n2.29\\n9.0\\n2.29\\n4.00\\n28.50 24.16 120.00\\n6.00\\n0.00\\n96.62\\n9.0\\n114.00\\n9.0\\n8.69\\n8.69\\n6.00\\n22.50 19.07 150.00\\n15.00\\n0.00\\n114.4\\n135.00\\n9.0\\n10.3\\n9.0\\n10.3\\n1.06\\n67.00\\n0\\n88.77\\n17.75\\n0.00\\n0 0 0 0 0\\n71.02\\n07099920\\n1.04\\n30.00\\n0\\n70.20\\n39.00\\n0.00\\nGrown 250 g\\n8 Fresho\\nLadies'\\nFingers 1 kg\\n0 0 0 0 0\\n31.20\\n1.04\\n38.00\\n0\\n49.40\\n9.88\\n0.00\\n0\\n0 0\\n0 0\\n39.52\\n1.01\\n25.00\\n0\\n42.93\\n17.68\\n0.00\\n0\\n0 0\\n0 0\\n25.25\\n1.05\\n28.00\\n0\\n59.06\\n29.66\\n0.00\\n0\\n0 0\\n0 0\\n29.40\\n1.00\\n47.00\\n0\\n58.75\\n11.75\\n0.00\\n0 0 0\\n0 0\\n47.00\\n2.16\\n42.00\\n0\\n113.40\\n22.68\\n0.00\\n0 0 0 0 0\\n90.72\\n9 Fresho Ginger 09103010\\nOrganically\\nGrown 250 g\\n10 Fresho Bitter 07099920\\nGourd 500 g\\n11 Fresho Parwal 07099920\\n1 kg\\n12 Fresho\\n07099920\\nAmaranthus -\\nRed Cleaned,\\nWithout Roots\\n1 kg\\n13 Fresho\\n07020000\\nTomato -\\nHybrid,\\nOrganically\\nGrown 1 kg\\n14 Fresho Potato 07019000\\nJyoti -\\nOrganically\\nGrown 1 kg\\n15 Fresho Ridge 07099920\\nGourd 1 kg\\n16 Fresho\\n02045000\\nMutton -\\nCurry Cut,\\nFrom Whole\\nCarcass,\\nAntibiotic\\nResidue-Free,\\n28 To 34 Pcs\\n1 kg\\n17 Fresho Onion 07031010\\n5.49\\n25.00\\n0\\n171.56\\n34.31\\n0.00\\n0 0 0 0 0\\n137.25\\n1.09\\n36.00\\n0\\n94.01\\n54.77\\n0.00\\n0 0 0 0 0\\n39.24\\n1.00\\n549.00\\n0\\n1099.00\\n550.00\\n0.00\\n0\\n0 0\\n0 0\\n549.00\\n1.06\\n60.00\\n0\\n79.50\\n15.90\\n0.00\\n0\\n0 0\\n0 0\\n63.60\\n2 kg\\n04071990\\n1.00\\n175.00\\n0\\n189.00\\n14.00\\n0.00\\n0 0 0 0 0\\n175.00\\n18 Fresho Farm\\nEggs - Table\\nTray,\\nMedium,\\nAntibiotic\\nResidue-Free\\n30 pcs\\nTotal\\nRs.\\n1852.2\\n* Includes GST component\\nTotal invoice value (In Figure) : Rs. 1852.20\\nTotal invoice value (In Words) : Rs. One Thousand, Eight Hundred And Fifty-Two Point Two Zero\\nSignature\\nAs per Section 31 of CGST Act read with Rules, invoice is issued at the point of delivering the goods\\nDigitally signed by: VIPUL MAHENDRA PAREKH\\nDN: VIPUL MAHENDRA PAREKH\\nVIPUL MAHENDRA PAREKH Company: INNOVATIVE RETAIL CONCEPTS PRIVATE LIMITED\\nLocation: Karnataka\\nDate: Fri Aug 18 04:18:06 UTC 2023\\n\"\"\"\n",
    "hathway_entities=\"\"\"{\n",
    "\t\"vendor\": \"hathway\",\n",
    "\t\"account number\": \"1183117411\",\n",
    "\t\"address\": \"48, PRATAPGAR 3RD FLOOR, NEAR LOKENATH MANDIR GARFA KOLKATA,SANTOSHPUR,SANTOSHPUR,,SANTOSHPUR,SANTOSHPUR KOLKATA WEST BENGAL - 700075\",\n",
    "\t\"invoice number\": \"I0119P2408002193\",\n",
    "\t\"invoice date\": \"05-AUG-23\",\n",
    "\t\"total amount\": 608,\n",
    "\t\"tax amount\": 92.70,\n",
    "\t\"cin\": \"L64204MH1959PLC011421\"\n",
    "}\"\"\"\n",
    "hathway_text=\"\"\"hathw@y\\nTAX INVOICE\\nBroadband Internet\\n(Under Rule 46 of the CGST Rules 2017)\\n(ORIGINAL FOR RECIPIENT / DUPLICATE FOR SUPPLIER)\\nPAN: AAACC6814B\\nGSTIN: 19AAACC6814B1Z1\\nCIN: L64204MH1959PLC011421\\nBILLING ADDRESS\\nINVOICE DETAILS\\n✓ INSTALLATION ADDRESS\\nSARBAJIT DAS\\n48, PRATAPGAR 3RD FLOOR, NEAR LOKENATH MANDIR GARFA\\nKOLKATA,SANTOSHPUR, SANTOSHPUR, SANTOSHPUR, SANTOSHPUR\\nKOLKATA WEST BENGAL - 700075\\nACCOUNT NOS.\\nSARBAJIT DAS\\n48, PRATAPGAR 3RD FLOOR, NEAR LOKENATH MANDIR GARFA\\nKOLKATA, SANTOSHPUR, SANTOSHPUR, SANTOSHPUR, SANTOSHPUR\\nKOLKATA WEST BENGAL - 700075\\n1183117411\\nDEVICE\\n: ZTEGC45ED020\\nINVOICE NO.\\n: 10119P2408002193\\nCONTACT NO\\n: 8017669963\\nINVOICE DATE\\n: 05-AUG-23\\nEMAIL\\nsarbajitdas08@gmail.com\\nCONTACT PERSON\\n:\\nTECHNOLOGY\\n: GPON\\nCONTACT NO\\n: 8017669963\\nCUSTOMER STATE CODE: 19 - WEST BENGAL\\nPLACE OF SUPPLY\\n: 19-WEST BENGAL\\nCONTACT PERSON\\n:\\nCHARGE DETAILS\\nPackage\\nHSN/SAC\\nTransaction Date\\nPeriod\\nCharges\\nDiscount\\nNet Charges\\n998422\\n05-AUG-23\\n05-AUG-23-04-SEP-23\\n500.00\\n0.00\\n500.00\\nGPON_RTN_HERO_ULTD_KOL_PRE_40MBPS_MTHLY -\\nSubscription Charges\\nPREPAID MONTHLY AMC PLAN FOR DCM - CPE Charges\\n998716\\n05-AUG-23\\n05-AUG-23-04-SEP-23\\n15.00\\n0.00\\n15.00\\nTotal Charges\\n515.00\\nCGST (9%)\\n46.35\\nSGST (9%)\\n46.35\\nCurrent Total\\n607.70\\nCurrent Total (Round off)\\n608\\nCurrent Total (In Words)\\nRupees Six Hundred Eight Only\\nFor HATHWAY CABLE AND DATACOM LIMITED\\n• Payment Modes - Pay online using debit/credit card/UPI, Netbanking on www.hathway.com,\\nMobile APP\\nAll cheque payments to be made in favor of \"HATHWAY CABLE AND DATACOM LIMITED\"\\nThis invoice is issued without any prejudice to our rights to claim previous outstanding if any\\nNature of Services - Internet Telecom Services (automated should be based HSN)\\nTax on Reverse Charge - Not Applicable\\n• Subject to MUMBAI jurisdiction\\nFor any Billing, Renewals or Technical queries Call on 3340302444 mail on\\nkolkatahelpdesk@hathway.net\\nFor any Technical assistance mail on kolkatahelpdesk@hathway.net\\nLate Fee Charges : Please make payment by due date to avoid charging of late fees\\n• Outstanding ( <Rs.2000: Rs 50+GST) (between 2000-5000 : Rs 100+GST) (>Rs 5000 : Rs\\n200+GST)\\nDigitally signed by\\nRATNADEEP\\nBHATTACHARJEZ\\n2023.08.18 09:34:20 IST\\nAuthorised Signatory\\n(Digital Signature)\\nSystem Generated QR Code\\nREMITTANCE SLIP (To be filled by Customer)\\nMODE OF PAYMENT\\nACCOUNT NO.\\n(CASH/CHEQUE/DD/ONLINE)\\nDATE\\nNAME OF BANK\\nINSTRUMENT NUMBER\\nAMOUNT (RS.)\\n1183117411\\nOfficial Use Only\\nDate Received\\nSignature & Stamp\\nHATHWAY CABLE AND DATACOM LIMITED\\nPAY NOW\\nHATHWAY CABLE AND DATACOM LIMITED\\nGST - State Registered Address : PLOT NO. 7,ECOSTATION, 2ND FLOOR, SECTOR-V, BLOCK - BP, SALT LAKE, SECH BHAWAN Kolkata-700091,\\nWest Bengal, IN\\nRegistered Address : 805 806, Windsor, Off C S T Road, Kalina Santacruz E, Mumbai-400098, Maharashtra, India\\nSwitch to the easiest way to resolve\\nall your Broadband queries with DIVA\\nScan the QR code to\\ndownload the App\\n\"\"\"\n",
    "aliance_entities=\"\"\"{\n",
    "\t\"vendor\": \"Alliance Broadband Services Pvt. Ltd.\",\n",
    "\t\"invoice number\": \"0020118023\",\n",
    "\t\"invoice date\": \"02.05.2022\",\n",
    "\t\"expiry date\": \"31.05.2022\",\n",
    "\t\"address\": \"RABINDRA NAGAR, MADHYAMGRAM, NORTH 24 PARGANAS, WEST BENGAL, KOLKATA-700132\",\n",
    "\t\"total amount\": 590,\n",
    "\t\"tax amount\": 90,\n",
    "\t\"cin\": \"U72900WB2003PTC095621\"\n",
    "}\"\"\"\n",
    "aliance_text=\"\"\"TAX INVOICE\\nORIGINAL for RECIPIENT\\nNo:-0020118023 | Issue Date 02.05.2022\\nAlliance Broadband Services Pvt. Ltd.\\nCity: Kolkata\\nAddress: P-31, Nani Gopal Roy Chowdhury Avenue, Kolkata - 700014\\nPAN NO: AAECA3151B\\nGST No: 19AAECA3151B1Z7\\nState: West Bengal code: 19\\nCIN No: U72900WB2003PTC095621\\nSAC No: 998422\\nPhone: 033-71002000, Toll Free No: 1800 1200 300 www.alliancebroadband.co.in\\nTO: JINA GHOSH\\nAddress: RABINDRA NAGAR, MADHYAMGRAM, NORTH 24 PARGANAS, WEST BENGAL, KOLKATA-700132 8670185721\\nState: West Bengal code: 19\\namount\\nN Description of goods or services\\n1 fee \"STARTER\" (02.05.2022 to 31.05.2022)\\n500.000\\nTOTAL AMOUNT\\n500.00\\nCGST (9%)\\n45.00\\nSGST (9%)\\n45.00\\nTOTAL\\n590.00\\nRounded off\\n590.00\\nIN WORDS: INR Five hundred and ninety rupee\\nPayment method: () Cheque () D.D/P.O. ( Cash\\nDate of occurrence of chargeable event /payment: 02.05.2022 / 02.05.2022\\nTERMS AND CONDITIONS\\n1) It will be deemed that you have accepted this Invoice in full in the event you have not lodged any written objection with us within 20 days of receipt of this Invoice.\\n2) To avoid disconnection of service you are requested to pay the full amount by the due date mentioned in the invoice. An interest of 18% per annum will be charged on the amount\\nremaining unpaid after the due date.\\n3) All Cheques/Demand Drafts in payment of Invoice should be drawn in favour of \"Alliance Broadband Services Pvt. Ltd.\".\\n4) Kindly mention invoice number along with your payment to ensure correct and timely processing.\\n5) Cheque Return Charges of Rs. 250 would be charged extra.\\n6) E-Invoice will be generated within 48 hours, wherever applicable.\\n7) E. & O. E.\\nIssuer: ******ONLINE PAYMENT******\\nReceiver:\\nClient ID: 12984187136\\nAuthorised Signatory:\\nJumidra kr. Shesh\\nAuthorised Signatory\\nAdditional user details: Username: jg122_svc\\nIP Address: 172.16.252.122\\nZone: Sky Vision Cable Network\\nTAX INVOICE No.0020118023 Date 02.05.2022 Page 1 from 1\\nGenerated by IPACCT IPBill 4.07 (www.ipacct.com)\\nPAYMENT DETAILS: (Please Tick) Mode of Payment\\nCheque/DD No. Name of the Bank\\nREMITTANCE SLIP\\n( Cheque ( ) Demand draft\\nBranch\\n( ) Cash\\nDate\\nAmount(Rs.)\\n590.00\\nUser ID jg122_svc\\nInvoice No.:\\n0020118023\\nCustomer\\'s name JINA GHOSH\\nInvoice Date\\nExpiry Date\\n02.05.2022\\n31.05.2022\\nCustomer\\'s Signature_\\nChannel Partner\\'s Seal\\n\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e067fa8",
   "metadata": {},
   "source": [
    "# method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c7d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt_extract_entity(folder_path):\n",
    "    vendor=folder_path.split('/')[6]\n",
    "    pdf_files = [file for file in os.listdir(folder_path) if file.endswith(\".pdf\")]\n",
    "    documents = []\n",
    "    v={}\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    for file in tqdm(pdf_files):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        reader = PdfReader(file_path)\n",
    "        # read data from the file and put them into a variable called raw_text\n",
    "        raw_text = ''\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                raw_text += text\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator = \"\\n\",\n",
    "            chunk_size = 1000,\n",
    "            chunk_overlap  = 200,\n",
    "            length_function = len,\n",
    "        )\n",
    "        texts = text_splitter.split_text(raw_text)\n",
    "        docsearch = FAISS.from_texts(texts, embeddings)\n",
    "        chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
    "        #define System Role\n",
    "        system_role=\"Extract entities and their values as a key-value pair from the provided OCR text also with\\\n",
    "        the same key  with example_entities\"\n",
    "        #Get The Response\n",
    "        if vendor=='amazon':\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=[\n",
    "                    {\"role\":\"system\",\"content\":system_role},\n",
    "                    {\"role\":\"user\",\"content\":amazon_text},\n",
    "                    {\"role\":\"assistant\",\"content\":amazon_entities},\n",
    "                    {\"role\":\"user\",\"content\":raw_text} #pass the OCR Text obtained from Amazon Textract\n",
    "                ]\n",
    "            )\n",
    "        elif vendor=='flipkart':\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=[\n",
    "                    {\"role\":\"system\",\"content\":system_role},\n",
    "                    {\"role\":\"user\",\"content\":flipkart_text},\n",
    "                    {\"role\":\"assistant\",\"content\":flipkart_entities},\n",
    "                    {\"role\":\"user\",\"content\":raw_text} #pass the OCR Text obtained from Amazon Textract\n",
    "                ]\n",
    "            )\n",
    "        elif vendor=='hathway':\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=[\n",
    "                    {\"role\":\"system\",\"content\":system_role},\n",
    "                    {\"role\":\"user\",\"content\":hathway_text},\n",
    "                    {\"role\":\"assistant\",\"content\":hathway_entities},\n",
    "                    {\"role\":\"user\",\"content\":raw_text} #pass the OCR Text obtained from Amazon Textract\n",
    "                ]\n",
    "            )\n",
    "        elif vendor=='big_basket':\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=[\n",
    "                    {\"role\":\"system\",\"content\":system_role},\n",
    "                    {\"role\":\"user\",\"content\":big_basket_text},\n",
    "                    {\"role\":\"assistant\",\"content\":big_basket_entities},\n",
    "                    {\"role\":\"user\",\"content\":raw_text} #pass the OCR Text obtained from Amazon Textract\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=[\n",
    "                    {\"role\":\"system\",\"content\":system_role},\n",
    "                    {\"role\":\"user\",\"content\":aliance_text},\n",
    "                    {\"role\":\"assistant\",\"content\":aliance_entities},\n",
    "                    {\"role\":\"user\",\"content\":raw_text} #pass the OCR Text obtained from Amazon Textract\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        res=response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        v[file]=res   \n",
    "    return v\n",
    "def remove_extra_spaces_from_keys_values(input_dict):\n",
    "    cleaned_dict = {}\n",
    "    for key, value in input_dict.items():\n",
    "        cleaned_key = key.strip().replace(' :',':').lower()\n",
    "        cleaned_key = ' '.join(cleaned_key.split())  # Removes extra spaces within the key\n",
    "        cleaned_dict[cleaned_key] = value.strip()\n",
    "    return cleaned_dict\n",
    "def final_output_chatgpt(ground_truth,output):\n",
    "    z=pd.DataFrame()\n",
    "    #ground_truth=remove_extra_spaces_from_keys_values(ground_truth)\n",
    "    #output=remove_extra_spaces_from_keys_values(output)\n",
    "    for key in output.keys():\n",
    "        if key in ground_truth:\n",
    "            res1 = ast.literal_eval(ground_truth[key])\n",
    "            res2 =ast.literal_eval(output[key])\n",
    "            total_entities = len(res1)\n",
    "            correct_predictions = 0\n",
    "            for entity, gt_value in res2.items():\n",
    "                #gt_value=remove_special_characters(gt_value)\n",
    "                if entity in res1:\n",
    "                        pred_value = res1[entity]\n",
    "                       # pred_value = remove_special_characters(pred_value)\n",
    "                        if gt_value == pred_value:\n",
    "                            correct_predictions += 1\n",
    "                else: \n",
    "                    pass\n",
    "\n",
    "            accuracy = round((correct_predictions / total_entities) * 100,0)\n",
    "            z=z.append({'file_name': key,'ground_truth':[res1],'chatgpt response':[res2],'accuracy':accuracy},ignore_index=True)\n",
    "    return z\n",
    "def chatgpt_llm_response(main_folder_path):\n",
    "    dataframes_list=[]\n",
    "    # Get a list of subfolders\n",
    "    subfolder_list = [os.path.join(main_folder_path, subfolder) for subfolder in os.listdir(main_folder_path) if os.path.isdir(os.path.join(main_folder_path, subfolder))]\n",
    "    #print(subfolder_list)\n",
    "    # #print the list of subfolder paths\n",
    "    for subfolder_path in subfolder_list:\n",
    "        c=chatgpt_extract_entity(subfolder_path)\n",
    "        output=final_output_chatgpt(ground_truth,c)\n",
    "        dataframes_list.append(output)\n",
    "    concatenated_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "\n",
    "\n",
    "#roberta invoice processing\n",
    "def load_model():\n",
    "    model_name = \"deepset/roberta-base-squad2\"\n",
    "    # a) Get predictions\n",
    "    nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "    # b) Load model & tokenizer\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return nlp\n",
    "def get_qstn(vendor):\n",
    "    if vendor=='amazon':\n",
    "        qstn_json=json.loads(amazon_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    elif vendor=='flipkart':\n",
    "        qstn_json=json.loads(flipkart_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    elif vendor=='hathway':\n",
    "        qstn_json=json.loads(hathway_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    elif vendor=='aliance': \n",
    "        qstn_json=json.loads(aliance_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    else:\n",
    "        qstn_json=json.loads(big_basket_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    x=[]\n",
    "    for i,v in qstn_json.items():\n",
    "        b=\"what is the \"+str(i)+\"?\"\n",
    "        x.append(b)\n",
    "    return x ,c \n",
    "def roberta_extraxt_entity(folder_path):\n",
    "    vendor=folder_path.split('/')[7]\n",
    "    pdf_files = [file for file in os.listdir(folder_path) if file.endswith(\".pdf\")]\n",
    "    v={}\n",
    "    qstn=get_qstn(vendor)[0]\n",
    "    output=get_qstn(vendor)[1]\n",
    "    for file in tqdm(pdf_files):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        nlp=load_model()\n",
    "        reader = PdfReader(file_path)\n",
    "        # read data from the file and put them into a variable called raw_text\n",
    "        raw_text = ''\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                raw_text += text \n",
    "        k=[]    \n",
    "        for q in tqdm(qstn):\n",
    "            QA_input = {'question': q,'context':raw_text}\n",
    "            res = nlp(QA_input)\n",
    "            res=remove_special_characters_roberta(res['answer'])\n",
    "            k.append(res)\n",
    "        v[file]=k\n",
    "    c={}\n",
    "    for k,j in v.items():\n",
    "        n=replace_dict_values_with_list_items(output,j)\n",
    "        c[k]=n\n",
    "    return c\n",
    "def remove_special_characters_roberta(input_string):\n",
    "    # Define a regex pattern to match any non-alphanumeric character\n",
    "    #pattern = r'[^a-zA-Z0-9\\s]' \n",
    "    # Use the sub() function to replace the matched pattern with an empty string\n",
    "    #cleaned_string = re.sub(pattern, '', str(input_string)) \n",
    "    cleaned_string = input_string.strip('\\n') \n",
    "    return cleaned_string\n",
    "def final_output_roberta(ground_truth,output):\n",
    "    z=pd.DataFrame()\n",
    "    for key in output.keys():\n",
    "        if key in ground_truth:\n",
    "            res1 = ast.literal_eval(ground_truth[key])\n",
    "            res2 = output[key]\n",
    "            total_entities = len(res1)\n",
    "            correct_predictions = 0\n",
    "            for entity, gt_value in res2.items():\n",
    "                if entity in res1:\n",
    "                        pred_value = res1[entity]\n",
    "                        #pred_value=remove_special_characters_roberta(pred_value)\n",
    "                        if gt_value == pred_value:\n",
    "                            correct_predictions += 1\n",
    "                else: \n",
    "                    pass\n",
    "                    \n",
    "            accuracy = round((correct_predictions / total_entities) * 100,0)\n",
    "            z=z.append({'file_name': key,'ground_truth':[res1],'roberta response':[res2],'accuracy':accuracy},ignore_index=True)\n",
    "            ##print(z)\n",
    "    return z\n",
    "#print(remove_special_characters(data))\n",
    "def roberta_llm_response(main_folder_path):\n",
    "    dataframes_list=[]\n",
    "    # Get a list of subfolders\n",
    "    subfolder_list = [os.path.join(main_folder_path, subfolder) for subfolder in os.listdir(main_folder_path) if os.path.isdir(os.path.join(main_folder_path, subfolder))]\n",
    "    # ##print the list of subfolder paths\n",
    "    for subfolder_path in subfolder_list:\n",
    "        c=roberta_extraxt_entity(subfolder_path)\n",
    "        output=final_output_roberta(ground_truth,c)\n",
    "        dataframes_list.append(output)\n",
    "    concatenated_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "\n",
    "#docquery\n",
    "def gv_doc_ai_data_extractor(file_path,doctype):\n",
    "    \n",
    "    url_address = \"https://uipathmldev.corp.uber.com\"\n",
    "    #url_address = \"http://127.0.0.1:5000\"\n",
    "    # url_address = http://DCA1-UP-ML-P01\n",
    "    # url_address = \"http://dca1-ic-d-aby01:5000/iacoe_ocr/doc-ai/data_extractor\"\n",
    "    ENDPOINT = '/iacoe_ocr/doc-ai/data_extractor_v1'\n",
    "    url = url_address + ENDPOINT\n",
    "   \n",
    "    with open(file_path, 'rb')as file_obj:\n",
    "        file = file_obj.read()\n",
    "    file_base64 = base64.b64encode(file)\n",
    "\n",
    "    payload = {'file_base64': file_base64,\n",
    "               'doctype':doctype,\n",
    "    }\n",
    "    response = requests.post(url, data=payload, verify=False)\n",
    "    ###print(response)\n",
    "    json_data = json.loads(response.text.encode('utf-8'))\n",
    "    doc_ai_base64 = json_data['success']\n",
    "    \n",
    "    doc_ai_base64 = eval(doc_ai_base64)\n",
    "    \n",
    "    doc_ai_bytes = base64.b64decode(doc_ai_base64)\n",
    "    doc_ai_json = json.loads(doc_ai_bytes)\n",
    "    return doc_ai_json\n",
    "def local_json_output(DATASET_INP_PATH):\n",
    "    dirs = os.listdir(DATASET_INP_PATH)\n",
    "    ##print(dirs)\n",
    "    doctype = 'p2p_invoice_trials'\n",
    "    data_files = {}\n",
    "    for class_folder in dirs:\n",
    "        if class_folder!=\".DS_Store\":\n",
    "            class_folder_path = os.path.join(DATASET_INP_PATH, class_folder)\n",
    "            files=glob.glob(class_folder_path+'/*.pdf')\n",
    "            try:\n",
    "                for i,doc_path in enumerate(files):\n",
    "                    filenames=doc_path.split('/')[-1][:-4]\n",
    "                    t1 = time.time()\n",
    "                    doc_ai_json= gv_doc_ai_data_extractor(doc_path,doctype)\n",
    "                    f_ext=\".json\"\n",
    "                    new_name = f'{filenames}{f_ext}'\n",
    "                    with open(os.path.join(class_folder_path,new_name),'w') as f:  \n",
    "                        json.dump(str(doc_ai_json), f, indent = 6)    \n",
    "            except:\n",
    "                pass\n",
    "            return None\n",
    "def data_extraction(dictionary):\n",
    "    return [dictionary['raw_text']],dictionary['pages'][0]['forms_data']\n",
    "def form_field_extraction(row):\n",
    "    z={}\n",
    "    for i in row:\n",
    "        z[i['fieldName'].replace('\\n','').strip()]=i['fieldValue'].replace('\\n','').strip()\n",
    "    return z\n",
    "def concatenated_output(subfolder_path):\n",
    "    files=glob.glob(subfolder_path+'/*.json')\n",
    "    documents = []\n",
    "    v={}\n",
    "    dataset = []\n",
    "    for filepath in files:\n",
    "        if filepath != \".DS_Store\":\n",
    "            with open(filepath, 'r') as f:\n",
    "                raw_json = eval(json.loads(f.read()))\n",
    "            class_folder=filepath.split('/')[-2]\n",
    "            data=[filepath.split('/')[-1],raw_json,class_folder]\n",
    "            dataset.append(data)\n",
    "    return dataset\n",
    "def remove_special_characters_docquery(input_string):\n",
    "    # Define a regex pattern to match any non-alphanumeric character\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    \n",
    "    # Use the sub() function to replace the matched pattern with an empty string\n",
    "    cleaned_string = re.sub(pattern, '', str(input_string))\n",
    "    \n",
    "    return cleaned_string\n",
    "def replace_dict_values_with_list_items(dictionary, lst):\n",
    "    replaced_dict = {}\n",
    "    list_index = 0\n",
    "    for key in dictionary:\n",
    "        replaced_dict[key] = lst[list_index]\n",
    "        list_index += 1\n",
    "    return replaced_dict\n",
    "def output_all_vendor(DATASET_INP_PATH):\n",
    "    dataframes_list=[]\n",
    "    # Get a list of subfolders\n",
    "    subfolder_list = [os.path.join(DATASET_INP_PATH, subfolder) for subfolder in os.listdir(DATASET_INP_PATH) if os.path.isdir(os.path.join(DATASET_INP_PATH, subfolder))]\n",
    "    # ##print the list of subfolder paths\n",
    "    for subfolder_path in subfolder_list:\n",
    "        x=dataframe_output(subfolder_path)\n",
    "        df1 = pd.DataFrame(x, columns=['class_folder_path', 'raw_json', 'class_pred'])\n",
    "        df1['raw_text']=df1['raw_json'].map(lambda s:data_extraction(s)[0])\n",
    "        df1['forms_data']=df1['raw_json'].map(lambda s:data_extraction(s)[1])\n",
    "        df1['google_ocr_response']=df1['forms_data'].apply(lambda row : form_field_extraction(row))\n",
    "        dataframes_list.append(df1)\n",
    "    concatenated_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "    return concatenated_df\n",
    "def get_qstn_docquery(vendor):\n",
    "    if vendor=='amazon':\n",
    "        qstn_json=json.loads(amazon_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    elif vendor=='flipkart':\n",
    "        qstn_json=json.loads(flipkart_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    elif vendor=='hathway':\n",
    "        qstn_json=json.loads(hathway_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    elif vendor=='aliance':  \n",
    "        qstn_json=json.loads(aliance_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    else:\n",
    "        qstn_json=json.loads(big_basket_entities)\n",
    "        output_json=list(qstn_json.keys())\n",
    "        c={}\n",
    "        for i in output_json:\n",
    "            c[i]=\" \"\n",
    "    x=[]\n",
    "    for i,v in qstn_json.items():\n",
    "        b=\"what is the \"+str(i)+\"?\"\n",
    "        x.append(b)\n",
    "    return x ,c \n",
    "def docquery_extraxt_entity(folder_path):\n",
    "    vendor=folder_path.split('/')[6]\n",
    "    pdf_files = [file for file in os.listdir(folder_path) if file.endswith(\".pdf\")]\n",
    "    p = pipeline('document-question-answering',model=\"impira/layoutlm-document-qa\")\n",
    "    documents = []\n",
    "    v={}\n",
    "    qstn=get_qstn_docquery(vendor)[0]\n",
    "    output=get_qstn_docquery(vendor)[1]\n",
    "    for file in tqdm(pdf_files):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        doc = document.load_document(file_path)\n",
    "        k=[]    \n",
    "        for q in tqdm(qstn):\n",
    "            result=p(question=q, **doc.context)\n",
    "            k.append(result[0]['answer'])\n",
    "        v[file]=k\n",
    "    c={}\n",
    "    for k,j in v.items():\n",
    "        n=replace_dict_values_with_list_items(output,j)\n",
    "        c[k]=n\n",
    "    return c\n",
    "def final_output_docquery(ground_truth,output):\n",
    "    z=pd.DataFrame()\n",
    "    for key in output.keys():\n",
    "        if key in ground_truth:\n",
    "            res1 = ast.literal_eval(ground_truth[key])\n",
    "            res2 = output[key]\n",
    "            total_entities = len(res1)\n",
    "            correct_predictions = 0\n",
    "            for entity, gt_value in res2.items():\n",
    "                gt_value=remove_special_characters_docquery(gt_value)\n",
    "                if entity in res1:\n",
    "                        pred_value = res1[entity]\n",
    "                        pred_value = remove_special_characters_docquery(pred_value)\n",
    "                        if gt_value == pred_value:\n",
    "                            correct_predictions += 1\n",
    "                else: \n",
    "                    pass                   \n",
    "            accuracy = round((correct_predictions / total_entities) * 100,0)\n",
    "            z=z.append({'file_name': key,'ground_truth':[res1],'docquery response':[res2],'accuracy':accuracy},ignore_index=True)\n",
    "    return z\n",
    "\n",
    "def docquery_llm_response(main_folder_path):\n",
    "    dataframes_list=[]\n",
    "    # Get a list of subfolders\n",
    "    subfolder_list = [os.path.join(main_folder_path, subfolder) for subfolder in os.listdir(main_folder_path) if os.path.isdir(os.path.join(main_folder_path, subfolder))]\n",
    "    # #print the list of subfolder paths\n",
    "    for subfolder_path in subfolder_list:\n",
    "        c=docquery_extraxt_entity(subfolder_path)\n",
    "        output=final_output_docquery(ground_truth,c)\n",
    "        dataframes_list.append(output)\n",
    "    concatenated_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e42dc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/jghosh2/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.openai.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/jghosh2/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.openai.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:19<00:00, 19.63s/it]\n",
      "<ipython-input-34-cd2e1b8457d5>:111: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  z=z.append({'file_name': key,'ground_truth':[res1],'chatgpt response':[res2],'accuracy':accuracy},ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#replace api key\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "\n",
    "df2=pd.read_csv('/Users/jghosh2/Desktop/INVOICES_NEW/evolution/Invoices_Ground _Truth-Sheet1.csv')\n",
    "ground_truth = dict(zip(df2['Filename'], df2['Ground_Truth ']))\n",
    "# Provide the path to the pdf you want to process\n",
    "main_folder_path_testing=r'/Users/jghosh2/Desktop/INVOICES_NEW/data/Testing'\n",
    "main_folder_path='/Users/jghosh2/Desktop/INVOICES_NEW/data/invoice_sample_non_uber'\n",
    "# Perform OCR on the image\n",
    "chatgpt_llm_response=chatgpt_llm_response(main_folder_path_testing)\n",
    "#roberta_llm_response=roberta_llm_response(main_folder_path)\n",
    "#docquery_llm_response=docquery_llm_response(main_folder_path)\n",
    "#final_evolution=pd.concat([chatgpt_llm_response,roberta_llm_response,docquery_llm_response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3508e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>chatgpt response</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OD126043904080329000.pdf</td>\n",
       "      <td>[{'vendor': 'Flipkart', 'seller': 'AVIK CREATI...</td>\n",
       "      <td>[{'order id': 'OD126043904080329000', 'order d...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name  \\\n",
       "0  OD126043904080329000.pdf   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  [{'vendor': 'Flipkart', 'seller': 'AVIK CREATI...   \n",
       "\n",
       "                                    chatgpt response  accuracy  \n",
       "0  [{'order id': 'OD126043904080329000', 'order d...      11.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b1a0483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'order id': 'OD126043904080329000',\n",
       "  'order date': '19-09-2022, 04:05 PM',\n",
       "  'invoice number': 'FADMLV2300002224',\n",
       "  'invoice date': '19-09-2022, 04:06 PM',\n",
       "  'gstin': '19DBEPP5071G1ZF',\n",
       "  'pan': 'DBEPP5071G',\n",
       "  'sold by': 'AVIK CREATIONS',\n",
       "  'billing address': 'Jina Ghosh, rb 77, rabindranagar, starting from netaji subhash sarani ..ending with trinomul van toto stand, Madhyamgram - 700132, IN-WB',\n",
       "  'shipping address': 'Jina Ghosh, rb 77, rabindranagar, starting from netaji subhash sarani ..ending with trinomul van toto stand, Madhyamgram - 700132, IN-WB',\n",
       "  'total quantity': 1,\n",
       "  'total price': 736.0,\n",
       "  'product description': 'Avik Creations Printed, Self Design, Paisley, Temple Border, Embroidered, Striped, Woven, Embellished, Applique, Polka Print, Floral Print, Solid/Plain Assam Silk Handloom Tussar Silk, Silk Blend Saree -1',\n",
       "  'taxable value': 700.96,\n",
       "  'cgst': 17.52,\n",
       "  'sgst/utgst': 17.52}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_llm_response['chatgpt response'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7006580d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'vendor': 'Flipkart',\n",
       "  'seller': 'AVIK CREATIONS',\n",
       "  'order number': 'OD126043904080329000',\n",
       "  'order date': '19-09-2022',\n",
       "  'shipping address': 'Jina Ghosh,rb 77,rabindranagar,starting from netaji subhash sarani ..end ing with trinomul van toto stand, Madhyamgram - 700132, IN-WB',\n",
       "  'invoice number': 'FADMLV2300002224',\n",
       "  'invoice date': '19-09-2022',\n",
       "  'total amount': 736,\n",
       "  'tax amount': 35.04}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_llm_response['ground_truth'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67de3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d45301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d92da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac65cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51380c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f4daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b41c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
