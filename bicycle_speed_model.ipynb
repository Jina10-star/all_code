{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Thanks for using Drogon for your interactive Spark application. We update Drogon/SparkMagic as often as possible to make it easier, faster and more reliable for you. Have a question or feedback? Ping us on [uChat](https://uchat.uberinternal.com/uber/channels/spark).</span>\n",
    "\n",
    "What's New\n",
    "- Now you can use `%%configure` and `%%spark` magics to configure and start a Spark session (deprecating hard-to-use `%load_ext sparkmagic.magics` and `manage_spark` magics). Check out [this example](https://workbench.uberinternal.com/explore/knowledge/localfile/cwang/sparkmagic_python2_example.ipynb) for more details.\n",
    "- Improved `%%configure` magic. You now can use it to make all Spark and Drogon configurations from within notebook itself. Check out our [latest documentation & examples](https://docs.google.com/document/d/1mkYtDHquh4FjqTeA0Fxii8lyV-P6qzmoABhmmRwm_00/edit#heading=h.xn14pmoorsn0) for more details.\n",
    "- Bug fixes and performance updates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Configuration\n",
    "\n",
    "%%configure -f\n",
    "{\n",
    "  \"pyFiles\": [], \n",
    "  \"kind\": \"pyspark\", \n",
    "  \"proxyUser\": \"dhruven.vora\", \n",
    "  \"sparkEnv\": \"SPARK_24\",\n",
    "  \"queue\": \"maps-popularity-routing\",\n",
    "  \"numExecutors\": 1000,\n",
    "  \"driverMemory\": \"12g\",\n",
    "  \"executorMemory\": \"12g\",\n",
    "  \"driverCores\": 4,\n",
    "  \"executorCores\": 1, \n",
    "  \"jars\": [], \n",
    "  \"conf\": {\n",
    "    \"spark.executor.memoryOverhead\": \"3g\",\n",
    "    \"spark.driver.memoryOverhead\": \"3g\",\n",
    "    \"spark.driver.maxResultSize\": \"10g\",\n",
    "    \"hive.exec.dynamic.partition\": \"true\",\n",
    "    \"hive.exec.dynamic.partition.mode\": \"nonstrict\",\n",
    "    \"spark.locality.wait\": \"6s\",\n",
    "    \"spark.maxRemoteBlockSizeFetchToMem\": \"200m\",\n",
    "    \"spark.driver.extraJavaOptions\": \"-XX:+UseCompressedOops -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps\",\n",
    "    \"spark.executor.extraJavaOptions\": \"-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=35 -XX:ConcGCThreads=6 -XX:+UseCompressedOops -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC\",\n",
    "    \"spark.sql.autoBroadcastJoinThreshold\":-1\n",
    "    }, \n",
    "  \"drogonHeaders\": {\n",
    "    \"X-DROGON-CLUSTER\": \"PHX2/Secure\"  \n",
    "  }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load segment speeds for bicycles on tomtom data\n",
    "## start date: 2021-10-03\n",
    "## end date: 2021-10-31\n",
    "segments = spark.sql(\"\"\"\n",
    " with all_data as (\n",
    "\n",
    " SELECT \n",
    "        msg.classification, \n",
    "        msg.durationms*1.0/1000 as durations,\n",
    "        msg.graphsegment.segmentuuid,\n",
    "        msg.graphsegment.startjunctionuuid,\n",
    "        msg.graphsegment.endjunctionuuid,\n",
    "        msg.segmentfeature.roadclass,\n",
    "        msg.latitude,\n",
    "        msg.longitude,\n",
    "        msg.jobuuid,\n",
    "        msg.supplyuuid,\n",
    "        msg.tasktype,\n",
    "        (case when msg.speedkmph < 1 then 1 when msg.speedkmph > 150 then 150 else msg.speedkmph end)*1.0/3.6 as speedms,\n",
    "        msg.lengthmeters,\n",
    "        msg.cityid\n",
    "\n",
    "    FROM \n",
    "        rawdata_user.kafka_hp_maps_historical_streaks_tomtom_nodedup\n",
    "        where 1=1\n",
    "        and datestr between '2022-04-04' and '2022-05-02'\n",
    "        and msg.classification = 'valid'\n",
    "        and msg.vehicletype = 'BICYCLE'\n",
    "        and msg.lengthmeters > 0\n",
    "        and msg.speedkmph > 0\n",
    ")\n",
    "\n",
    ", segments as (\n",
    "SELECT \n",
    "startjunctionuuid\n",
    ",segmentuuid\n",
    ",endjunctionuuid\n",
    ",avg(latitude) as latitude\n",
    ",avg(longitude) as longitude\n",
    ",LEAST(72,GREATEST(1,count(*)/sum(1/speedms))) as harmonic_mean_ms\n",
    "from all_data\n",
    "group by segmentuuid,startjunctionuuid,endjunctionuuid\n",
    "having count(*) >= 5\n",
    ")\n",
    "select * from segments\n",
    "\"\"\")\n",
    "segments.cache()\n",
    "segments.createOrReplaceTempView(\"segments\")\n",
    "spark.sql(\"\"\"\n",
    "insert overwrite table tmp.bike_model_tomtom_global select * from segments\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show segments snippet and count\n",
    "segments.show()\n",
    "segments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the historical model to HDFS location\n",
    "segments.write.format(\"parquet\").mode(\"overwrite\").save(\"hdfs:///user/dhruven.vora/tomtom_bicycle_20220504_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load segment speeds for bicycles on OSM data\n",
    "## start date: 2021-10-03\n",
    "## end date: 2021-10-31\n",
    "segments = spark.sql(\"\"\"\n",
    " with all_data as (\n",
    "\n",
    " SELECT \n",
    "        msg.classification, \n",
    "        msg.durationms*1.0/1000 as durations,\n",
    "        msg.graphsegment.segmentuuid,\n",
    "        msg.graphsegment.startjunctionuuid,\n",
    "        msg.graphsegment.endjunctionuuid,\n",
    "        msg.segmentfeature.roadclass,\n",
    "        msg.latitude,\n",
    "        msg.longitude,\n",
    "        msg.jobuuid,\n",
    "        msg.supplyuuid,\n",
    "        msg.tasktype,\n",
    "        (case when msg.speedkmph < 1 then 1 when msg.speedkmph > 150 then 150 else msg.speedkmph end)*1.0/3.6 as speedms,\n",
    "        msg.lengthmeters,\n",
    "        msg.cityid\n",
    "\n",
    "    FROM \n",
    "        rawdata_user.kafka_hp_maps_historical_streaks_osm_nodedup\n",
    "        where 1=1\n",
    "        and datestr between '2022-04-04' and '2022-05-02'\n",
    "        and msg.classification = 'valid'\n",
    "        and msg.vehicletype = 'BICYCLE'\n",
    "        and msg.lengthmeters > 0\n",
    "        and msg.speedkmph > 0\n",
    ")\n",
    "\n",
    ", segments as (\n",
    "SELECT \n",
    "startjunctionuuid\n",
    ",segmentuuid\n",
    ",endjunctionuuid\n",
    ",avg(latitude) as latitude\n",
    ",avg(longitude) as longitude\n",
    ",LEAST(72,GREATEST(1,count(*)/sum(1/speedms))) as harmonic_mean_ms\n",
    "from all_data\n",
    "group by segmentuuid,startjunctionuuid,endjunctionuuid\n",
    "having count(*) >= 5\n",
    ")\n",
    "select * from segments\n",
    "\"\"\")\n",
    "segments.cache()\n",
    "segments.createOrReplaceTempView(\"segments\")\n",
    "spark.sql(\"\"\"\n",
    "insert overwrite table tmp.bike_model_osm_global select * from segments\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show segments snippet and count\n",
    "segments.show()\n",
    "segments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the historical model to HDFS location\n",
    "segments.write.format(\"parquet\").mode(\"overwrite\").save(\"hdfs:///user/dhruven.vora/osm_bicycle_20220504_parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SparkMagic (Remote Python2)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
