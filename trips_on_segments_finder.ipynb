{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Thanks for using Drogon for your interactive Spark application. We update Drogon/SparkMagic as often as possible to make it easier, faster and more reliable for you. Have a question or feedback? Ping us on [uChat](https://uchat.uberinternal.com/uber/channels/spark).</span>\n",
    "\n",
    "What's New\n",
    "- Now you can use `%%configure` and `%%spark` magics to configure and start a Spark session (deprecating hard-to-use `%load_ext sparkmagic.magics` and `manage_spark` magics). Check out [this example](https://workbench.uberinternal.com/explore/knowledge/localfile/cwang/sparkmagic_python2_example.ipynb) for more details.\n",
    "- Improved `%%configure` magic. You now can use it to make all Spark and Drogon configurations from within notebook itself. Check out our [latest documentation & examples](https://docs.google.com/document/d/1mkYtDHquh4FjqTeA0Fxii8lyV-P6qzmoABhmmRwm_00/edit#heading=h.xn14pmoorsn0) for more details.\n",
    "- Bug fixes and performance updates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This script is to identify the trips passing through a given sequence of segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\n",
    "  \"kind\": \"spark\", \n",
    "  \"proxyUser\": \"dhruven.vora\", \n",
    "  \"sparkEnv\": \"SPARK_24\", \n",
    "  \"driverMemory\": \"12g\", \n",
    "  \"queue\": \"maps_route_analytics\", \n",
    "  \"numExecutors\": 300, \n",
    "  \"executorCores\": 2, \n",
    "  \"driverCores\": 2,\n",
    "  \"conf\": {\n",
    "    \"spark.driver.maxResultSize\": \"10g\",\n",
    "    \"spark.executor.memoryOverhead\": 3072, \n",
    "    \"spark.locality.wait\": \"0\",\n",
    "    \"spark.default.parallelism\":10000\n",
    "  },\n",
    "  \"executorMemory\": \"24g\",\n",
    "  \"drogonHeaders\": {\n",
    "    \"X-DROGON-CLUSTER\": \"PHX2/Secure\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.{DataFrame, Dataset, Row, SparkSession}\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import scala.collection.mutable.ListBuffer\n",
    "import org.apache.spark.sql._\n",
    "\n",
    "case class GpsPoint(\n",
    "//     endJunctionUuid: String,\n",
    "    segmentUuid: String\n",
    "//     startJunctionUuid: String\n",
    ")\n",
    "\n",
    "case class ActualPolylineInfo (\n",
    "    tripUuid: String,\n",
    "    gpsPoints: List[GpsPoint],\n",
    "    waypointTaskType: String,\n",
    "    driverUuid: String,\n",
    "    buildUuid: String,\n",
    "    dataProvider: String,\n",
    "    vehicleType: String\n",
    ")\n",
    "\n",
    "case class RouteCorpus (\n",
    "    actualPolylineInfo: ActualPolylineInfo\n",
    ")\n",
    "\n",
    "case class Trip (\n",
    "    tripUuid: String,\n",
    "    segments: List[String]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object AllDone extends Exception { }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// find trips with segments\n",
    "val trips = spark.read.parquet(\"/app/route_corpus_features/route_corpus/daily/date=2023-01-*\").as[RouteCorpus]\n",
    "trips.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val derivedTrips = trips.\n",
    "map(r => {\n",
    "    val points = r.actualPolylineInfo.gpsPoints\n",
    "    var segments = ListBuffer[String]()\n",
    "    \n",
    "    points.foreach(point => segments += point.segmentUuid)\n",
    "    \n",
    "    Trip(tripUuid = r.actualPolylineInfo.tripUuid, segments = segments.toList.distinct)\n",
    "}).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val result = derivedTrips.\n",
    "filter(t => {\n",
    "    \n",
    "    var flag = false\n",
    "    \n",
    "    if(t.segments.length >= 3) {\n",
    "    \n",
    "        var segment1 = \"\"\n",
    "        var segment2 = t.segments.apply(1)\n",
    "        var segment3 = t.segments.apply(2)\n",
    "\n",
    "        try {\n",
    "            for(i <- 2 until t.segments.length) {\n",
    "                segment1 = segment2\n",
    "                segment2 = segment3\n",
    "                segment3 = t.segments.apply(i)\n",
    "\n",
    "                if(segment1 == \"fef65886-b01e-2f8a-a1ad-b8f8e48c4fd7\" &&\n",
    "                  segment2 == \"aec44bb4-e716-99f6-0e49-f8f0efd8e5e4\" && \n",
    "                  segment3 == \"79d49cc2-fa1b-c43a-129b-b1a9956bfabf\"\n",
    "                  ) {\n",
    "                    throw AllDone\n",
    "                }\n",
    "            }\n",
    "        } catch {\n",
    "            case AllDone => flag = true\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    flag\n",
    "    \n",
    "}).\n",
    "map(t => t.tripUuid)\n",
    "\n",
    "result.collect().foreach(println)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "07. SparkMagic (Remote Scala)",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
