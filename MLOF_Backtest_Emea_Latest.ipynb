{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://yoober11:****@pypi.uberinternal.com/index\n",
      "Requirement already satisfied: dataclasses in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (0.8)\n",
      "Looking in indexes: https://yoober11:****@pypi.uberinternal.com/index\n",
      "Requirement already satisfied: matching-ds-tools in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (0.7.7)\n",
      "Requirement already satisfied: pytz>2021 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from matching-ds-tools) (2021.3)\n",
      "Requirement already satisfied: haversine==2.1.2 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from matching-ds-tools) (2.1.2)\n",
      "Requirement already satisfied: protobuf==3.12.2 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from matching-ds-tools) (3.12.2)\n",
      "Requirement already satisfied: requests==2.22.0 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from matching-ds-tools) (2.22.0)\n",
      "Requirement already satisfied: pandas>1 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from matching-ds-tools) (1.1.5)\n",
      "Requirement already satisfied: ujson==1.35 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from matching-ds-tools) (1.35)\n",
      "Requirement already satisfied: queryrunner-client>3 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from matching-ds-tools) (3.4.1)\n",
      "Requirement already satisfied: h3==3.6.4 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from matching-ds-tools) (3.6.4)\n",
      "Requirement already satisfied: setuptools in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from protobuf==3.12.2->matching-ds-tools) (59.6.0)\n",
      "Requirement already satisfied: six>=1.9 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from protobuf==3.12.2->matching-ds-tools) (1.15.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from requests==2.22.0->matching-ds-tools) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from requests==2.22.0->matching-ds-tools) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from requests==2.22.0->matching-ds-tools) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from requests==2.22.0->matching-ds-tools) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from pandas>1->matching-ds-tools) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from pandas>1->matching-ds-tools) (1.16.6)\n",
      "Requirement already satisfied: hive-csv-reader==0.1.9 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from queryrunner-client>3->matching-ds-tools) (0.1.9)\n",
      "Requirement already satisfied: wonkapy>=3 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from queryrunner-client>3->matching-ds-tools) (3.0.2)\n",
      "Requirement already satisfied: querybuilder-client==0.6.1 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from queryrunner-client>3->matching-ds-tools) (0.6.1)\n",
      "Requirement already satisfied: m3>=4 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from queryrunner-client>3->matching-ds-tools) (4.3.1)\n",
      "Requirement already satisfied: pysocks>=1.5.7 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from queryrunner-client>3->matching-ds-tools) (1.7.1)\n",
      "Requirement already satisfied: pyyaml in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from queryrunner-client>3->matching-ds-tools) (5.3.1)\n",
      "Requirement already satisfied: clay-config>=2 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from queryrunner-client>3->matching-ds-tools) (2.1.1)\n",
      "Requirement already satisfied: future==0.16.0 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from queryrunner-client>3->matching-ds-tools) (0.16.0)\n",
      "Requirement already satisfied: clay-config-file in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from clay-config>=2->queryrunner-client>3->matching-ds-tools) (1.2.1)\n",
      "Requirement already satisfied: tornado<6 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from m3>=4->queryrunner-client>3->matching-ds-tools) (4.5.3)\n",
      "Requirement already satisfied: thriftrw>=1.8 in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from m3>=4->queryrunner-client>3->matching-ds-tools) (1.8.1)\n",
      "Requirement already satisfied: ply in /dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages (from thriftrw>=1.8->m3>=4->queryrunner-client>3->matching-ds-tools) (3.11)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source $VIRTUAL_ENV_DIR/python3/bin/activate\n",
    " \n",
    "# Install latest mxpkg version (to specify version, use syntax: pip install mxpkg==1.1.7)\n",
    "pip install dataclasses\n",
    "pip install matching-ds-tools\n",
    " \n",
    "deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from queryrunner_client import Client\n",
    "USER_EMAIL = 'thai@uber.com'\n",
    "qclient = Client(user_email=USER_EMAIL)\n",
    "CONSUMER_NAME = 'intelligentdispatch'\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "#num_cores = multiprocessing.cpu_count()  -- 48\n",
    "n_cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from queryrunner_client import Client as QRClient\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdstk\n",
    "from mdstk.data_fetcher.data_fetcher import DataFetcher\n",
    "from mdstk.data_fetcher.cached_data_fetcher import CachedDataFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collection\n",
    "\n",
    "QUERY = \"\"\"\n",
    "with dispatch as (\n",
    "select \n",
    "    datestr,\n",
    "    msg.cityid,\n",
    "    msg.ctplangenrequestuuid as plangen_uuid,\n",
    "    msg.ctrequestuuid as scan_uuid,\n",
    "    j as job_uuid,\n",
    "    msg.supplyuuid,\n",
    "    msg.planactiontype\n",
    "from \n",
    "    rawdata_user.kafka_hp_multileg_dispatched_plan_nodedup\n",
    "cross join \n",
    "    unnest(msg.jobuuid) jobs(j)\n",
    "where \n",
    "    datestr = '{datestr}'\n",
    "    and msg.cityid = {city_id}\n",
    "    and msg.vehicleviewid = {vvid} \n",
    "    and msg.tenancy = 'uber/production'\n",
    "    and CARDINALITY(msg.jobuuid) > 0\n",
    "    and substr(msg.ctrequestuuid, 1, length('{digits}')) = '{digits}'\n",
    "),\n",
    "plangen as (\n",
    "select \n",
    "    msg.scanuuid as plangen_uuid, \n",
    "    p.uuid as job_uuid,\n",
    "    j.supplyuuid\n",
    "from \n",
    "    rawdata_user.kafka_hp_multileg_matching_observability_proposals_v2_nodedup\n",
    "cross join \n",
    "    unnest(msg.proposals) as job(j)\n",
    "cross join \n",
    "    unnest(j.jobs) as plan(p)\n",
    "where \n",
    "    datestr = '{datestr}'\n",
    "    and msg.cityid = {city_id}\n",
    "    and msg.flowtype = 'solo_batch'\n",
    "    and msg.tenancy = 'uber/production'\n",
    "    and j.status = 'eligible'\n",
    "),\n",
    "mgv as (\n",
    "select datestr,\n",
    "    msg.city_id,\n",
    "    msg.job_uuid,\n",
    "    msg.client_uuid,\n",
    "    msg.ct_request_uuid as plangen_uuid,\n",
    "    msg.supply_uuid,\n",
    "    msg.supply_plan_uuid as plan_uuid,\n",
    "    msg.unadjusted_eta as eta,\n",
    "    (CASE\n",
    "      WHEN msg.adjustedeta > 1500 THEN 1500.0\n",
    "      WHEN msg.adjustedeta < 0 THEN 0.0\n",
    "      ELSE msg.adjustedeta\n",
    "    END) as adjustedeta,\n",
    "    round(msg.job_surge, 4) as surge_mul,\n",
    "    round(msg.eventual_completion_probability, 4) as eventual_comp_prob,\n",
    "    msg.ranking_metric,\n",
    "    round(1 - msg.solo_cancel_model_driver_accept_prob, 4) as d_proba,\n",
    "    round(1 - msg.solo_cancel_model_rider_accept_prob, 4) as r_proba,\n",
    "    round(1 - msg.spinner_survive_prob_before_next_scan, 4) as s_proba,\n",
    "    msg.preferred_destination_adjustment,\n",
    "    msg.objective_value as of_value,\n",
    "    msg.inconvenience_etd - msg.ranking_metric as trip_length\n",
    "from   \n",
    "    rawdata.kafka_hp_multileg_mgv_log_nodedup\n",
    "where  \n",
    "    datestr = '{datestr}'\n",
    "    and msg.city_id = {city_id}\n",
    "    and msg.tenancy = 'uber/production'\n",
    "    and msg.vehicle_view_id = {vvid} \n",
    "    and msg.flow_type = 'solo_batch'\n",
    "    and msg.job_uuid <> msg.client_uuid\n",
    "    and msg.calculator_type = 'markov_eta_v2'\n",
    "),\n",
    "test as (\n",
    "select \n",
    "    mgv.datestr,\n",
    "    mgv.city_id,\n",
    "    dispatch.scan_uuid,\n",
    "    mgv.plangen_uuid,\n",
    "    mgv.job_uuid,\n",
    "    dispatch.planactiontype,\n",
    "    mgv.supply_uuid,\n",
    "    case when dispatch.supplyuuid = mgv.supply_uuid then 1 else 0 end as is_selected,\n",
    "    mgv.eta,\n",
    "    mgv.adjustedeta,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1), 4) as eta_one,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.05), 4) as eta_one_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.10), 4) as eta_one_ten,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.15), 4) as eta_one_fifteen,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.20), 4) as eta_one_twenty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.25), 4) as eta_one_quarter,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.30), 4) as eta_one_thirty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.35), 4) as eta_one_thirty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.40), 4) as eta_one_forty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.45), 4) as eta_one_forty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.50), 4) as eta_one_fifty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.55), 4) as eta_one_fifty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.60), 4) as eta_one_sixty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.65), 4) as eta_one_sixty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.70), 4) as eta_one_seventy,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.75), 4) as eta_one_seventy_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.80), 4) as eta_one_eighty,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.85), 4) as eta_one_eighty_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.90), 4) as eta_one_ninety,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 1.95), 4) as eta_one_ninety_five,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 2), 4) as eta_square,\n",
    "    round(POWER(1 - mgv.adjustedeta / 1500.0, 3), 4) as eta_cube,\n",
    "    mgv.surge_mul,\n",
    "    mgv.eventual_comp_prob,\n",
    "    round(1.0 / (1.0 + POWER(mgv.surge_mul, 2)), 4) as network_contention_2,\n",
    "    round(1.0 / (1.0 + POWER(mgv.surge_mul, 3)), 4) as network_contention_3,\n",
    "    round(1.0 / (1.0 + POWER(mgv.surge_mul, 5)), 4) as network_contention_5,\n",
    "    mgv.ranking_metric,\n",
    "    mgv.d_proba,\n",
    "    mgv.r_proba,\n",
    "    mgv.s_proba,\n",
    "    round((1.0 - mgv.d_proba) * (1.0 - mgv.r_proba) * (1.0 - mgv.s_proba) + mgv.eventual_comp_prob * mgv.d_proba, 4) as cr_ratio,\n",
    "    round((1.0 - mgv.d_proba) * (1.0 - mgv.r_proba) + mgv.eventual_comp_prob * mgv.d_proba, 4) as crof_ratio,\n",
    "    mgv.preferred_destination_adjustment,\n",
    "    mgv.of_value,\n",
    "    mgv.trip_length,\n",
    "    fare.est_rider_quoted_final_fare as fare,\n",
    "    fare.est_rider_quoted_final_fare * 1.0 / fare.usd_fx_rate as fare_usd\n",
    "from\n",
    "    mgv\n",
    "join\n",
    "    plangen\n",
    "on \n",
    "    mgv.plangen_uuid = plangen.plangen_uuid\n",
    "    and mgv.job_uuid = plangen.job_uuid\n",
    "    and mgv.supply_uuid = plangen.supplyuuid\n",
    "join\n",
    "    dispatch\n",
    "on\n",
    "    mgv.plangen_uuid = dispatch.plangen_uuid\n",
    "    and mgv.job_uuid = dispatch.job_uuid\n",
    "join\n",
    "    dwh.fact_trip_fare fare \n",
    "on\n",
    "    mgv.job_uuid = fare.trip_uuid\n",
    "    and fare.datestr = '{datestr}'\n",
    "    and fare.city_id = {city_id}\n",
    ")\n",
    "select * from test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Query:\n",
    "    prefix: str\n",
    "    hex_digits: str\n",
    "    city_id: int\n",
    "    vvid: str\n",
    "    datestr: str\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.name = f'{self.prefix}_city{self.city_id}_{self.vvid}_{self.datestr}_segment{self.hex_digits}'\n",
    "        self.qry = QUERY.format(city_id=self.city_id, vvid=self.vvid, digits=self.hex_digits, datestr=self.datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataFetcher(DataFetcher):\n",
    "    def query_many_presto(self, *args, **kwargs):\n",
    "        return super().query_many_presto(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new objective function\n",
    "def clean_df(df):\n",
    "    df = df[df['fare'].notnull()]\n",
    "    df['trip_length'][df['trip_length'] <= 100] = 100\n",
    "    df = df.drop_duplicates(subset=['job_uuid', 'supply_uuid'])\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def compute_new_of(df):\n",
    "    \n",
    "#     # Baseline (Markov)\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.945,\n",
    "#  'overwrite': 0.0,\n",
    "#  'Average Matched ETA': 487.91,\n",
    "#  'P90 Matched ETA': 1122.0,\n",
    "#  'Driver AR': 0.496,\n",
    "#  'Rider cancel': 0.154,\n",
    "#  'Average trip length': 829.1,\n",
    "#  'Average Matched Fare': 16.0,\n",
    "#  'Total GB': 38381}\n",
    "\n",
    "#     # EFOF\n",
    "#     df['new_of'] = - df['eta_square'] * df['cr_ratio'] * df['fare']\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.985,\n",
    "#  'overwrite': 0.164,\n",
    "#  'Average Matched ETA': 531.9,\n",
    "#  'P90 Matched ETA': 1219.8,\n",
    "#  'Driver AR': 0.493,\n",
    "#  'Rider cancel': 0.171,\n",
    "#  'Average trip length': 835.03,\n",
    "#  'Average Matched Fare': 16.1,\n",
    "#  'Total GB': 39531}\n",
    "\n",
    "#     # CROF\n",
    "#     df['new_of'] = - df['eta_square'] * df['crof_ratio']\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.984,\n",
    "#  'overwrite': 0.134,\n",
    "#  'Average Matched ETA': 530.09,\n",
    "#  'P90 Matched ETA': 1217.0,\n",
    "#  'Driver AR': 0.493,\n",
    "#  'Rider cancel': 0.169,\n",
    "#  'Average trip length': 833.92,\n",
    "#  'Average Matched Fare': 16.08,\n",
    "#  'Total GB': 39573}\n",
    "\n",
    "#     # WCOF\n",
    "#     df['new_of'] = - (df['network_contention_5'] * df['eta_square'] * df['crof_ratio'] \\\n",
    "#                       + (1 - df['network_contention_5']) * df['eta_square'] * df['crof_ratio'] * df['fare'] / 10.0\n",
    "#                      )\n",
    "    \n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.984,\n",
    "#  'overwrite': 0.155,\n",
    "#  'Average Matched ETA': 531.1,\n",
    "#  'P90 Matched ETA': 1217.1,\n",
    "#  'Driver AR': 0.493,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 834.36,\n",
    "#  'Average Matched Fare': 16.09,\n",
    "#  'Total GB': 39525}\n",
    "\n",
    "#     # WCOF - Latest Version\n",
    "#     df['new_of'] = - (df['eta_square'] * df['crof_ratio'] / df['surge_mul']**36 \\\n",
    "#                       + (1 - 1/df['surge_mul']**36) * df['eta_square'] * df['crof_ratio'] * df['fare'] / 18.0\n",
    "#                      )\n",
    "    \n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.985,\n",
    "#  'overwrite': 0.157,\n",
    "#  'Average Matched ETA': 531.62,\n",
    "#  'P90 Matched ETA': 1221.6,\n",
    "#  'Driver AR': 0.493,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 834.03,\n",
    "#  'Average Matched Fare': 16.08,\n",
    "#  'Total GB': 39508}\n",
    "\n",
    "\n",
    "############################################\n",
    "#             GUB as label                 #\n",
    "#              Unit: USD                   #\n",
    "############################################\n",
    "#     # gamma = 1.00 - MAIN I\n",
    "#     df['new_of'] = - (0.4019 * df['d_proba'] \\\n",
    "#                       - 0.9627 * df['eventual_comp_prob'] \\\n",
    "#                       - 1.3453 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.6210 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       - 0.6435 * df['eta_one_quarter'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       - 1.1098 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] / df['surge_mul'] \\\n",
    "#                       + 4.1085 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare_usd'] / df['surge_mul']\n",
    "#                      )\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.978,\n",
    "#  'overwrite': 0.187,\n",
    "#  'Average Matched ETA': 528.79,\n",
    "#  'P90 Matched ETA': 1203.6,\n",
    "#  'Driver AR': 0.5,\n",
    "#  'Rider cancel': 0.169,\n",
    "#  'Average trip length': 834.69,\n",
    "#  'Average Matched Fare': 16.12,\n",
    "#  'Total GB': 40149}\n",
    "\n",
    "\n",
    "#     # gamma = 1.00 - with Intercept - MAIN I\n",
    "#     df['new_of'] = - (0.4019 * df['d_proba'] \\\n",
    "#                       - 0.9627 * df['eventual_comp_prob'] \\\n",
    "#                       - 1.3453 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.6210 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       - 0.6435 * df['eta_one_quarter'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       - 1.1098 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] / df['surge_mul'] \\\n",
    "#                       + 4.1085 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare_usd'] / df['surge_mul'] \\\n",
    "#                       + 1.3591\n",
    "#                      )\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.988,\n",
    "#  'overwrite': 0.197,\n",
    "#  'Average Matched ETA': 539.94,\n",
    "#  'P90 Matched ETA': 1231.0,\n",
    "#  'Driver AR': 0.501,\n",
    "#  'Rider cancel': 0.172,\n",
    "#  'Average trip length': 835.1,\n",
    "#  'Average Matched Fare': 16.1,\n",
    "#  'Total GB': 40449}\n",
    "\n",
    "#     # gamma = 1.00 - with Intercept - MAIN II\n",
    "#     df['new_of'] = - (0.4019 * df['d_proba'] \\\n",
    "#                       - 0.9627 * df['eventual_comp_prob'] \\\n",
    "#                       - 1.3453 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.6210 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       - 0.6435 * df['eta_one_quarter'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       - 1.1098 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] / df['surge_mul'] \\\n",
    "#                       + 4.1085 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare_usd'] / df['surge_mul'] \\\n",
    "#                       + 0.15\n",
    "#                      )\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.981,\n",
    "#  'overwrite': 0.189,\n",
    "#  'Average Matched ETA': 531.46,\n",
    "#  'P90 Matched ETA': 1212.0,\n",
    "#  'Driver AR': 0.5,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 834.25,\n",
    "#  'Average Matched Fare': 16.1,\n",
    "#  'Total GB': 40195}\n",
    "\n",
    "    # gamma = 1.00 - with Intercept - MAIN II - Use local currency with a fixed exchange rate (which is ~ 1 at the median value)\n",
    "    df['new_of'] = - (0.4019 * df['d_proba'] \\\n",
    "                      - 0.9627 * df['eventual_comp_prob'] \\\n",
    "                      - 1.3453 * df['eta_one'] * df['cr_ratio'] \\\n",
    "                      + 0.6210 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "                      - 0.6435 * df['eta_one_quarter'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "                      - 1.1098 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "                      + 4.1085 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "                      + 0.15\n",
    "                     )\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.981,\n",
    "#  'overwrite': 0.19,\n",
    "#  'Average Matched ETA': 531.33,\n",
    "#  'P90 Matched ETA': 1212.0,\n",
    "#  'Driver AR': 0.501,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 834.63,\n",
    "#  'Average Matched Fare': 16.12,\n",
    "#  'Total GB': 40213}\n",
    "\n",
    "\n",
    "#     df['new_of'] = - (0.4019 * df['d_proba'] \\\n",
    "#                       - 0.9627 * df['eventual_comp_prob'] \\\n",
    "#                       - 1.3453 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.6210 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] / 10.0 \\\n",
    "#                       - 0.6435 * df['eta_one_quarter'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       - 1.1098 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] / 10.0 / df['surge_mul'] \\\n",
    "#                       + 4.1085 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] / 10.0 / df['surge_mul'] \\\n",
    "#                       + 1.3591\n",
    "#                      )\n",
    "\n",
    "#     # gamma = 1.00 - with Intercept - MAIN III - Use local currency with a fixed exchange rate (which is ~ 1 at the median value)\n",
    "#     df['new_of'] = - (0.3933 * df['d_proba'] \\\n",
    "#                       - 0.9410 * df['eventual_comp_prob'] \\\n",
    "#                       - 1.4449 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.5347 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       - 0.5527 * df['eta_one_quarter'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       + 3.0118 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "#                       + 0.15\n",
    "#                      )\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.981,\n",
    "#  'overwrite': 0.191,\n",
    "#  'Average Matched ETA': 531.99,\n",
    "#  'P90 Matched ETA': 1212.9,\n",
    "#  'Driver AR': 0.501,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 834.37,\n",
    "#  'Average Matched Fare': 16.1,\n",
    "#  'Total GB': 40218}\n",
    "\n",
    "\n",
    "# #     # gamma = 1.00 - with Intercept - MAIN IV - Use local currency with a fixed exchange rate (which is ~ 1 at the median value)\n",
    "# #     # Scale features and labels by mean(labels)\n",
    "#     df['new_of'] = - (0.3754 * df['d_proba'] \\\n",
    "#                       - 1.9908 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.0481 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       - 0.0983 * df['eta_cube'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       + 3.1308 * df['eta_one_fifty'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] / df['surge_mul']\n",
    "#                      )\n",
    "\n",
    "#     # gamma = 0.99 - MAIN I\n",
    "#     df['new_of'] = - (0.4044 * df['d_proba'] \\\n",
    "#                       - 0.8661 * df['eventual_comp_prob'] \\\n",
    "#                       - 0.7857 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.3434 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       - 0.7348 * df['eta_square'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       + 0.3817 * df['eta_cube'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       + 2.2700 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "#                       + 0.12\n",
    "#                      )\n",
    "\n",
    "#     # gamma = 0.99 - MAIN I - Use local currency with a fixed exchange rate (which is ~ 1 at the median value)\n",
    "#     df['new_of'] = - (0.4044 * df['d_proba'] \\\n",
    "#                       - 0.8661 * df['eventual_comp_prob'] \\\n",
    "#                       - 0.7857 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.3434 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       - 0.7348 * df['eta_square'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       + 0.3817 * df['eta_cube'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       + 2.2700 * df['eta_one'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "#                       + 0.12\n",
    "#                      )\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.981,\n",
    "#  'overwrite': 0.19,\n",
    "#  'Average Matched ETA': 531.63,\n",
    "#  'P90 Matched ETA': 1213.0,\n",
    "#  'Driver AR': 0.499,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 834.36,\n",
    "#  'Average Matched Fare': 16.1,\n",
    "#  'Total GB': 40147}\n",
    "\n",
    "#     # gamma = 0.95 - MAIN I\n",
    "#     df['new_of'] = - (0.2490 * df['d_proba'] \\\n",
    "#                       - 0.4376 * df['eventual_comp_prob'] \\\n",
    "#                       - 0.2893 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.0160 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       - 0.0296 * df['eta_cube'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       + 0.9739 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] / df['surge_mul'] \\\n",
    "#                       + 0.05\n",
    "#                      )\n",
    "    \n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.981,\n",
    "#  'overwrite': 0.187,\n",
    "#  'Average Matched ETA': 530.77,\n",
    "#  'P90 Matched ETA': 1212.0,\n",
    "#  'Driver AR': 0.494,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 833.81,\n",
    "#  'Average Matched Fare': 16.1,\n",
    "#  'Total GB': 39846}\n",
    "\n",
    "#     # gamma = 0.95 - MAIN I - Use local currency with a fixed exchange rate (which is ~ 1 at the median value)\n",
    "#     df['new_of'] = - (0.2490 * df['d_proba'] \\\n",
    "#                       - 0.4376 * df['eventual_comp_prob'] \\\n",
    "#                       - 0.2893 * df['eta_one'] * df['cr_ratio'] \\\n",
    "#                       + 0.0160 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       - 0.0296 * df['eta_cube'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       + 0.9739 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] / df['surge_mul'] \\\n",
    "#                       + 0.05\n",
    "#                      )\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.981,\n",
    "#  'overwrite': 0.189,\n",
    "#  'Average Matched ETA': 531.08,\n",
    "#  'P90 Matched ETA': 1212.1,\n",
    "#  'Driver AR': 0.495,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 833.83,\n",
    "#  'Average Matched Fare': 16.1,\n",
    "#  'Total GB': 39917}\n",
    "\n",
    "#     # gamma = 0.90 - MAIN I\n",
    "#     df['new_of'] = - (0.1968 * df['d_proba'] \\\n",
    "#                       - 0.3421 * df['eventual_comp_prob'] \\\n",
    "#                       + 0.0102 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       - 0.0194 * df['eta_cube'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare_usd'] \\\n",
    "#                       + 0.5001 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare_usd'] / df['surge_mul'] \\\n",
    "#                       + 0.05\n",
    "#                      )\n",
    "    \n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.981,\n",
    "#  'overwrite': 0.19,\n",
    "#  'Average Matched ETA': 530.24,\n",
    "#  'P90 Matched ETA': 1211.0,\n",
    "#  'Driver AR': 0.489,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 833.39,\n",
    "#  'Average Matched Fare': 16.09,\n",
    "#  'Total GB': 39527}\n",
    "\n",
    "#     # gamma = 0.90 - MAIN I - Use local currency with a fixed exchange rate (which is ~ 1 at the median value)\n",
    "#     df['new_of'] = - (0.1968 * df['d_proba'] \\\n",
    "#                       - 0.3421 * df['eventual_comp_prob'] \\\n",
    "#                       + 0.0102 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       - 0.0194 * df['eta_cube'] * (1 - df['network_contention_5']) * df['cr_ratio'] * df['fare'] \\\n",
    "#                       + 0.5001 * df['eta_one'] * (1 - df['network_contention_2']) * df['cr_ratio'] * df['fare'] / df['surge_mul']\n",
    "#                       + 0.05\n",
    "#                      )\n",
    "\n",
    "# {'total_jobs': 6076,\n",
    "#  'match_rate': 0.981,\n",
    "#  'overwrite': 0.191,\n",
    "#  'Average Matched ETA': 530.76,\n",
    "#  'P90 Matched ETA': 1212.0,\n",
    "#  'Driver AR': 0.49,\n",
    "#  'Rider cancel': 0.17,\n",
    "#  'Average trip length': 833.4,\n",
    "#  'Average Matched Fare': 16.09,\n",
    "#  'Total GB': 39637}\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local solver\n",
    "def solve_dict(\n",
    "    scan: dict, \n",
    "    cost_col: str, \n",
    "    job_singleton: float = 1500,\n",
    "    infinity: float = 1000000\n",
    "):\n",
    "    job_list = list(set([k[0] for k in scan.keys()]))\n",
    "    job_idx = {j: i for i, j in enumerate(job_list)}\n",
    "    job_count = len(job_list)\n",
    "\n",
    "    supply_list = list(set([k[1] for k in scan.keys()]))\n",
    "    supply_idx = {s: i for i, s in enumerate(supply_list)}\n",
    "    supply_count = len(supply_list)\n",
    "    \n",
    "    utility = np.full((len(job_list), len(supply_list) + len(job_list)), infinity, dtype=np.float32)\n",
    "    for k in scan.keys():\n",
    "        jidx = job_idx[k[0]]\n",
    "        sidx = supply_idx[k[1]]\n",
    "        utility[jidx, sidx] = scan[k][cost_col]\n",
    "    for i in range(len(job_list)):\n",
    "        utility[i, supply_count + i] = job_singleton\n",
    "            \n",
    "    # solve\n",
    "    job_sol, supply_sol = linear_sum_assignment(utility)\n",
    "\n",
    "    result = set()\n",
    "    for jidx, sidx in zip(job_sol, supply_sol):\n",
    "        j = job_list[jidx]\n",
    "        if sidx >= supply_count:\n",
    "            result.add((j,))\n",
    "        else:\n",
    "            s = supply_list[sidx]\n",
    "            result.add((j, s))\n",
    "            \n",
    "    assert len(result) == len(job_list)\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import field\n",
    "\n",
    "@dataclass\n",
    "class ScanMetrics:\n",
    "    total_jobs: int = 0.\n",
    "    total_eta: float = 0.\n",
    "    total_offer: float = 0.\n",
    "    total_ar: float = 0.\n",
    "    total_rc: float = 0.\n",
    "    total_trip: float = 0.\n",
    "    total_gb: float = 0.\n",
    "    total_fare: float = 0.\n",
    "    total_overwrite: int = 0.\n",
    "    list_etas: list = field(default_factory = list)\n",
    "    \n",
    "    def __add__(self, o: 'ScanMetrics') -> 'ScanMetrics':\n",
    "        return ScanMetrics(\n",
    "            self.total_jobs + o.total_jobs,\n",
    "            self.total_eta + o.total_eta,\n",
    "            self.total_offer + o.total_offer,\n",
    "            self.total_ar + o.total_ar,\n",
    "            self.total_rc + o.total_rc,\n",
    "            self.total_trip + o.total_trip,\n",
    "            self.total_overwrite + o.total_overwrite,\n",
    "            self.total_gb + o.total_gb,\n",
    "            self.total_fare + o.total_fare,\n",
    "            self.list_etas.expand + o.list_etas\n",
    "        )\n",
    "    def __iadd__(self, o: 'ScanMetrics') -> 'ScanMetrics':\n",
    "        self.total_jobs += o.total_jobs\n",
    "        self.total_eta += o.total_eta\n",
    "        self.total_offer += o.total_offer\n",
    "        self.total_ar += o.total_ar\n",
    "        self.total_rc += o.total_rc\n",
    "        self.total_trip += o.total_trip\n",
    "        self.total_overwrite += o.total_overwrite\n",
    "        self.total_gb += o.total_gb\n",
    "        self.total_fare += o.total_fare\n",
    "        self.list_etas += o.list_etas\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Summary\n",
    "def metric_summary_dict(\n",
    "    scan_dict: Dict[str, Dict[str, Any]],\n",
    "    matching: set, \n",
    "    overwrite: int,\n",
    ") -> ScanMetrics:\n",
    "    sm = ScanMetrics()\n",
    "    sm.total_jobs = len(matching)\n",
    "    sm.total_overwrite = overwrite\n",
    "    \n",
    "    for m in matching:\n",
    "        if len(m) == 2:\n",
    "            row = scan_dict[(m[0], m[1])]\n",
    "            sm.total_offer += 1\n",
    "            sm.total_eta += row['eta']\n",
    "            sm.total_ar += 1 - row['d_proba']\n",
    "            sm.total_rc += row['r_proba']\n",
    "            if row['trip_length'] < 7200:\n",
    "                sm.total_trip += row['trip_length']\n",
    "            if row['fare_usd'] > 0:\n",
    "                sm.total_gb += (1 - row['d_proba']) * (1 - row['r_proba']) * row['fare_usd']\n",
    "                sm.total_fare += row['fare_usd']\n",
    "                \n",
    "            sm.list_etas.append(row['eta'])\n",
    "\n",
    "    return sm\n",
    "\n",
    "def solve_all_dict(df, solver: Callable[[dict], set]):\n",
    "    total_scans = dict(tuple(df.groupby('scan_uuid')))\n",
    "\n",
    "    sm = ScanMetrics()\n",
    "    for scan_uuid, scan_df in total_scans.items():\n",
    "        scan = (scan_df.set_index(['job_uuid', 'supply_uuid']).to_dict(orient='index'))\n",
    "        matching, overwrite = solver(scan)\n",
    "        sm += metric_summary_dict(scan, matching, overwrite)\n",
    "        \n",
    "    return {'total_jobs': round(sm.total_jobs),\n",
    "            'match_rate': round(sm.total_offer * 1.0 / sm.total_jobs, 3),\n",
    "            'overwrite': round(sm.total_overwrite * 1.0 / sm.total_jobs, 3), # different decisions compared to Markov\n",
    "            'Average Matched ETA': round(sm.total_eta * 1.0 / sm.total_offer, 2),\n",
    "            'P90 Matched ETA': round(np.percentile(sm.list_etas, 90), 2),\n",
    "            'Driver AR': round(sm.total_ar * 1.0 / sm.total_offer, 3),\n",
    "            'Rider cancel': round(sm.total_rc * 1.0 / sm.total_offer, 3),\n",
    "            'Average trip length': round(sm.total_trip * 1.0 / sm.total_offer, 2),\n",
    "            'Average Matched Fare': round(sm.total_fare * 1.0 / sm.total_offer, 2),\n",
    "            'Total GB': round(sm.total_gb)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_matching_decision(m1,m2):\n",
    "    return m1.difference(m2), m2.difference(m1)\n",
    "\n",
    "def supply_cost_solve_dict(scan, is_markov = False, secondary_singleton = 0.0):\n",
    "    # Markov\n",
    "    primary_matching = solve_dict(scan, 'of_value', job_singleton = 1500)\n",
    "    if is_markov:      \n",
    "        return primary_matching, 0\n",
    "    \n",
    "    # SCA solve\n",
    "    secondary_matching = solve_dict(scan, 'new_of', job_singleton = secondary_singleton)\n",
    "    different_matches = len(different_matching_decision(primary_matching, secondary_matching)[0])\n",
    "    return secondary_matching, different_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21/21 dataframes from cache!\n"
     ]
    }
   ],
   "source": [
    "prefix = 'replay'\n",
    "hex_digits = '36'\n",
    "\n",
    "city_id_vvids = {38: '(3298)', 37: '(5235)', 36: '(570)'}\n",
    "\n",
    "datestrs = [  # 1 week\n",
    "    '2022-09-13',\n",
    "    '2022-09-14',\n",
    "    '2022-09-15',\n",
    "    '2022-09-16',\n",
    "    '2022-09-17',\n",
    "    '2022-09-18',\n",
    "    '2022-09-19'\n",
    "]\n",
    "\n",
    "queries = [\n",
    "    Query(prefix=prefix, hex_digits=hex_digits, city_id=city_id, vvid=vvid, datestr=datestr)\n",
    "    for (city_id, vvid), datestr in itertools.product(city_id_vvids.items(), datestrs)\n",
    "]\n",
    "\n",
    "cache_qry_map = {\n",
    "    q.name: q.qry \n",
    "    for q in queries\n",
    "}\n",
    "\n",
    "cdf = CachedDataFetcher(\n",
    "    data_fetcher=MyDataFetcher(\n",
    "        user_email=USER_EMAIL,\n",
    "        consumer_name=CONSUMER_NAME,\n",
    "    ),\n",
    "    cache_qry_map=cache_qry_map,\n",
    "    datacenter='dca1',\n",
    "    datasource='presto-secure',\n",
    ")\n",
    "\n",
    "cdf.fetch(bust_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 236 ms, sys: 102 ms, total: 338 ms\n",
      "Wall time: 336 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# clean data\n",
    "scans = pd.concat(cdf.dfs.values(), axis=0, ignore_index=True) \n",
    "df = scans\n",
    "df = clean_df(df)\n",
    "df = compute_new_of(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    172545.000000\n",
       "mean          1.080144\n",
       "std           0.184598\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           1.100000\n",
       "max           2.900000\n",
       "Name: surge_mul, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['surge_mul'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.65 s, sys: 36.2 ms, total: 8.69 s\n",
      "Wall time: 8.69 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_jobs': 6076,\n",
       " 'match_rate': 0.981,\n",
       " 'overwrite': 0.19,\n",
       " 'Average Matched ETA': 531.33,\n",
       " 'P90 Matched ETA': 1212.0,\n",
       " 'Driver AR': 0.501,\n",
       " 'Rider cancel': 0.17,\n",
       " 'Average trip length': 834.63,\n",
       " 'Average Matched Fare': 16.12,\n",
       " 'Total GB': 40213}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SCA solve\n",
    "sca_matching = solve_all_dict(df,lambda scan: supply_cost_solve_dict(scan, is_markov = False))\n",
    "sca_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.46 s, sys: 0 ns, total: 8.46 s\n",
      "Wall time: 8.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_jobs': 6076,\n",
       " 'match_rate': 0.945,\n",
       " 'overwrite': 0.0,\n",
       " 'Average Matched ETA': 487.91,\n",
       " 'P90 Matched ETA': 1122.0,\n",
       " 'Driver AR': 0.496,\n",
       " 'Rider cancel': 0.154,\n",
       " 'Average trip length': 829.1,\n",
       " 'Average Matched Fare': 16.0,\n",
       " 'Total GB': 38381}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jaeger_tracing:Tracing sampler started with sampling refresh interval 60 sec\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Primary (Markov) solve\n",
    "markov_matching = solve_all_dict(df,lambda scan: supply_cost_solve_dict(scan, is_markov = True))\n",
    "markov_matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (General DS)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
