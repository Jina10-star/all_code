{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "099f3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95573ca5",
   "metadata": {},
   "source": [
    "a)remove all duplicates from sheet in excel using DATA>remove duplicates\n",
    "b)using excel concatenate function joined \"AgentCorrected_CatName_Primary\" and \"AgentCorrected_Integer_Primary\" column with comma and new target column name is \"primary\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "767be0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_cicd=pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/TaxML-CICD - Prod_Data.csv')\n",
    "df2_cicd.drop_duplicates(inplace=True)\n",
    "df2_cicd.dropna(how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc11c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(message):\n",
    "\n",
    "    #new_stopwords=['grocery']\n",
    "    stpwrd = nltk.corpus.stopwords.words('english')\n",
    "    #stpwrd.extend(new_stopwords)\n",
    "    # 1. Init Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #lowering and removing punctuation\n",
    "    message = re.sub(r'[^\\w\\s]','', message.lower())\n",
    "    #removing the numerical values and working only with text values\n",
    "    message = re.sub('[^a-zA-Z]', \" \", message )\n",
    "    #removing the stopwords\n",
    "    message = ' '.join([word for word in message.split() if word not in stpwrd and len(word)>1])\n",
    "    #lemmatizing the text\n",
    "    message =  \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(message) if w not in string.punctuation])\n",
    "    #print(\"message is : \",message)\n",
    "    \n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dceab9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a549eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/data/historical_data.csv', encoding='utf8',engine='python',usecols=['Item','Description','establishment_type','primary'])\n",
    "df1=df.sample(frac=1, random_state=42)\n",
    "df1 = df1.fillna('')\n",
    "df1['input_str'] = df1[['Item','Description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "#df1['cleanText'] = df1['input_str'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "df1['cleanText']=df1['input_str'].map(lambda s:preprocess_text(s)) \n",
    "#df1['cleanText'] = df1['input_str'].apply(normalize, lowercase=True, remove_stopwords=True)\n",
    "df1 = df1.reset_index(drop=True)\n",
    "X=df1[['Item','Description','establishment_type','cleanText']]\n",
    "Y_primary=df1['primary']\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train_primary, y_test_primary = train_test_split(X,\n",
    "                                                    Y_primary,\n",
    "                                                    test_size = .20, \n",
    "                                                    random_state = 42\n",
    "                                                    )\n",
    "\n",
    "df2 = df2_cicd\n",
    "df2['primary'] = df2['AgentCorrected_CatName_Primary'] + ',' + df2['AgentCorrected_Integer_Primary'].astype('int').astype('str')\n",
    "df2['input_str'] = df2[['Item','Description','establishment_type']].apply(lambda x: ' '.join(x[x.notnull()]), axis = 1)\n",
    "df2['cleanText']=df2['input_str'].map(lambda s:preprocess_text(s))\n",
    "#df2['cleanText'] = df2['input_str'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "X_cicd=df2[['Item','Description','establishment_type','cleanText']]\n",
    "\n",
    "Y_primary_cicd=df2['primary']\n",
    "X_train_cicd, X_test_cicd, y_train_primary_cicd, y_test_primary_cicd = train_test_split(X_cicd,\n",
    "                                                    Y_primary_cicd,\n",
    "                                                    test_size = .20, \n",
    "                                                    random_state = 42\n",
    "                                                    )\n",
    "X_train_final_1 = X_train.append(X_train_cicd)\n",
    "X_test_final_1 = X_test.append(X_test_cicd)\n",
    "X_train_final=X_train['cleanText'].append(X_train_cicd['cleanText'])\n",
    "y_train_final_primary=y_train_primary.append(y_train_primary_cicd)\n",
    "X_test_final=X_test['cleanText'].append(X_test_cicd['cleanText'])\n",
    "y_test_final_primary=y_test_primary.append(y_test_primary_cicd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7a1d0",
   "metadata": {},
   "source": [
    "split and save  data for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d3c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_end = int(len(df1)*train_size)\n",
    "df_train = df1[:train_end]\n",
    "df_test = df1[train_end:]\n",
    "train_end_cicd = int(len(df2)*train_size)\n",
    "df2_train = df2[:train_end_cicd]\n",
    "df2_test = df2[train_end_cicd:]\n",
    "df2_train = df2_train[['Item','Description','establishment_type','primary','input_str','cleanText']]\n",
    "df2_test = df2_test[['Item','Description','establishment_type','primary','input_str','cleanText']]\n",
    "X_train_save = df_train.append(df2_train)\n",
    "X_test_save = df_test.append(df2_test)\n",
    "X_train_save['label'] = 'train'\n",
    "X_test_save['label'] = 'test'\n",
    "X_data = X_train_save.append(X_test_save)\n",
    "X_data.to_csv('df_traintestdata_03-01-22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d043639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 10:10:04.412949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8456978368056545, 'precision_score': 0.6529295046837348, 'recall_score': 0.7615040953967324, 'f1_score': 0.6820349299083349}\n",
      "2022-01-11 10:52:42.738877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/envs/py365/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "result=X_test_final_1\n",
    "print(datetime.datetime.now())\n",
    "rf = Pipeline([('vect', CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', stop_words='english',max_df=0.85)),\n",
    "       ('tfidf', TfidfTransformer()),\n",
    "       ('clf', RandomForestClassifier(oob_score=True,n_jobs=-1,random_state=42,n_estimators=500))])\n",
    "       #('clf',GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))])\n",
    "       #('clf',XGBClassifier(eval_metric='mlogloss'))])  \n",
    "       \n",
    "rf.fit(X_train_final, y_train_final_primary)\n",
    "y_pred= rf.predict(X_test_final)\n",
    "result['original_cat_primary']=y_test_final_primary\n",
    "result['prediction_cat_primary']=y_pred\n",
    "result['prediction_cat_primary_confscore']=rf.predict_proba(X_test_final).max()\n",
    "output={'accuracy':accuracy_score(y_pred,y_test_final_primary),'precision_score':precision_score(y_pred,y_test_final_primary,average='macro'),'recall_score':recall_score(y_pred,y_test_final_primary,average='macro')\n",
    ",'f1_score':f1_score(y_pred,y_test_final_primary,average='macro')}\n",
    "result['confusion_matrix_primary']=str(output)\n",
    "print(result['confusion_matrix_primary'][0])\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e88b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=0.85,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(1, 1), preprocessor=None,\n",
      "                                 stop_words='english', strip_accents='ascii',\n",
      "                                 token_pattern='(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',\n",
      "                                 tokenizer=No...\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=None,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=500, n_jobs=-1,\n",
      "                                        oob_score=True, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "misclassifications_primary= result.loc[result['original_cat_primary']!=result['prediction_cat_primary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ac7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications_primary.sort_values(by=['Item','Description','establishment_type'], ascending=True).head(270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a95a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications_primary.to_csv('/Users/jghosh2/Documents/my-notebook/Tax_ml_poc/output/misclassifications_primary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications_primary[misclassifications_primary['original_cat_primary']=='CAT_TPP_BATH_GELS,776']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e7a986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05aff761",
   "metadata": {},
   "source": [
    "\"{'accuracy': 0.8146149522203485, 'precision_score': 0.6027551606729535, 'recall_score': 0.7097466761674291, 'f1_score': 0.6327463859326979}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4013975a",
   "metadata": {},
   "source": [
    "saving model to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename_primary= 'finalized_model_rf_primary-03-01-22_allprod.sav'\n",
    "pickle.dump(rf, open(filename_primary, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8d5d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(\"Time :{} result :{}\".format(datetime.datetime.now(),result['confusion_matrix_primary'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad733b6",
   "metadata": {},
   "source": [
    "Time :2022-01-10 13:30:26.356610 result :{'accuracy': 0.8185367800039901, 'precision_score': 0.5848761715254991, 'recall_score': 0.672646577840006, 'f1_score': 0.6100045958278678}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b033e",
   "metadata": {},
   "source": [
    "Time :2022-01-10 13:39:45.378508 result :{'accuracy': 0.8167982443640095, 'precision_score': 0.5828179565369508, 'recall_score': 0.694053097419111, 'f1_score': 0.6153519093480956}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64140eb1",
   "metadata": {},
   "source": [
    "Time :2022-01-10 14:04:13.438304 result :{'accuracy': 0.8207028244079003, 'precision_score': 0.598134322659592, 'recall_score': 0.7163954355735384, 'f1_score': 0.6336420913159138}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31081800",
   "metadata": {},
   "source": [
    "Time :2022-01-10 16:15:05.965823 result :{'accuracy': 0.8192777951948015, 'precision_score': 0.58422004758596, 'recall_score': 0.7013460556124523, 'f1_score': 0.6171140663609939}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af584f15",
   "metadata": {},
   "source": [
    "Time :2022-01-10 16:30:28.661864 result :{'accuracy': 0.8203323168124946, 'precision_score': 0.5828415707142136, 'recall_score': 0.6922552428178115, 'f1_score': 0.6158350834301465}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a9d33",
   "metadata": {},
   "source": [
    "Time :2022-01-10 17:13:56.042353 result :{'accuracy': 0.8250634137999829, 'precision_score': 0.6017204348512221, 'recall_score': 0.7016768888896173, 'f1_score': 0.6292577552019242}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a6c8ca",
   "metadata": {},
   "source": [
    "Time :2022-01-10 17:45:33.576796 result :{'accuracy': 0.8197338045429932, 'precision_score': 0.6097855795962889, 'recall_score': 0.6989103740558321, 'f1_score': 0.6339990438994022}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69b43a",
   "metadata": {},
   "source": [
    "Time :2022-01-10 18:00:59.932664 result :{'accuracy': 0.8222988571265711, 'precision_score': 0.6040505715950665, 'recall_score': 0.7041889895331753, 'f1_score': 0.630361835607479}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ab76b",
   "metadata": {},
   "source": [
    "Time :2022-01-10 18:50:01.397963 result :{'accuracy': 0.8222988571265711, 'precision_score': 0.6040505715950665, 'recall_score': 0.7041889895331753, 'f1_score': 0.630361835607479}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d766ea20",
   "metadata": {},
   "source": [
    "{'accuracy': 0.8198348463305261, 'precision_score': 0.5943177708372124, 'recall_score': 0.6808857187011089, 'f1_score': 0.6211879572499776}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb1c31",
   "metadata": {},
   "source": [
    "{'accuracy': 0.8341265995952917, 'precision_score': 0.6140457607875881, 'recall_score': 0.7160461281960248, 'f1_score': 0.6411403224021243}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e471ae",
   "metadata": {},
   "source": [
    "{'accuracy': 0.8424202696155271, 'precision_score': 0.63494046605141, 'recall_score': 0.750621724728942, 'f1_score': 0.66790481231777}\n",
    "n_estimator-100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e30f44",
   "metadata": {},
   "source": [
    "{'accuracy': 0.8435317924017443, 'precision_score': 0.6366498170102253, 'recall_score': 0.7501320433368587, 'f1_score': 0.6679389982024275}----200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4570a",
   "metadata": {},
   "source": [
    "{'accuracy': 0.8443013081768176, 'precision_score': 0.6519943872650363, 'recall_score': 0.7635078463184546, 'f1_score': 0.6826975082666656}---300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807c77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e342c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61dba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3712483d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ba841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cat(category):\n",
    "    category_list=category.split(',')\n",
    "    if len(category_list)==1:      \n",
    "        primary_category=category_list[0]\n",
    "        secondary_category=category_list[0]\n",
    "    if len(category_list)==2:      \n",
    "        primary_category=category_list[0]\n",
    "        if category_list[1] in ['TEMP_HEATED','TEMP_COLD','TEMP_UNHEATED']:\n",
    "              secondary_category=category_list[0]\n",
    "        else:\n",
    "              secondary_category=category_list[1]\n",
    "    if len(category_list)>2:      \n",
    "        primary_category=category_list[0]\n",
    "        secondary_category=category_list[1]\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    return primary_category,secondary_category\n",
    "def split_int(integer):\n",
    "    str_int=str(integer)\n",
    "    integer_list=str_int.split(',')\n",
    "    if len(integer_list)==1:      \n",
    "        primary_integer=integer_list[0]\n",
    "        secondary_integer=integer_list[0]\n",
    "    if len(integer_list)==2:      \n",
    "        primary_integer=integer_list[0]\n",
    "        if integer_list[1]=='1':\n",
    "            secondary_integer=integer_list[0]\n",
    "        else:\n",
    "            secondary_integer=integer_list[1]\n",
    "    if len(integer_list)>2:      \n",
    "        primary_integer=integer_list[0]\n",
    "        secondary_integer=integer_list[1]\n",
    "    else:\n",
    "         pass\n",
    "        \n",
    "    return primary_integer,secondary_integer\n",
    "def combine(category,integer):\n",
    "    return category+\",\"+integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55492cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['primary_cat']=df['Agent Corrected CAT Name'].map(lambda x:split_cat(x)[0])\n",
    "df['secondary_cat']=df['Agent Corrected CAT Name'].map(lambda x:split_cat(x)[1])\n",
    "df['primary_int']=df['Agent Corrected Integer'].map(lambda x:split_int(x)[0])\n",
    "df['secondary_int']=df['Agent Corrected Integer'].map(lambda x:split_int(x)[1])\n",
    "df['primary_int_prediction']=df['Integer'].map(lambda x:split_int(x)[0])\n",
    "df['primary']=df[['primary_cat','primary_int']].apply(lambda x:combine(*x),axis=1)\n",
    "df['secondary']=df[['secondary_cat','secondary_int']].apply(lambda x:combine(*x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fcb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('TaxML-CICD - Prod_Data_after_preprocess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[df['Inetger_ValidationScore[0-100]'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c396c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff06ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df_test[df_test['primary_int_prediction']==df_test['primary_int']]\n",
    "len(df2)#no of correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a63145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "rf = Pipeline([('vect', CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', lowercase=True, stop_words='english')),\n",
    "       ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "       ('clf', RandomForestClassifier()),\n",
    "      ])\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigramslf__\n",
    "     \"clf__bootstrap\":[True, False],\n",
    "     \"clf__max_depth\":[10, 50, 100,500, None],\n",
    "     \"clf__max_features\":['auto', 'sqrt'],\n",
    "     \"clf__min_samples_leaf\":[1,2,4],\n",
    "     \"clf__min_samples_split\":[2,5,10],\n",
    "     \"clf__n_estimators\":[400,600,800],\n",
    "     \"clf__random_state\":[3]\n",
    "\n",
    "}\n",
    "\n",
    "RandomizedSearch = RandomizedSearchCV(rf,\n",
    "                          parameters, \n",
    "                          cv=5,\n",
    "                          verbose=1, \n",
    "                          n_jobs=-1)\n",
    "\n",
    "t0 = time()\n",
    "rf_best_model = RandomizedSearch.fit(X_train_final, y_train_final_primary)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "#print()\n",
    "print(\"Best score: %0.3f\" % rf_best_model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = rf_best_model.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e934dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b26998a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf39b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29af17c1",
   "metadata": {},
   "source": [
    "169000 total data b4 traing + 403 rows\n",
    "exp01:169000+403 rows\n",
    "exp02:169000+727 rows\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
